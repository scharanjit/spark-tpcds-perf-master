[0m[[0minfo[0m] [0mRunning com.imaginea.spark.tpcds.perf.RunBenchmark --benchmark DatasetPerformance[0m
[0m[[31merror[0m] [0mUsing Spark's default log4j profile: org/apache/spark/log4j-defaults.properties[0m
[0m[[31merror[0m] [0m16/06/07 19:49:10 INFO SparkContext: Running Spark version 2.0.0-SNAPSHOT[0m
[0m[[31merror[0m] [0m16/06/07 19:49:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable[0m
[0m[[31merror[0m] [0m16/06/07 19:49:10 WARN Utils: Your hostname, PRINHYLTPHP0415 resolves to a loopback address: 127.0.1.1; using 172.16.54.31 instead (on interface wlan0)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:10 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address[0m
[0m[[31merror[0m] [0m16/06/07 19:49:10 INFO SecurityManager: Changing view acls to: charanjits[0m
[0m[[31merror[0m] [0m16/06/07 19:49:10 INFO SecurityManager: Changing modify acls to: charanjits[0m
[0m[[31merror[0m] [0m16/06/07 19:49:10 INFO SecurityManager: Changing view acls groups to: [0m
[0m[[31merror[0m] [0m16/06/07 19:49:10 INFO SecurityManager: Changing modify acls groups to: [0m
[0m[[31merror[0m] [0m16/06/07 19:49:10 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(charanjits); groups with view permissions: Set(); users  with modify permissions: Set(charanjits); groups with modify permissions: Set()[0m
[0m[[31merror[0m] [0m16/06/07 19:49:10 INFO Utils: Successfully started service 'sparkDriver' on port 58066.[0m
[0m[[31merror[0m] [0m16/06/07 19:49:10 INFO SparkEnv: Registering MapOutputTracker[0m
[0m[[31merror[0m] [0m16/06/07 19:49:10 INFO SparkEnv: Registering BlockManagerMaster[0m
[0m[[31merror[0m] [0m16/06/07 19:49:10 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-fa5dffbc-b027-44b9-a4d7-c3fa9433426b[0m
[0m[[31merror[0m] [0m16/06/07 19:49:10 INFO MemoryStore: MemoryStore started with capacity 2.4 GB[0m
[0m[[31merror[0m] [0m16/06/07 19:49:10 INFO SparkEnv: Registering OutputCommitCoordinator[0m
[0m[[31merror[0m] [0m16/06/07 19:49:11 WARN AbstractHandler: No Server set for org.spark_project.jetty.server.handler.ErrorHandler@fc258b1[0m
[0m[[31merror[0m] [0m16/06/07 19:49:11 INFO Utils: Successfully started service 'SparkUI' on port 4040.[0m
[0m[[31merror[0m] [0m16/06/07 19:49:11 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://172.16.54.31:4040[0m
[0m[[31merror[0m] [0m16/06/07 19:49:11 INFO Executor: Starting executor ID driver on host localhost[0m
[0m[[31merror[0m] [0m16/06/07 19:49:11 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33061.[0m
[0m[[31merror[0m] [0m16/06/07 19:49:11 INFO NettyBlockTransferService: Server created on 172.16.54.31:33061[0m
[0m[[31merror[0m] [0m16/06/07 19:49:11 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.16.54.31, 33061)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:11 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.54.31:33061 with 2.4 GB RAM, BlockManagerId(driver, 172.16.54.31, 33061)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:11 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.16.54.31, 33061)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:11 WARN SparkContext: Use an existing SparkContext, some configuration may not take effect.[0m
[0m[[31merror[0m] [0m16/06/07 19:49:13 WARN ClosureCleaner: Expected a closure; got com.imaginea.spark.tpcds.perf.Data$[0m
[0m[[0minfo[0m] [0m== QUERY LIST ==[0m
[0m[[0minfo[0m] [0m== Parsed Logical Plan ==[0m
[0m[[0minfo[0m] [0mRange (1, 100000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== Analyzed Logical Plan ==[0m
[0m[[0minfo[0m] [0mid: bigint[0m
[0m[[0minfo[0m] [0mRange (1, 100000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== Optimized Logical Plan ==[0m
[0m[[0minfo[0m] [0mRange (1, 100000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== Physical Plan ==[0m
[0m[[0minfo[0m] [0m*Range (1, 100000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== Query45: DS: range ==[0m
[0m[[0minfo[0m] [0mRange (1, 100000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m     [0m
[0m[[0minfo[0m] [0m== Parsed Logical Plan ==[0m
[0m[[0minfo[0m] [0mRange (1, 100000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== Analyzed Logical Plan ==[0m
[0m[[0minfo[0m] [0mid: bigint[0m
[0m[[0minfo[0m] [0mRange (1, 100000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== Optimized Logical Plan ==[0m
[0m[[0minfo[0m] [0mRange (1, 100000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== Physical Plan ==[0m
[0m[[0minfo[0m] [0m*Range (1, 100000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== Query45: DF: range ==[0m
[0m[[0minfo[0m] [0mRange (1, 100000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m     [0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== RDD: range ==[0m
[0m[[0minfo[0m] [0m(4) MapPartitionsRDD[4] at map at DatasetPerformance.scala:51 [][0m
[0m[[0minfo[0m] [0m  MapPartitionsRDD[1] at range at DatasetPerformance.scala:32 [][0m
[0m[[0minfo[0m] [0m  ParallelCollectionRDD[0] at range at DatasetPerformance.scala:32 [][0m
[0m[[0minfo[0m] [0m       [0m
[0m[[0minfo[0m] [0m== Parsed Logical Plan ==[0m
[0m[[0minfo[0m] [0m'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#36L][0m
[0m[[0minfo[0m] [0m+- 'Filter <function1>.apply[0m
[0m[[0minfo[0m] [0m   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#35: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#33L][0m
[0m[[0minfo[0m] [0m         +- Filter <function1>.apply[0m
[0m[[0minfo[0m] [0m            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#32: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#30L][0m
[0m[[0minfo[0m] [0m                  +- Filter <function1>.apply[0m
[0m[[0minfo[0m] [0m                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#29: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#27L][0m
[0m[[0minfo[0m] [0m                           +- Filter <function1>.apply[0m
[0m[[0minfo[0m] [0m                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#26: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m                                 +- Range (1, 100000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== Analyzed Logical Plan ==[0m
[0m[[0minfo[0m] [0mid: bigint[0m
[0m[[0minfo[0m] [0mSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#36L][0m
[0m[[0minfo[0m] [0m+- Filter <function1>.apply[0m
[0m[[0minfo[0m] [0m   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#35: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#33L][0m
[0m[[0minfo[0m] [0m         +- Filter <function1>.apply[0m
[0m[[0minfo[0m] [0m            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#32: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#30L][0m
[0m[[0minfo[0m] [0m                  +- Filter <function1>.apply[0m
[0m[[0minfo[0m] [0m                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#29: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#27L][0m
[0m[[0minfo[0m] [0m                           +- Filter <function1>.apply[0m
[0m[[0minfo[0m] [0m                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#26: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m                                 +- Range (1, 100000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== Optimized Logical Plan ==[0m
[0m[[0minfo[0m] [0mSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#36L][0m
[0m[[0minfo[0m] [0m+- Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)[0m
[0m[[0minfo[0m] [0m   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#26: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m      +- Range (1, 100000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== Physical Plan ==[0m
[0m[[0minfo[0m] [0m*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#36L][0m
[0m[[0minfo[0m] [0m+- *Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)[0m
[0m[[0minfo[0m] [0m   +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#26: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m      +- *Range (1, 100000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== Query45: DS: back-to-back filters ==[0m
[0m[[0minfo[0m] [0mSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#52L][0m
[0m[[0minfo[0m] [0m+- Filter <function1>.apply[0m
[0m[[0minfo[0m] [0m   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#51: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#49L][0m
[0m[[0minfo[0m] [0m         +- Filter <function1>.apply[0m
[0m[[0minfo[0m] [0m            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#48: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#46L][0m
[0m[[0minfo[0m] [0m                  +- Filter <function1>.apply[0m
[0m[[0minfo[0m] [0m                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#45: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#43L][0m
[0m[[0minfo[0m] [0m                           +- Filter <function1>.apply[0m
[0m[[0minfo[0m] [0m                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#42: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m                                 +- Range (1, 100000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m     [0m
[0m[[31merror[0m] [0m16/06/07 19:49:14 INFO SparkSqlParser: Parsing command: id % 100 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:49:15 INFO SparkSqlParser: Parsing command: id % 101 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:49:15 INFO SparkSqlParser: Parsing command: id % 102 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:49:15 INFO SparkSqlParser: Parsing command: id % 103 != 0[0m
[0m[[0minfo[0m] [0m== Parsed Logical Plan ==[0m
[0m[[0minfo[0m] [0m'Filter NOT (('id % 103) = 0)[0m
[0m[[0minfo[0m] [0m+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))[0m
[0m[[0minfo[0m] [0m   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))[0m
[0m[[0minfo[0m] [0m      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))[0m
[0m[[0minfo[0m] [0m         +- Range (1, 100000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== Analyzed Logical Plan ==[0m
[0m[[0minfo[0m] [0mid: bigint[0m
[0m[[0minfo[0m] [0mFilter NOT ((id#0L % cast(103 as bigint)) = cast(0 as bigint))[0m
[0m[[0minfo[0m] [0m+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))[0m
[0m[[0minfo[0m] [0m   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))[0m
[0m[[0minfo[0m] [0m      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))[0m
[0m[[0minfo[0m] [0m         +- Range (1, 100000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== Optimized Logical Plan ==[0m
[0m[[0minfo[0m] [0mFilter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))[0m
[0m[[0minfo[0m] [0m+- Range (1, 100000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== Physical Plan ==[0m
[0m[[0minfo[0m] [0m*Filter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))[0m
[0m[[0minfo[0m] [0m+- *Range (1, 100000000, splits=4)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:15 INFO SparkSqlParser: Parsing command: id % 100 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:49:15 INFO SparkSqlParser: Parsing command: id % 101 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:49:15 INFO SparkSqlParser: Parsing command: id % 102 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:49:15 INFO SparkSqlParser: Parsing command: id % 103 != 0[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== Query45: DF: back-to-back filters ==[0m
[0m[[0minfo[0m] [0mFilter NOT ((id#0L % cast(103 as bigint)) = cast(0 as bigint))[0m
[0m[[0minfo[0m] [0m+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))[0m
[0m[[0minfo[0m] [0m   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))[0m
[0m[[0minfo[0m] [0m      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))[0m
[0m[[0minfo[0m] [0m         +- Range (1, 100000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m     [0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== RDD: back-to-back filters ==[0m
[0m[[0minfo[0m] [0m(4) MapPartitionsRDD[9] at filter at DatasetPerformance.scala:75 [][0m
[0m[[0minfo[0m] [0m  MapPartitionsRDD[8] at filter at DatasetPerformance.scala:74 [][0m
[0m[[0minfo[0m] [0m  MapPartitionsRDD[7] at filter at DatasetPerformance.scala:73 [][0m
[0m[[0minfo[0m] [0m  MapPartitionsRDD[6] at filter at DatasetPerformance.scala:72 [][0m
[0m[[0minfo[0m] [0m  MapPartitionsRDD[5] at map at DatasetPerformance.scala:71 [][0m
[0m[[0minfo[0m] [0m  MapPartitionsRDD[1] at range at DatasetPerformance.scala:32 [][0m
[0m[[0minfo[0m] [0m  ParallelCollectionRDD[0] at range at DatasetPerformance.scala:32 [][0m
[0m[[0minfo[0m] [0m       [0m
[0m[[0minfo[0m] [0m== Parsed Logical Plan ==[0m
[0m[[0minfo[0m] [0m'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#88L][0m
[0m[[0minfo[0m] [0m+- 'MapElements <function1>, obj#87: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#86: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#83L][0m
[0m[[0minfo[0m] [0m         +- MapElements <function1>, obj#82: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#81: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#78L][0m
[0m[[0minfo[0m] [0m                  +- MapElements <function1>, obj#77: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#76: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#73L][0m
[0m[[0minfo[0m] [0m                           +- MapElements <function1>, obj#72: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#71: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m                                 +- Range (1, 100000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== Analyzed Logical Plan ==[0m
[0m[[0minfo[0m] [0mid: bigint[0m
[0m[[0minfo[0m] [0mSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#88L][0m
[0m[[0minfo[0m] [0m+- MapElements <function1>, obj#87: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#86: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#83L][0m
[0m[[0minfo[0m] [0m         +- MapElements <function1>, obj#82: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#81: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#78L][0m
[0m[[0minfo[0m] [0m                  +- MapElements <function1>, obj#77: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#76: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#73L][0m
[0m[[0minfo[0m] [0m                           +- MapElements <function1>, obj#72: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#71: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m                                 +- Range (1, 100000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== Optimized Logical Plan ==[0m
[0m[[0minfo[0m] [0mSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#88L][0m
[0m[[0minfo[0m] [0m+- MapElements <function1>, obj#87: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m   +- MapElements <function1>, obj#82: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m      +- MapElements <function1>, obj#77: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m         +- MapElements <function1>, obj#72: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#71: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m               +- Range (1, 100000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== Physical Plan ==[0m
[0m[[0minfo[0m] [0m*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#88L][0m
[0m[[0minfo[0m] [0m+- *MapElements <function1>, obj#87: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m   +- *MapElements <function1>, obj#82: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m      +- *MapElements <function1>, obj#77: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m         +- *MapElements <function1>, obj#72: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m            +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#71: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m               +- *Range (1, 100000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== Query45: DS: back-to-back maps ==[0m
[0m[[0minfo[0m] [0mSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#112L][0m
[0m[[0minfo[0m] [0m+- MapElements <function1>, obj#111: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#110: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#107L][0m
[0m[[0minfo[0m] [0m         +- MapElements <function1>, obj#106: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#105: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#102L][0m
[0m[[0minfo[0m] [0m                  +- MapElements <function1>, obj#101: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#100: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#97L][0m
[0m[[0minfo[0m] [0m                           +- MapElements <function1>, obj#96: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#95: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m                                 +- Range (1, 100000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m     [0m
[0m[[0minfo[0m] [0m== Parsed Logical Plan ==[0m
[0m[[0minfo[0m] [0m'Project [('id + 1) AS id#127][0m
[0m[[0minfo[0m] [0m+- Project [(id#121L + cast(1 as bigint)) AS id#124L][0m
[0m[[0minfo[0m] [0m   +- Project [(id#118L + cast(1 as bigint)) AS id#121L][0m
[0m[[0minfo[0m] [0m      +- Project [(id#0L + cast(1 as bigint)) AS id#118L][0m
[0m[[0minfo[0m] [0m         +- Range (1, 100000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== Analyzed Logical Plan ==[0m
[0m[[0minfo[0m] [0mid: bigint[0m
[0m[[0minfo[0m] [0mProject [(id#124L + cast(1 as bigint)) AS id#127L][0m
[0m[[0minfo[0m] [0m+- Project [(id#121L + cast(1 as bigint)) AS id#124L][0m
[0m[[0minfo[0m] [0m   +- Project [(id#118L + cast(1 as bigint)) AS id#121L][0m
[0m[[0minfo[0m] [0m      +- Project [(id#0L + cast(1 as bigint)) AS id#118L][0m
[0m[[0minfo[0m] [0m         +- Range (1, 100000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== Optimized Logical Plan ==[0m
[0m[[0minfo[0m] [0mProject [((((id#0L + 1) + 1) + 1) + 1) AS id#127L][0m
[0m[[0minfo[0m] [0m+- Range (1, 100000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== Physical Plan ==[0m
[0m[[0minfo[0m] [0m*Project [((((id#0L + 1) + 1) + 1) + 1) AS id#127L][0m
[0m[[0minfo[0m] [0m+- *Range (1, 100000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== Query45: DF: back-to-back maps ==[0m
[0m[[0minfo[0m] [0mProject [(id#138L + cast(1 as bigint)) AS id#141L][0m
[0m[[0minfo[0m] [0m+- Project [(id#135L + cast(1 as bigint)) AS id#138L][0m
[0m[[0minfo[0m] [0m   +- Project [(id#132L + cast(1 as bigint)) AS id#135L][0m
[0m[[0minfo[0m] [0m      +- Project [(id#0L + cast(1 as bigint)) AS id#132L][0m
[0m[[0minfo[0m] [0m         +- Range (1, 100000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m     [0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== RDD: back-to-back maps ==[0m
[0m[[0minfo[0m] [0m(4) MapPartitionsRDD[14] at map at DatasetPerformance.scala:99 [][0m
[0m[[0minfo[0m] [0m  MapPartitionsRDD[13] at map at DatasetPerformance.scala:98 [][0m
[0m[[0minfo[0m] [0m  MapPartitionsRDD[12] at map at DatasetPerformance.scala:97 [][0m
[0m[[0minfo[0m] [0m  MapPartitionsRDD[11] at map at DatasetPerformance.scala:96 [][0m
[0m[[0minfo[0m] [0m  MapPartitionsRDD[10] at map at DatasetPerformance.scala:95 [][0m
[0m[[0minfo[0m] [0m  MapPartitionsRDD[1] at range at DatasetPerformance.scala:32 [][0m
[0m[[0minfo[0m] [0m  ParallelCollectionRDD[0] at range at DatasetPerformance.scala:32 [][0m
[0m[[0minfo[0m] [0m       [0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== Query78: DS: average ==[0m
[0m[[0minfo[0m] [0m Can't be analyzed: org.apache.spark.sql.AnalysisException: cannot resolve '`sum`' given input columns: [id];[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m [0m
[0m[[0minfo[0m] [0m         [0m
[0m[[31merror[0m] [0m16/06/07 19:49:15 INFO SparkSqlParser: Parsing command: avg(id)[0m
[0m[[0minfo[0m] [0m== Parsed Logical Plan ==[0m
[0m[[0minfo[0m] [0m'Project [unresolvedalias('avg('id), Some(<function1>))][0m
[0m[[0minfo[0m] [0m+- Range (1, 1000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== Analyzed Logical Plan ==[0m
[0m[[0minfo[0m] [0mavg(id): double[0m
[0m[[0minfo[0m] [0mAggregate [avg(id#3L) AS avg(id)#153][0m
[0m[[0minfo[0m] [0m+- Range (1, 1000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== Optimized Logical Plan ==[0m
[0m[[0minfo[0m] [0mAggregate [avg(id#3L) AS avg(id)#153][0m
[0m[[0minfo[0m] [0m+- Range (1, 1000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== Physical Plan ==[0m
[0m[[0minfo[0m] [0m*TungstenAggregate(key=[], functions=[avg(id#3L)], output=[avg(id)#153])[0m
[0m[[0minfo[0m] [0m+- Exchange SinglePartition, None[0m
[0m[[0minfo[0m] [0m   +- *TungstenAggregate(key=[], functions=[partial_avg(id#3L)], output=[sum#157,count#158L])[0m
[0m[[0minfo[0m] [0m      +- *Range (1, 1000000, splits=4)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:16 INFO SparkSqlParser: Parsing command: avg(id)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== Query45: DF: average ==[0m
[0m[[0minfo[0m] [0mAggregate [avg(id#3L) AS avg(id)#165][0m
[0m[[0minfo[0m] [0m+- Range (1, 1000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m     [0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== RDD: average ==[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m       [0m
[0m[[0minfo[0m] [0m== Parsed Logical Plan ==[0m
[0m[[0minfo[0m] [0mRange (1, 100000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== Analyzed Logical Plan ==[0m
[0m[[0minfo[0m] [0mid: bigint[0m
[0m[[0minfo[0m] [0mRange (1, 100000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== Optimized Logical Plan ==[0m
[0m[[0minfo[0m] [0mRange (1, 100000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== Physical Plan ==[0m
[0m[[0minfo[0m] [0m*Range (1, 100000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== Query45: DS: range ==[0m
[0m[[0minfo[0m] [0mRange (1, 100000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m     [0m
[0m[[0minfo[0m] [0m== Parsed Logical Plan ==[0m
[0m[[0minfo[0m] [0mRange (1, 100000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== Analyzed Logical Plan ==[0m
[0m[[0minfo[0m] [0mid: bigint[0m
[0m[[0minfo[0m] [0mRange (1, 100000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== Optimized Logical Plan ==[0m
[0m[[0minfo[0m] [0mRange (1, 100000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== Physical Plan ==[0m
[0m[[0minfo[0m] [0m*Range (1, 100000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== Query45: DF: range ==[0m
[0m[[0minfo[0m] [0mRange (1, 100000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m     [0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== RDD: range ==[0m
[0m[[0minfo[0m] [0m(4) MapPartitionsRDD[4] at map at DatasetPerformance.scala:51 [][0m
[0m[[0minfo[0m] [0m  MapPartitionsRDD[1] at range at DatasetPerformance.scala:32 [][0m
[0m[[0minfo[0m] [0m  ParallelCollectionRDD[0] at range at DatasetPerformance.scala:32 [][0m
[0m[[0minfo[0m] [0m       [0m
[0m[[0minfo[0m] [0m== Parsed Logical Plan ==[0m
[0m[[0minfo[0m] [0m'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#191L][0m
[0m[[0minfo[0m] [0m+- 'Filter <function1>.apply[0m
[0m[[0minfo[0m] [0m   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#190: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#188L][0m
[0m[[0minfo[0m] [0m         +- Filter <function1>.apply[0m
[0m[[0minfo[0m] [0m            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#187: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#185L][0m
[0m[[0minfo[0m] [0m                  +- Filter <function1>.apply[0m
[0m[[0minfo[0m] [0m                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#184: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#182L][0m
[0m[[0minfo[0m] [0m                           +- Filter <function1>.apply[0m
[0m[[0minfo[0m] [0m                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#181: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m                                 +- Range (1, 100000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== Analyzed Logical Plan ==[0m
[0m[[0minfo[0m] [0mid: bigint[0m
[0m[[0minfo[0m] [0mSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#191L][0m
[0m[[0minfo[0m] [0m+- Filter <function1>.apply[0m
[0m[[0minfo[0m] [0m   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#190: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#188L][0m
[0m[[0minfo[0m] [0m         +- Filter <function1>.apply[0m
[0m[[0minfo[0m] [0m            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#187: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#185L][0m
[0m[[0minfo[0m] [0m                  +- Filter <function1>.apply[0m
[0m[[0minfo[0m] [0m                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#184: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#182L][0m
[0m[[0minfo[0m] [0m                           +- Filter <function1>.apply[0m
[0m[[0minfo[0m] [0m                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#181: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m                                 +- Range (1, 100000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== Optimized Logical Plan ==[0m
[0m[[0minfo[0m] [0mSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#191L][0m
[0m[[0minfo[0m] [0m+- Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)[0m
[0m[[0minfo[0m] [0m   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#181: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m      +- Range (1, 100000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== Physical Plan ==[0m
[0m[[0minfo[0m] [0m*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#191L][0m
[0m[[0minfo[0m] [0m+- *Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)[0m
[0m[[0minfo[0m] [0m   +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#181: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m      +- *Range (1, 100000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== Query45: DS: back-to-back filters ==[0m
[0m[[0minfo[0m] [0mSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#207L][0m
[0m[[0minfo[0m] [0m+- Filter <function1>.apply[0m
[0m[[0minfo[0m] [0m   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#206: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#204L][0m
[0m[[0minfo[0m] [0m         +- Filter <function1>.apply[0m
[0m[[0minfo[0m] [0m            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#203: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#201L][0m
[0m[[0minfo[0m] [0m                  +- Filter <function1>.apply[0m
[0m[[0minfo[0m] [0m                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#200: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#198L][0m
[0m[[0minfo[0m] [0m                           +- Filter <function1>.apply[0m
[0m[[0minfo[0m] [0m                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#197: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m                                 +- Range (1, 100000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m     [0m
[0m[[31merror[0m] [0m16/06/07 19:49:16 INFO SparkSqlParser: Parsing command: id % 100 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:49:16 INFO SparkSqlParser: Parsing command: id % 101 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:49:16 INFO SparkSqlParser: Parsing command: id % 102 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:49:16 INFO SparkSqlParser: Parsing command: id % 103 != 0[0m
[0m[[0minfo[0m] [0m== Parsed Logical Plan ==[0m
[0m[[0minfo[0m] [0m'Filter NOT (('id % 103) = 0)[0m
[0m[[0minfo[0m] [0m+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))[0m
[0m[[0minfo[0m] [0m   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))[0m
[0m[[0minfo[0m] [0m      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))[0m
[0m[[0minfo[0m] [0m         +- Range (1, 100000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== Analyzed Logical Plan ==[0m
[0m[[0minfo[0m] [0mid: bigint[0m
[0m[[0minfo[0m] [0mFilter NOT ((id#0L % cast(103 as bigint)) = cast(0 as bigint))[0m
[0m[[0minfo[0m] [0m+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))[0m
[0m[[0minfo[0m] [0m   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))[0m
[0m[[0minfo[0m] [0m      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))[0m
[0m[[0minfo[0m] [0m         +- Range (1, 100000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== Optimized Logical Plan ==[0m
[0m[[0minfo[0m] [0mFilter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))[0m
[0m[[0minfo[0m] [0m+- Range (1, 100000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== Physical Plan ==[0m
[0m[[0minfo[0m] [0m*Filter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))[0m
[0m[[0minfo[0m] [0m+- *Range (1, 100000000, splits=4)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:16 INFO SparkSqlParser: Parsing command: id % 100 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:49:16 INFO SparkSqlParser: Parsing command: id % 101 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:49:16 INFO SparkSqlParser: Parsing command: id % 102 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:49:16 INFO SparkSqlParser: Parsing command: id % 103 != 0[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== Query45: DF: back-to-back filters ==[0m
[0m[[0minfo[0m] [0mFilter NOT ((id#0L % cast(103 as bigint)) = cast(0 as bigint))[0m
[0m[[0minfo[0m] [0m+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))[0m
[0m[[0minfo[0m] [0m   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))[0m
[0m[[0minfo[0m] [0m      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))[0m
[0m[[0minfo[0m] [0m         +- Range (1, 100000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m     [0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== RDD: back-to-back filters ==[0m
[0m[[0minfo[0m] [0m(4) MapPartitionsRDD[9] at filter at DatasetPerformance.scala:75 [][0m
[0m[[0minfo[0m] [0m  MapPartitionsRDD[8] at filter at DatasetPerformance.scala:74 [][0m
[0m[[0minfo[0m] [0m  MapPartitionsRDD[7] at filter at DatasetPerformance.scala:73 [][0m
[0m[[0minfo[0m] [0m  MapPartitionsRDD[6] at filter at DatasetPerformance.scala:72 [][0m
[0m[[0minfo[0m] [0m  MapPartitionsRDD[5] at map at DatasetPerformance.scala:71 [][0m
[0m[[0minfo[0m] [0m  MapPartitionsRDD[1] at range at DatasetPerformance.scala:32 [][0m
[0m[[0minfo[0m] [0m  ParallelCollectionRDD[0] at range at DatasetPerformance.scala:32 [][0m
[0m[[0minfo[0m] [0m       [0m
[0m[[0minfo[0m] [0m== Parsed Logical Plan ==[0m
[0m[[0minfo[0m] [0m'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#243L][0m
[0m[[0minfo[0m] [0m+- 'MapElements <function1>, obj#242: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#241: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#238L][0m
[0m[[0minfo[0m] [0m         +- MapElements <function1>, obj#237: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#236: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#233L][0m
[0m[[0minfo[0m] [0m                  +- MapElements <function1>, obj#232: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#231: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#228L][0m
[0m[[0minfo[0m] [0m                           +- MapElements <function1>, obj#227: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#226: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m                                 +- Range (1, 100000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== Analyzed Logical Plan ==[0m
[0m[[0minfo[0m] [0mid: bigint[0m
[0m[[0minfo[0m] [0mSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#243L][0m
[0m[[0minfo[0m] [0m+- MapElements <function1>, obj#242: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#241: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#238L][0m
[0m[[0minfo[0m] [0m         +- MapElements <function1>, obj#237: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#236: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#233L][0m
[0m[[0minfo[0m] [0m                  +- MapElements <function1>, obj#232: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#231: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#228L][0m
[0m[[0minfo[0m] [0m                           +- MapElements <function1>, obj#227: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#226: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m                                 +- Range (1, 100000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== Optimized Logical Plan ==[0m
[0m[[0minfo[0m] [0mSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#243L][0m
[0m[[0minfo[0m] [0m+- MapElements <function1>, obj#242: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m   +- MapElements <function1>, obj#237: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m      +- MapElements <function1>, obj#232: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m         +- MapElements <function1>, obj#227: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#226: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m               +- Range (1, 100000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== Physical Plan ==[0m
[0m[[0minfo[0m] [0m*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#243L][0m
[0m[[0minfo[0m] [0m+- *MapElements <function1>, obj#242: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m   +- *MapElements <function1>, obj#237: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m      +- *MapElements <function1>, obj#232: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m         +- *MapElements <function1>, obj#227: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m            +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#226: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m               +- *Range (1, 100000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== Query45: DS: back-to-back maps ==[0m
[0m[[0minfo[0m] [0mSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#267L][0m
[0m[[0minfo[0m] [0m+- MapElements <function1>, obj#266: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#265: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#262L][0m
[0m[[0minfo[0m] [0m         +- MapElements <function1>, obj#261: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#260: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#257L][0m
[0m[[0minfo[0m] [0m                  +- MapElements <function1>, obj#256: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#255: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#252L][0m
[0m[[0minfo[0m] [0m                           +- MapElements <function1>, obj#251: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#250: com.imaginea.spark.tpcds.perf.Data[0m
[0m[[0minfo[0m] [0m                                 +- Range (1, 100000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m     [0m
[0m[[0minfo[0m] [0m== Parsed Logical Plan ==[0m
[0m[[0minfo[0m] [0m'Project [('id + 1) AS id#282][0m
[0m[[0minfo[0m] [0m+- Project [(id#276L + cast(1 as bigint)) AS id#279L][0m
[0m[[0minfo[0m] [0m   +- Project [(id#273L + cast(1 as bigint)) AS id#276L][0m
[0m[[0minfo[0m] [0m      +- Project [(id#0L + cast(1 as bigint)) AS id#273L][0m
[0m[[0minfo[0m] [0m         +- Range (1, 100000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== Analyzed Logical Plan ==[0m
[0m[[0minfo[0m] [0mid: bigint[0m
[0m[[0minfo[0m] [0mProject [(id#279L + cast(1 as bigint)) AS id#282L][0m
[0m[[0minfo[0m] [0m+- Project [(id#276L + cast(1 as bigint)) AS id#279L][0m
[0m[[0minfo[0m] [0m   +- Project [(id#273L + cast(1 as bigint)) AS id#276L][0m
[0m[[0minfo[0m] [0m      +- Project [(id#0L + cast(1 as bigint)) AS id#273L][0m
[0m[[0minfo[0m] [0m         +- Range (1, 100000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== Optimized Logical Plan ==[0m
[0m[[0minfo[0m] [0mProject [((((id#0L + 1) + 1) + 1) + 1) AS id#282L][0m
[0m[[0minfo[0m] [0m+- Range (1, 100000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== Physical Plan ==[0m
[0m[[0minfo[0m] [0m*Project [((((id#0L + 1) + 1) + 1) + 1) AS id#282L][0m
[0m[[0minfo[0m] [0m+- *Range (1, 100000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== Query45: DF: back-to-back maps ==[0m
[0m[[0minfo[0m] [0mProject [(id#293L + cast(1 as bigint)) AS id#296L][0m
[0m[[0minfo[0m] [0m+- Project [(id#290L + cast(1 as bigint)) AS id#293L][0m
[0m[[0minfo[0m] [0m   +- Project [(id#287L + cast(1 as bigint)) AS id#290L][0m
[0m[[0minfo[0m] [0m      +- Project [(id#0L + cast(1 as bigint)) AS id#287L][0m
[0m[[0minfo[0m] [0m         +- Range (1, 100000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m     [0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== RDD: back-to-back maps ==[0m
[0m[[0minfo[0m] [0m(4) MapPartitionsRDD[14] at map at DatasetPerformance.scala:99 [][0m
[0m[[0minfo[0m] [0m  MapPartitionsRDD[13] at map at DatasetPerformance.scala:98 [][0m
[0m[[0minfo[0m] [0m  MapPartitionsRDD[12] at map at DatasetPerformance.scala:97 [][0m
[0m[[0minfo[0m] [0m  MapPartitionsRDD[11] at map at DatasetPerformance.scala:96 [][0m
[0m[[0minfo[0m] [0m  MapPartitionsRDD[10] at map at DatasetPerformance.scala:95 [][0m
[0m[[0minfo[0m] [0m  MapPartitionsRDD[1] at range at DatasetPerformance.scala:32 [][0m
[0m[[0minfo[0m] [0m  ParallelCollectionRDD[0] at range at DatasetPerformance.scala:32 [][0m
[0m[[0minfo[0m] [0m       [0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== Query78: DS: average ==[0m
[0m[[0minfo[0m] [0m Can't be analyzed: org.apache.spark.sql.AnalysisException: cannot resolve '`sum`' given input columns: [id];[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m [0m
[0m[[0minfo[0m] [0m         [0m
[0m[[31merror[0m] [0m16/06/07 19:49:16 INFO SparkSqlParser: Parsing command: avg(id)[0m
[0m[[0minfo[0m] [0m== Parsed Logical Plan ==[0m
[0m[[0minfo[0m] [0m'Project [unresolvedalias('avg('id), Some(<function1>))][0m
[0m[[0minfo[0m] [0m+- Range (1, 1000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== Analyzed Logical Plan ==[0m
[0m[[0minfo[0m] [0mavg(id): double[0m
[0m[[0minfo[0m] [0mAggregate [avg(id#3L) AS avg(id)#308][0m
[0m[[0minfo[0m] [0m+- Range (1, 1000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== Optimized Logical Plan ==[0m
[0m[[0minfo[0m] [0mAggregate [avg(id#3L) AS avg(id)#308][0m
[0m[[0minfo[0m] [0m+- Range (1, 1000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== Physical Plan ==[0m
[0m[[0minfo[0m] [0m*TungstenAggregate(key=[], functions=[avg(id#3L)], output=[avg(id)#308])[0m
[0m[[0minfo[0m] [0m+- Exchange SinglePartition, None[0m
[0m[[0minfo[0m] [0m   +- *TungstenAggregate(key=[], functions=[partial_avg(id#3L)], output=[sum#312,count#313L])[0m
[0m[[0minfo[0m] [0m      +- *Range (1, 1000000, splits=4)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:16 INFO SparkSqlParser: Parsing command: avg(id)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== Query45: DF: average ==[0m
[0m[[0minfo[0m] [0mAggregate [avg(id#3L) AS avg(id)#320][0m
[0m[[0minfo[0m] [0m+- Range (1, 1000000, splits=4)[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m     [0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m== RDD: average ==[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0m       [0m
[0m[[0minfo[0m] [0m== STARTING EXPERIMENT ==[0m
[0m[[31merror[0m] [0m16/06/07 19:49:16 INFO SparkSqlParser: Parsing command: id % 100 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:49:16 INFO SparkSqlParser: Parsing command: id % 101 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:49:16 INFO SparkSqlParser: Parsing command: id % 102 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:49:16 INFO SparkSqlParser: Parsing command: id % 103 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:49:17 INFO SparkSqlParser: Parsing command: avg(id)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:17 INFO ContextCleaner: Cleaned accumulator 0[0m
[0m[[31merror[0m] [0m16/06/07 19:49:17 INFO ContextCleaner: Cleaned accumulator 1[0m
[0m[[31merror[0m] [0m16/06/07 19:49:17 INFO ContextCleaner: Cleaned accumulator 2[0m
[0m[[31merror[0m] [0m16/06/07 19:49:17 INFO ContextCleaner: Cleaned accumulator 3[0m
[0m[[31merror[0m] [0m16/06/07 19:49:17 INFO SparkSqlParser: Parsing command: id % 100 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:49:17 INFO SparkSqlParser: Parsing command: id % 101 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:49:17 INFO SparkSqlParser: Parsing command: id % 102 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:49:17 INFO SparkSqlParser: Parsing command: id % 103 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:49:17 INFO SparkSqlParser: Parsing command: avg(id)[0m
[0m[[0minfo[0m] [0mRunning execution DS: range iteration: 1, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:49:17 INFO CodeGenerator: Code generated in 284.637731 ms[0m
[0m[[31merror[0m] [0m16/06/07 19:49:17 INFO SparkContext: Starting job: foreach at Query.scala:127[0m
[0m[[31merror[0m] [0m16/06/07 19:49:17 INFO DAGScheduler: Got job 0 (foreach at Query.scala:127) with 4 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:49:17 INFO DAGScheduler: Final stage: ResultStage 0 (foreach at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:17 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:49:17 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:49:17 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[19] at rdd at Query.scala:127), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:49:18 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 9.9 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:18 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.1 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:18 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.54.31:33061 (size: 5.1 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:18 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:49:18 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 0 (MapPartitionsRDD[19] at rdd at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:18 INFO TaskSchedulerImpl: Adding task set 0.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:49:18 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5485 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:18 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1, PROCESS_LOCAL, 5485 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:18 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, partition 2, PROCESS_LOCAL, 5485 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:18 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, partition 3, PROCESS_LOCAL, 5485 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:18 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:18 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:18 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:18 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:18 INFO CodeGenerator: Code generated in 19.468882 ms[0m
[0m[[31merror[0m] [0m16/06/07 19:49:22 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1222 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:49:22 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 4363 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:22 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:49:22 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 4496 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:22 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:49:22 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:49:22 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 4599 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:22 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 4598 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:22 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:49:22 INFO DAGScheduler: ResultStage 0 (foreach at Query.scala:127) finished in 4.711 s[0m
[0m[[31merror[0m] [0m16/06/07 19:49:22 INFO DAGScheduler: Job 0 finished: foreach at Query.scala:127, took 4.993742 s[0m
[0m[[31merror[0m] [0m16/06/07 19:49:23 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 172.16.54.31:33061 in memory (size: 5.1 KB, free: 2.4 GB)[0m
[0m[[0minfo[0m] [0mExecution time: 5.411379155s[0m
[0m[[0minfo[0m] [0mRunning execution DF: range iteration: 1, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:49:23 WARN BlockManager: Asked to remove block broadcast_0_piece0, which does not exist[0m
[0m[[31merror[0m] [0m16/06/07 19:49:23 INFO ContextCleaner: Cleaned accumulator 5[0m
[0m[[31merror[0m] [0m16/06/07 19:49:23 INFO ContextCleaner: Cleaned accumulator 4[0m
[0m[[31merror[0m] [0m16/06/07 19:49:23 INFO SparkContext: Starting job: foreach at Query.scala:127[0m
[0m[[31merror[0m] [0m16/06/07 19:49:23 INFO DAGScheduler: Got job 1 (foreach at Query.scala:127) with 4 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:49:23 INFO DAGScheduler: Final stage: ResultStage 1 (foreach at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:23 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:49:23 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:49:23 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[24] at rdd at Query.scala:127), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:49:23 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 9.9 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:23 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.1 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:23 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.54.31:33061 (size: 5.1 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:23 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:49:23 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 1 (MapPartitionsRDD[24] at rdd at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:23 INFO TaskSchedulerImpl: Adding task set 1.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:49:23 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5485 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:23 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 5, localhost, partition 1, PROCESS_LOCAL, 5485 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:23 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 6, localhost, partition 2, PROCESS_LOCAL, 5485 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:23 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 7, localhost, partition 3, PROCESS_LOCAL, 5485 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:23 INFO Executor: Running task 2.0 in stage 1.0 (TID 6)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:23 INFO Executor: Running task 1.0 in stage 1.0 (TID 5)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:23 INFO Executor: Running task 0.0 in stage 1.0 (TID 4)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:23 INFO Executor: Running task 3.0 in stage 1.0 (TID 7)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:26 INFO Executor: Finished task 1.0 in stage 1.0 (TID 5). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:49:26 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 5) in 3658 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:26 INFO Executor: Finished task 0.0 in stage 1.0 (TID 4). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:49:26 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 4) in 3672 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:26 INFO Executor: Finished task 3.0 in stage 1.0 (TID 7). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:49:26 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 7) in 3710 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:26 INFO Executor: Finished task 2.0 in stage 1.0 (TID 6). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:49:26 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 6) in 3800 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:26 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:49:26 INFO DAGScheduler: ResultStage 1 (foreach at Query.scala:127) finished in 3.803 s[0m
[0m[[31merror[0m] [0m16/06/07 19:49:26 INFO DAGScheduler: Job 1 finished: foreach at Query.scala:127, took 3.815413 s[0m
[0m[[0minfo[0m] [0mExecution time: 3.840861593s[0m
[0m[[0minfo[0m] [0mRunning execution RDD: range iteration: 1, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:49:27 WARN BlockManager: Asked to remove block broadcast_1_piece0, which does not exist[0m
[0m[[31merror[0m] [0m16/06/07 19:49:27 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.16.54.31:33061 in memory (size: 5.1 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:27 INFO ContextCleaner: Cleaned accumulator 116[0m
[0m[[31merror[0m] [0m16/06/07 19:49:27 INFO ContextCleaner: Cleaned accumulator 117[0m
[0m[[31merror[0m] [0m16/06/07 19:49:27 INFO SparkContext: Starting job: count at Benchmark.scala:455[0m
[0m[[31merror[0m] [0m16/06/07 19:49:27 INFO DAGScheduler: Got job 2 (count at Benchmark.scala:455) with 4 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:49:27 INFO DAGScheduler: Final stage: ResultStage 2 (count at Benchmark.scala:455)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:27 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:49:27 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:49:27 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[4] at map at DatasetPerformance.scala:51), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:49:27 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 2.9 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:27 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 1860.0 B, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:27 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.54.31:33061 (size: 1860.0 B, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:27 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:49:27 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 2 (MapPartitionsRDD[4] at map at DatasetPerformance.scala:51)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:27 INFO TaskSchedulerImpl: Adding task set 2.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:49:27 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 8, localhost, partition 0, PROCESS_LOCAL, 5403 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:27 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 9, localhost, partition 1, PROCESS_LOCAL, 5403 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:27 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 10, localhost, partition 2, PROCESS_LOCAL, 5403 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:27 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 11, localhost, partition 3, PROCESS_LOCAL, 5403 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:27 INFO Executor: Running task 2.0 in stage 2.0 (TID 10)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:27 INFO Executor: Running task 1.0 in stage 2.0 (TID 9)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:27 INFO Executor: Running task 0.0 in stage 2.0 (TID 8)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:27 INFO Executor: Running task 3.0 in stage 2.0 (TID 11)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:28 INFO Executor: Finished task 3.0 in stage 2.0 (TID 11). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:49:28 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 11) in 1127 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:28 INFO Executor: Finished task 0.0 in stage 2.0 (TID 8). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:49:28 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 8) in 1138 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:28 INFO Executor: Finished task 2.0 in stage 2.0 (TID 10). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:49:28 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 10) in 1156 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:28 INFO Executor: Finished task 1.0 in stage 2.0 (TID 9). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:49:28 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 9) in 1194 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:28 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:49:28 INFO DAGScheduler: ResultStage 2 (count at Benchmark.scala:455) finished in 1.196 s[0m
[0m[[31merror[0m] [0m16/06/07 19:49:28 INFO DAGScheduler: Job 2 finished: count at Benchmark.scala:455, took 1.206790 s[0m
[0m[[31merror[0m] [0m16/06/07 19:49:28 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 172.16.54.31:33061 in memory (size: 1860.0 B, free: 2.4 GB)[0m
[0m[[0minfo[0m] [0mExecution time: 1.2134211270000002s[0m
[0m[[0minfo[0m] [0mRunning execution DS: back-to-back filters iteration: 1, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:49:28 WARN BlockManager: Asked to remove block broadcast_2_piece0, which does not exist[0m
[0m[[31merror[0m] [0m16/06/07 19:49:28 INFO CodeGenerator: Code generated in 30.026481 ms[0m
[0m[[31merror[0m] [0m16/06/07 19:49:28 INFO SparkContext: Starting job: foreach at Query.scala:127[0m
[0m[[31merror[0m] [0m16/06/07 19:49:28 INFO DAGScheduler: Got job 3 (foreach at Query.scala:127) with 4 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:49:28 INFO DAGScheduler: Final stage: ResultStage 3 (foreach at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:28 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:49:28 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:49:28 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[29] at rdd at Query.scala:127), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:49:28 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 18.9 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:28 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.9 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:28 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.54.31:33061 (size: 7.9 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:28 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:49:28 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 3 (MapPartitionsRDD[29] at rdd at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:28 INFO TaskSchedulerImpl: Adding task set 3.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:49:28 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 12, localhost, partition 0, PROCESS_LOCAL, 5500 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:28 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 13, localhost, partition 1, PROCESS_LOCAL, 5500 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:28 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 14, localhost, partition 2, PROCESS_LOCAL, 5500 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:28 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 15, localhost, partition 3, PROCESS_LOCAL, 5500 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:28 INFO Executor: Running task 1.0 in stage 3.0 (TID 13)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:28 INFO Executor: Running task 0.0 in stage 3.0 (TID 12)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:28 INFO Executor: Running task 2.0 in stage 3.0 (TID 14)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:28 INFO Executor: Running task 3.0 in stage 3.0 (TID 15)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:28 INFO CodeGenerator: Code generated in 27.235401 ms[0m
[0m[[31merror[0m] [0m16/06/07 19:49:32 INFO Executor: Finished task 2.0 in stage 3.0 (TID 14). 1197 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:49:32 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 14) in 4109 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:32 INFO Executor: Finished task 1.0 in stage 3.0 (TID 13). 1197 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:49:32 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 13) in 4139 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:32 INFO Executor: Finished task 3.0 in stage 3.0 (TID 15). 1197 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:49:32 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 15) in 4209 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:32 INFO Executor: Finished task 0.0 in stage 3.0 (TID 12). 1197 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:49:32 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 12) in 4218 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:32 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:49:32 INFO DAGScheduler: ResultStage 3 (foreach at Query.scala:127) finished in 4.218 s[0m
[0m[[31merror[0m] [0m16/06/07 19:49:32 INFO DAGScheduler: Job 3 finished: foreach at Query.scala:127, took 4.251805 s[0m
[0m[[0minfo[0m] [0mExecution time: 4.337064718s[0m
[0m[[0minfo[0m] [0mRunning execution DF: back-to-back filters iteration: 1, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:49:32 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.16.54.31:33061 in memory (size: 7.9 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:32 INFO SparkSqlParser: Parsing command: id % 100 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:49:32 INFO ContextCleaner: Cleaned accumulator 338[0m
[0m[[31merror[0m] [0m16/06/07 19:49:32 INFO ContextCleaner: Cleaned accumulator 339[0m
[0m[[31merror[0m] [0m16/06/07 19:49:32 INFO ContextCleaner: Cleaned accumulator 340[0m
[0m[[31merror[0m] [0m16/06/07 19:49:32 INFO SparkSqlParser: Parsing command: id % 101 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:49:32 INFO SparkSqlParser: Parsing command: id % 102 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:49:32 INFO SparkSqlParser: Parsing command: id % 103 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:49:32 INFO SparkSqlParser: Parsing command: id % 100 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:49:32 INFO SparkSqlParser: Parsing command: id % 101 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:49:32 INFO SparkSqlParser: Parsing command: id % 102 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:49:32 INFO SparkSqlParser: Parsing command: id % 103 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:49:32 INFO CodeGenerator: Code generated in 26.552409 ms[0m
[0m[[31merror[0m] [0m16/06/07 19:49:32 INFO SparkContext: Starting job: foreach at Query.scala:127[0m
[0m[[31merror[0m] [0m16/06/07 19:49:32 INFO DAGScheduler: Got job 4 (foreach at Query.scala:127) with 4 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:49:32 INFO DAGScheduler: Final stage: ResultStage 4 (foreach at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:32 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:49:32 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:49:32 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[34] at rdd at Query.scala:127), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:49:32 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 15.0 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:32 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.7 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:32 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.16.54.31:33061 (size: 6.7 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:32 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:49:32 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 4 (MapPartitionsRDD[34] at rdd at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:32 INFO TaskSchedulerImpl: Adding task set 4.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:49:32 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 16, localhost, partition 0, PROCESS_LOCAL, 5500 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:32 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 17, localhost, partition 1, PROCESS_LOCAL, 5500 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:32 INFO TaskSetManager: Starting task 2.0 in stage 4.0 (TID 18, localhost, partition 2, PROCESS_LOCAL, 5500 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:32 INFO TaskSetManager: Starting task 3.0 in stage 4.0 (TID 19, localhost, partition 3, PROCESS_LOCAL, 5500 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:32 INFO Executor: Running task 1.0 in stage 4.0 (TID 17)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:32 INFO Executor: Running task 0.0 in stage 4.0 (TID 16)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:32 INFO Executor: Running task 3.0 in stage 4.0 (TID 19)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:32 INFO Executor: Running task 2.0 in stage 4.0 (TID 18)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:36 INFO Executor: Finished task 0.0 in stage 4.0 (TID 16). 1197 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:49:36 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 16) in 3704 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:36 INFO Executor: Finished task 2.0 in stage 4.0 (TID 18). 1197 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:49:36 INFO TaskSetManager: Finished task 2.0 in stage 4.0 (TID 18) in 3825 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:36 INFO Executor: Finished task 1.0 in stage 4.0 (TID 17). 1197 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:49:36 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 17) in 3888 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:36 INFO Executor: Finished task 3.0 in stage 4.0 (TID 19). 1197 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:49:36 INFO TaskSetManager: Finished task 3.0 in stage 4.0 (TID 19) in 3926 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:36 INFO DAGScheduler: ResultStage 4 (foreach at Query.scala:127) finished in 3.929 s[0m
[0m[[31merror[0m] [0m16/06/07 19:49:36 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:49:36 INFO DAGScheduler: Job 4 finished: foreach at Query.scala:127, took 3.953461 s[0m
[0m[[31merror[0m] [0m16/06/07 19:49:36 INFO SparkSqlParser: Parsing command: id % 100 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:49:36 INFO SparkSqlParser: Parsing command: id % 101 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:49:36 INFO SparkSqlParser: Parsing command: id % 102 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:49:36 INFO SparkSqlParser: Parsing command: id % 103 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:49:36 INFO ContextCleaner: Cleaned accumulator 451[0m
[0m[[31merror[0m] [0m16/06/07 19:49:36 INFO ContextCleaner: Cleaned accumulator 452[0m
[0m[[31merror[0m] [0m16/06/07 19:49:36 INFO ContextCleaner: Cleaned accumulator 453[0m
[0m[[0minfo[0m] [0mExecution time: 4.010398432s[0m
[0m[[0minfo[0m] [0mRunning execution RDD: back-to-back filters iteration: 1, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:49:36 INFO SparkContext: Starting job: count at Benchmark.scala:455[0m
[0m[[31merror[0m] [0m16/06/07 19:49:36 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.16.54.31:33061 in memory (size: 6.7 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:36 INFO DAGScheduler: Got job 5 (count at Benchmark.scala:455) with 4 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:49:36 INFO DAGScheduler: Final stage: ResultStage 5 (count at Benchmark.scala:455)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:36 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:49:36 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:49:36 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[9] at filter at DatasetPerformance.scala:75), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:49:36 WARN BlockManager: Asked to remove block broadcast_4_piece0, which does not exist[0m
[0m[[31merror[0m] [0m16/06/07 19:49:36 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 3.5 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:36 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 1991.0 B, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:36 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.54.31:33061 (size: 1991.0 B, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:37 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:49:37 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 5 (MapPartitionsRDD[9] at filter at DatasetPerformance.scala:75)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:37 INFO TaskSchedulerImpl: Adding task set 5.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:49:37 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 20, localhost, partition 0, PROCESS_LOCAL, 5418 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:37 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 21, localhost, partition 1, PROCESS_LOCAL, 5418 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:37 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 22, localhost, partition 2, PROCESS_LOCAL, 5418 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:37 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 23, localhost, partition 3, PROCESS_LOCAL, 5418 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:37 INFO Executor: Running task 0.0 in stage 5.0 (TID 20)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:37 INFO Executor: Running task 1.0 in stage 5.0 (TID 21)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:37 INFO Executor: Running task 2.0 in stage 5.0 (TID 22)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:37 INFO Executor: Running task 3.0 in stage 5.0 (TID 23)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:40 INFO Executor: Finished task 1.0 in stage 5.0 (TID 21). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:49:40 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 21) in 3471 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:40 INFO Executor: Finished task 2.0 in stage 5.0 (TID 22). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:49:40 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 22) in 3838 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:41 INFO Executor: Finished task 0.0 in stage 5.0 (TID 20). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:49:41 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 20) in 4036 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:41 INFO Executor: Finished task 3.0 in stage 5.0 (TID 23). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:49:41 INFO TaskSetManager: Finished task 3.0 in stage 5.0 (TID 23) in 4132 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:41 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:49:41 INFO DAGScheduler: ResultStage 5 (count at Benchmark.scala:455) finished in 4.136 s[0m
[0m[[31merror[0m] [0m16/06/07 19:49:41 INFO DAGScheduler: Job 5 finished: count at Benchmark.scala:455, took 4.145470 s[0m
[0m[[0minfo[0m] [0mExecution time: 4.149787571s[0m
[0m[[0minfo[0m] [0mRunning execution DS: back-to-back maps iteration: 1, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:49:41 WARN BlockManager: Asked to remove block broadcast_5_piece0, which does not exist[0m
[0m[[31merror[0m] [0m16/06/07 19:49:41 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 172.16.54.31:33061 in memory (size: 1991.0 B, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:41 INFO CodeGenerator: Code generated in 22.764011 ms[0m
[0m[[31merror[0m] [0m16/06/07 19:49:41 INFO SparkContext: Starting job: foreach at Query.scala:127[0m
[0m[[31merror[0m] [0m16/06/07 19:49:41 INFO DAGScheduler: Got job 6 (foreach at Query.scala:127) with 4 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:49:41 INFO DAGScheduler: Final stage: ResultStage 6 (foreach at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:41 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:49:41 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:49:41 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[39] at rdd at Query.scala:127), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:49:41 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 21.3 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:41 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 8.0 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:41 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.16.54.31:33061 (size: 8.0 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:41 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:49:41 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 6 (MapPartitionsRDD[39] at rdd at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:41 INFO TaskSchedulerImpl: Adding task set 6.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:49:41 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 24, localhost, partition 0, PROCESS_LOCAL, 5497 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:41 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 25, localhost, partition 1, PROCESS_LOCAL, 5497 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:41 INFO TaskSetManager: Starting task 2.0 in stage 6.0 (TID 26, localhost, partition 2, PROCESS_LOCAL, 5497 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:41 INFO TaskSetManager: Starting task 3.0 in stage 6.0 (TID 27, localhost, partition 3, PROCESS_LOCAL, 5497 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:41 INFO Executor: Running task 1.0 in stage 6.0 (TID 25)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:41 INFO Executor: Running task 0.0 in stage 6.0 (TID 24)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:41 INFO Executor: Running task 2.0 in stage 6.0 (TID 26)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:41 INFO Executor: Running task 3.0 in stage 6.0 (TID 27)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:45 INFO Executor: Finished task 0.0 in stage 6.0 (TID 24). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:49:45 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 24) in 3722 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:45 INFO Executor: Finished task 1.0 in stage 6.0 (TID 25). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:49:45 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 25) in 3825 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:45 INFO Executor: Finished task 2.0 in stage 6.0 (TID 26). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:49:45 INFO TaskSetManager: Finished task 2.0 in stage 6.0 (TID 26) in 3832 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:45 INFO Executor: Finished task 3.0 in stage 6.0 (TID 27). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:49:45 INFO TaskSetManager: Finished task 3.0 in stage 6.0 (TID 27) in 3882 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:45 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:49:45 INFO DAGScheduler: ResultStage 6 (foreach at Query.scala:127) finished in 3.887 s[0m
[0m[[31merror[0m] [0m16/06/07 19:49:45 INFO DAGScheduler: Job 6 finished: foreach at Query.scala:127, took 3.899221 s[0m
[0m[[31merror[0m] [0m16/06/07 19:49:45 INFO ContextCleaner: Cleaned accumulator 674[0m
[0m[[0minfo[0m] [0mExecution time: 3.9517472s[0m
[0m[[0minfo[0m] [0mRunning execution DF: back-to-back maps iteration: 1, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:49:45 WARN BlockManager: Asked to remove block broadcast_6_piece0, which does not exist[0m
[0m[[31merror[0m] [0m16/06/07 19:49:45 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 172.16.54.31:33061 in memory (size: 8.0 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:45 INFO ContextCleaner: Cleaned accumulator 675[0m
[0m[[31merror[0m] [0m16/06/07 19:49:45 INFO CodeGenerator: Code generated in 15.015607 ms[0m
[0m[[31merror[0m] [0m16/06/07 19:49:45 INFO SparkContext: Starting job: foreach at Query.scala:127[0m
[0m[[31merror[0m] [0m16/06/07 19:49:45 INFO DAGScheduler: Got job 7 (foreach at Query.scala:127) with 4 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:49:45 INFO DAGScheduler: Final stage: ResultStage 7 (foreach at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:45 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:49:45 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:49:45 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[44] at rdd at Query.scala:127), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:49:45 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 12.0 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:45 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 5.9 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:45 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.16.54.31:33061 (size: 5.9 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:45 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:49:45 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 7 (MapPartitionsRDD[44] at rdd at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:45 INFO TaskSchedulerImpl: Adding task set 7.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:49:45 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 28, localhost, partition 0, PROCESS_LOCAL, 5497 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:45 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 29, localhost, partition 1, PROCESS_LOCAL, 5497 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:45 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 30, localhost, partition 2, PROCESS_LOCAL, 5497 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:45 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 31, localhost, partition 3, PROCESS_LOCAL, 5497 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:45 INFO Executor: Running task 0.0 in stage 7.0 (TID 28)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:45 INFO Executor: Running task 1.0 in stage 7.0 (TID 29)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:45 INFO Executor: Running task 2.0 in stage 7.0 (TID 30)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:45 INFO Executor: Running task 3.0 in stage 7.0 (TID 31)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:49 INFO Executor: Finished task 0.0 in stage 7.0 (TID 28). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:49:49 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 28) in 3663 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:49 INFO Executor: Finished task 1.0 in stage 7.0 (TID 29). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:49:49 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 29) in 3725 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:49 INFO Executor: Finished task 3.0 in stage 7.0 (TID 31). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:49:49 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 31) in 3851 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:49 INFO Executor: Finished task 2.0 in stage 7.0 (TID 30). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:49:49 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 30) in 3903 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:49 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:49:49 INFO DAGScheduler: ResultStage 7 (foreach at Query.scala:127) finished in 3.894 s[0m
[0m[[31merror[0m] [0m16/06/07 19:49:49 INFO DAGScheduler: Job 7 finished: foreach at Query.scala:127, took 3.926009 s[0m
[0m[[0minfo[0m] [0mExecution time: 3.9664025740000004s[0m
[0m[[0minfo[0m] [0mRunning execution RDD: back-to-back maps iteration: 1, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:49:49 WARN BlockManager: Asked to remove block broadcast_7_piece0, which does not exist[0m
[0m[[31merror[0m] [0m16/06/07 19:49:49 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 172.16.54.31:33061 in memory (size: 5.9 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:49 INFO ContextCleaner: Cleaned accumulator 786[0m
[0m[[31merror[0m] [0m16/06/07 19:49:49 INFO ContextCleaner: Cleaned accumulator 787[0m
[0m[[31merror[0m] [0m16/06/07 19:49:49 INFO SparkContext: Starting job: count at Benchmark.scala:455[0m
[0m[[31merror[0m] [0m16/06/07 19:49:49 INFO DAGScheduler: Got job 8 (count at Benchmark.scala:455) with 4 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:49:49 INFO DAGScheduler: Final stage: ResultStage 8 (count at Benchmark.scala:455)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:49 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:49:49 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:49:49 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[14] at map at DatasetPerformance.scala:99), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:49:49 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 3.4 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:49 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 1990.0 B, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:49 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.16.54.31:33061 (size: 1990.0 B, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:49 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:49:49 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 8 (MapPartitionsRDD[14] at map at DatasetPerformance.scala:99)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:49 INFO TaskSchedulerImpl: Adding task set 8.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:49:49 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 32, localhost, partition 0, PROCESS_LOCAL, 5415 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:49 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 33, localhost, partition 1, PROCESS_LOCAL, 5415 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:49 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 34, localhost, partition 2, PROCESS_LOCAL, 5415 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:49 INFO TaskSetManager: Starting task 3.0 in stage 8.0 (TID 35, localhost, partition 3, PROCESS_LOCAL, 5415 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:49 INFO Executor: Running task 0.0 in stage 8.0 (TID 32)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:49 INFO Executor: Running task 2.0 in stage 8.0 (TID 34)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:49 INFO Executor: Running task 1.0 in stage 8.0 (TID 33)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:49 INFO Executor: Running task 3.0 in stage 8.0 (TID 35)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO Executor: Finished task 3.0 in stage 8.0 (TID 35). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO TaskSetManager: Finished task 3.0 in stage 8.0 (TID 35) in 4669 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO Executor: Finished task 2.0 in stage 8.0 (TID 34). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO TaskSetManager: Finished task 2.0 in stage 8.0 (TID 34) in 4702 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO Executor: Finished task 0.0 in stage 8.0 (TID 32). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 32) in 4725 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO Executor: Finished task 1.0 in stage 8.0 (TID 33). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 33) in 4787 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO DAGScheduler: ResultStage 8 (count at Benchmark.scala:455) finished in 4.788 s[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO DAGScheduler: Job 8 finished: count at Benchmark.scala:455, took 4.797433 s[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 WARN BlockManager: Asked to remove block broadcast_8_piece0, which does not exist[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 172.16.54.31:33061 in memory (size: 1990.0 B, free: 2.4 GB)[0m
[0m[[0minfo[0m] [0mExecution time: 4.8006115739999995s[0m
[0m[[0minfo[0m] [0mRunning execution DS: average iteration: 1, StandardRun=true[0m
[0m[[0minfo[0m] [0mExecution 'DS: average' failed: cannot resolve '`sum`' given input columns: [id];[0m
[0m[[0minfo[0m] [0mRunning execution DF: average iteration: 1, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO SparkSqlParser: Parsing command: avg(id)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO SparkSqlParser: Parsing command: avg(id)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO CodeGenerator: Code generated in 9.386461 ms[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO CodeGenerator: Code generated in 20.429442 ms[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO SparkContext: Starting job: collect at Query.scala:126[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO DAGScheduler: Registering RDD 48 (rdd at Query.scala:126)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO DAGScheduler: Got job 9 (collect at Query.scala:126) with 1 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO DAGScheduler: Final stage: ResultStage 10 (collect at Query.scala:126)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[48] at rdd at Query.scala:126), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 12.4 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 5.9 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.16.54.31:33061 (size: 5.9 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[48] at rdd at Query.scala:126)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO TaskSchedulerImpl: Adding task set 9.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 36, localhost, partition 0, PROCESS_LOCAL, 5477 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 37, localhost, partition 1, PROCESS_LOCAL, 5477 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO TaskSetManager: Starting task 2.0 in stage 9.0 (TID 38, localhost, partition 2, PROCESS_LOCAL, 5477 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO TaskSetManager: Starting task 3.0 in stage 9.0 (TID 39, localhost, partition 3, PROCESS_LOCAL, 5477 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO Executor: Running task 0.0 in stage 9.0 (TID 36)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO Executor: Running task 2.0 in stage 9.0 (TID 38)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO Executor: Running task 3.0 in stage 9.0 (TID 39)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO Executor: Running task 1.0 in stage 9.0 (TID 37)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO Executor: Finished task 1.0 in stage 9.0 (TID 37). 1726 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO Executor: Finished task 0.0 in stage 9.0 (TID 36). 1639 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO Executor: Finished task 2.0 in stage 9.0 (TID 38). 1639 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 36) in 69 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 37) in 67 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO TaskSetManager: Finished task 2.0 in stage 9.0 (TID 38) in 68 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO Executor: Finished task 3.0 in stage 9.0 (TID 39). 1639 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO TaskSetManager: Finished task 3.0 in stage 9.0 (TID 39) in 70 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO DAGScheduler: ShuffleMapStage 9 (rdd at Query.scala:126) finished in 0.074 s[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO DAGScheduler: looking for newly runnable stages[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO DAGScheduler: running: Set()[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO DAGScheduler: waiting: Set(ResultStage 10)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO DAGScheduler: failed: Set()[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[52] at rdd at Query.scala:126), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 19.0 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 9.1 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.16.54.31:33061 (size: 9.1 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[52] at rdd at Query.scala:126)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 40, localhost, partition 0, ANY, 5389 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO Executor: Running task 0.0 in stage 10.0 (TID 40)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO CodeGenerator: Code generated in 16.200409 ms[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO Executor: Finished task 0.0 in stage 10.0 (TID 40). 3616 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 40) in 63 ms on localhost (1/1)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO DAGScheduler: ResultStage 10 (collect at Query.scala:126) finished in 0.059 s[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO DAGScheduler: Job 9 finished: collect at Query.scala:126, took 0.174127 s[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO SparkSqlParser: Parsing command: avg(id)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 172.16.54.31:33061 in memory (size: 9.1 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 172.16.54.31:33061 in memory (size: 5.9 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 WARN BlockManager: Asked to remove block broadcast_9_piece0, which does not exist[0m
[0m[[0minfo[0m] [0mExecution time: 0.293341033s[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO ContextCleaner: Cleaned accumulator 1008[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO ContextCleaner: Cleaned accumulator 1009[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO ContextCleaner: Cleaned accumulator 1010[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO ContextCleaner: Cleaned accumulator 1011[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO ContextCleaner: Cleaned accumulator 1012[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO ContextCleaner: Cleaned accumulator 1013[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO ContextCleaner: Cleaned accumulator 1014[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO ContextCleaner: Cleaned accumulator 1015[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO ContextCleaner: Cleaned accumulator 1016[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO ContextCleaner: Cleaned accumulator 1017[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO ContextCleaner: Cleaned accumulator 1018[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO ContextCleaner: Cleaned accumulator 1019[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO ContextCleaner: Cleaned accumulator 1020[0m
[0m[[0minfo[0m] [0mRunning execution RDD: average iteration: 1, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO ContextCleaner: Cleaned accumulator 1021[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO ContextCleaner: Cleaned accumulator 1022[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO ContextCleaner: Cleaned accumulator 1023[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO ContextCleaner: Cleaned accumulator 1024[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO ContextCleaner: Cleaned shuffle 0[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO SparkContext: Starting job: reduce at DatasetPerformance.scala:139[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO DAGScheduler: Got job 10 (reduce at DatasetPerformance.scala:139) with 4 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO DAGScheduler: Final stage: ResultStage 11 (reduce at DatasetPerformance.scala:139)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[53] at map at DatasetPerformance.scala:139), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 2.9 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 1858.0 B, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.16.54.31:33061 (size: 1858.0 B, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 11 (MapPartitionsRDD[53] at map at DatasetPerformance.scala:139)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO TaskSchedulerImpl: Adding task set 11.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 41, localhost, partition 0, PROCESS_LOCAL, 5488 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO TaskSetManager: Starting task 1.0 in stage 11.0 (TID 42, localhost, partition 1, PROCESS_LOCAL, 5488 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO TaskSetManager: Starting task 2.0 in stage 11.0 (TID 43, localhost, partition 2, PROCESS_LOCAL, 5488 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO TaskSetManager: Starting task 3.0 in stage 11.0 (TID 44, localhost, partition 3, PROCESS_LOCAL, 5488 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO Executor: Running task 0.0 in stage 11.0 (TID 41)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO Executor: Running task 1.0 in stage 11.0 (TID 42)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO Executor: Running task 2.0 in stage 11.0 (TID 43)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO Executor: Running task 3.0 in stage 11.0 (TID 44)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO Executor: Finished task 1.0 in stage 11.0 (TID 42). 1004 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO TaskSetManager: Finished task 1.0 in stage 11.0 (TID 42) in 82 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO Executor: Finished task 2.0 in stage 11.0 (TID 43). 917 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO Executor: Finished task 3.0 in stage 11.0 (TID 44). 917 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO TaskSetManager: Finished task 2.0 in stage 11.0 (TID 43) in 120 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO TaskSetManager: Finished task 3.0 in stage 11.0 (TID 44) in 121 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO Executor: Finished task 0.0 in stage 11.0 (TID 41). 917 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 41) in 132 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO DAGScheduler: ResultStage 11 (reduce at DatasetPerformance.scala:139) finished in 0.134 s[0m
[0m[[31merror[0m] [0m16/06/07 19:49:54 INFO DAGScheduler: Job 10 finished: reduce at DatasetPerformance.scala:139, took 0.143968 s[0m
[0m[[0minfo[0m] [0mExecution time: 0.164646803s[0m
[0m[[0minfo[0m] [0mRunning execution DS: range iteration: 1, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:49:55 WARN BlockManager: Asked to remove block broadcast_11_piece0, which does not exist[0m
[0m[[31merror[0m] [0m16/06/07 19:49:55 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 172.16.54.31:33061 in memory (size: 1858.0 B, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:55 INFO SparkContext: Starting job: foreach at Query.scala:127[0m
[0m[[31merror[0m] [0m16/06/07 19:49:55 INFO DAGScheduler: Got job 11 (foreach at Query.scala:127) with 4 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:49:55 INFO DAGScheduler: Final stage: ResultStage 12 (foreach at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:55 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:49:55 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:49:55 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[58] at rdd at Query.scala:127), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:49:55 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 9.9 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:55 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 5.1 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:55 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.16.54.31:33061 (size: 5.1 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:55 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:49:55 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 12 (MapPartitionsRDD[58] at rdd at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:55 INFO TaskSchedulerImpl: Adding task set 12.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:49:55 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 45, localhost, partition 0, PROCESS_LOCAL, 5486 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:55 INFO TaskSetManager: Starting task 1.0 in stage 12.0 (TID 46, localhost, partition 1, PROCESS_LOCAL, 5486 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:55 INFO TaskSetManager: Starting task 2.0 in stage 12.0 (TID 47, localhost, partition 2, PROCESS_LOCAL, 5486 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:55 INFO TaskSetManager: Starting task 3.0 in stage 12.0 (TID 48, localhost, partition 3, PROCESS_LOCAL, 5486 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:55 INFO Executor: Running task 0.0 in stage 12.0 (TID 45)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:55 INFO Executor: Running task 2.0 in stage 12.0 (TID 47)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:55 INFO Executor: Running task 1.0 in stage 12.0 (TID 46)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:55 INFO Executor: Running task 3.0 in stage 12.0 (TID 48)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:58 INFO Executor: Finished task 0.0 in stage 12.0 (TID 45). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:49:58 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 45) in 3155 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:58 INFO Executor: Finished task 1.0 in stage 12.0 (TID 46). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:49:58 INFO TaskSetManager: Finished task 1.0 in stage 12.0 (TID 46) in 3309 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:58 INFO Executor: Finished task 3.0 in stage 12.0 (TID 48). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:49:58 INFO TaskSetManager: Finished task 3.0 in stage 12.0 (TID 48) in 3511 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:58 INFO Executor: Finished task 2.0 in stage 12.0 (TID 47). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:49:58 INFO TaskSetManager: Finished task 2.0 in stage 12.0 (TID 47) in 3535 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:58 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:49:58 INFO DAGScheduler: ResultStage 12 (foreach at Query.scala:127) finished in 3.536 s[0m
[0m[[31merror[0m] [0m16/06/07 19:49:58 INFO DAGScheduler: Job 11 finished: foreach at Query.scala:127, took 3.546930 s[0m
[0m[[0minfo[0m] [0mExecution time: 3.5681932240000003s[0m
[0m[[0minfo[0m] [0mRunning execution DF: range iteration: 1, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:49:58 INFO ContextCleaner: Cleaned accumulator 1289[0m
[0m[[31merror[0m] [0m16/06/07 19:49:58 INFO ContextCleaner: Cleaned accumulator 1290[0m
[0m[[31merror[0m] [0m16/06/07 19:49:58 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 172.16.54.31:33061 in memory (size: 5.1 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:58 INFO SparkContext: Starting job: foreach at Query.scala:127[0m
[0m[[31merror[0m] [0m16/06/07 19:49:58 INFO DAGScheduler: Got job 12 (foreach at Query.scala:127) with 4 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:49:58 INFO DAGScheduler: Final stage: ResultStage 13 (foreach at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:58 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:49:58 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:49:58 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[63] at rdd at Query.scala:127), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:49:58 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 9.9 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:58 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 5.1 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:58 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.16.54.31:33061 (size: 5.1 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:58 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:49:58 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 13 (MapPartitionsRDD[63] at rdd at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:58 INFO TaskSchedulerImpl: Adding task set 13.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:49:58 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 49, localhost, partition 0, PROCESS_LOCAL, 5486 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:58 INFO TaskSetManager: Starting task 1.0 in stage 13.0 (TID 50, localhost, partition 1, PROCESS_LOCAL, 5486 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:58 INFO TaskSetManager: Starting task 2.0 in stage 13.0 (TID 51, localhost, partition 2, PROCESS_LOCAL, 5486 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:58 INFO TaskSetManager: Starting task 3.0 in stage 13.0 (TID 52, localhost, partition 3, PROCESS_LOCAL, 5486 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:58 INFO Executor: Running task 0.0 in stage 13.0 (TID 49)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:58 INFO Executor: Running task 1.0 in stage 13.0 (TID 50)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:58 INFO Executor: Running task 2.0 in stage 13.0 (TID 51)[0m
[0m[[31merror[0m] [0m16/06/07 19:49:58 INFO Executor: Running task 3.0 in stage 13.0 (TID 52)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:02 INFO Executor: Finished task 3.0 in stage 13.0 (TID 52). 1222 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:02 INFO TaskSetManager: Finished task 3.0 in stage 13.0 (TID 52) in 3362 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:02 INFO Executor: Finished task 2.0 in stage 13.0 (TID 51). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:02 INFO TaskSetManager: Finished task 2.0 in stage 13.0 (TID 51) in 3463 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:02 INFO Executor: Finished task 0.0 in stage 13.0 (TID 49). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:02 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 49) in 3511 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:02 INFO Executor: Finished task 1.0 in stage 13.0 (TID 50). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:02 INFO TaskSetManager: Finished task 1.0 in stage 13.0 (TID 50) in 3540 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:02 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:50:02 INFO DAGScheduler: ResultStage 13 (foreach at Query.scala:127) finished in 3.540 s[0m
[0m[[31merror[0m] [0m16/06/07 19:50:02 INFO DAGScheduler: Job 12 finished: foreach at Query.scala:127, took 3.547018 s[0m
[0m[[31merror[0m] [0m16/06/07 19:50:02 WARN BlockManager: Asked to remove block broadcast_13_piece0, which does not exist[0m
[0m[[31merror[0m] [0m16/06/07 19:50:02 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 172.16.54.31:33061 in memory (size: 5.1 KB, free: 2.4 GB)[0m
[0m[[0minfo[0m] [0mExecution time: 3.559188665s[0m
[0m[[0minfo[0m] [0mRunning execution RDD: range iteration: 1, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:50:02 INFO SparkContext: Starting job: count at Benchmark.scala:455[0m
[0m[[31merror[0m] [0m16/06/07 19:50:02 INFO DAGScheduler: Got job 13 (count at Benchmark.scala:455) with 4 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:50:02 INFO ContextCleaner: Cleaned accumulator 1401[0m
[0m[[31merror[0m] [0m16/06/07 19:50:02 INFO ContextCleaner: Cleaned accumulator 1402[0m
[0m[[31merror[0m] [0m16/06/07 19:50:02 INFO DAGScheduler: Final stage: ResultStage 14 (count at Benchmark.scala:455)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:02 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:50:02 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:50:02 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[4] at map at DatasetPerformance.scala:51), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:50:02 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 2.9 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:02 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 1860.0 B, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:02 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.16.54.31:33061 (size: 1860.0 B, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:02 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:50:02 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 14 (MapPartitionsRDD[4] at map at DatasetPerformance.scala:51)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:02 INFO TaskSchedulerImpl: Adding task set 14.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:50:02 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 53, localhost, partition 0, PROCESS_LOCAL, 5403 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:02 INFO TaskSetManager: Starting task 1.0 in stage 14.0 (TID 54, localhost, partition 1, PROCESS_LOCAL, 5403 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:02 INFO TaskSetManager: Starting task 2.0 in stage 14.0 (TID 55, localhost, partition 2, PROCESS_LOCAL, 5403 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:02 INFO TaskSetManager: Starting task 3.0 in stage 14.0 (TID 56, localhost, partition 3, PROCESS_LOCAL, 5403 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:02 INFO Executor: Running task 1.0 in stage 14.0 (TID 54)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:02 INFO Executor: Running task 0.0 in stage 14.0 (TID 53)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:02 INFO Executor: Running task 2.0 in stage 14.0 (TID 55)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:02 INFO Executor: Running task 3.0 in stage 14.0 (TID 56)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:03 INFO Executor: Finished task 2.0 in stage 14.0 (TID 55). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:03 INFO TaskSetManager: Finished task 2.0 in stage 14.0 (TID 55) in 1391 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:03 INFO Executor: Finished task 3.0 in stage 14.0 (TID 56). 954 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:03 INFO TaskSetManager: Finished task 3.0 in stage 14.0 (TID 56) in 1400 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:03 INFO Executor: Finished task 0.0 in stage 14.0 (TID 53). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:03 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 53) in 1411 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:03 INFO Executor: Finished task 1.0 in stage 14.0 (TID 54). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:03 INFO TaskSetManager: Finished task 1.0 in stage 14.0 (TID 54) in 1428 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:03 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:50:03 INFO DAGScheduler: ResultStage 14 (count at Benchmark.scala:455) finished in 1.430 s[0m
[0m[[31merror[0m] [0m16/06/07 19:50:03 INFO DAGScheduler: Job 13 finished: count at Benchmark.scala:455, took 1.439257 s[0m
[0m[[31merror[0m] [0m16/06/07 19:50:03 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 172.16.54.31:33061 in memory (size: 1860.0 B, free: 2.4 GB)[0m
[0m[[0minfo[0m] [0mExecution time: 1.4415447979999998s[0m
[0m[[0minfo[0m] [0mRunning execution DS: back-to-back filters iteration: 1, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:50:03 INFO SparkContext: Starting job: foreach at Query.scala:127[0m
[0m[[31merror[0m] [0m16/06/07 19:50:03 INFO DAGScheduler: Got job 14 (foreach at Query.scala:127) with 4 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:50:03 INFO DAGScheduler: Final stage: ResultStage 15 (foreach at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:03 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:50:03 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:50:03 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[68] at rdd at Query.scala:127), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:50:03 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 18.9 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:03 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 7.9 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:03 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 172.16.54.31:33061 (size: 7.9 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:03 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:50:03 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 15 (MapPartitionsRDD[68] at rdd at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:03 INFO TaskSchedulerImpl: Adding task set 15.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:50:03 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 57, localhost, partition 0, PROCESS_LOCAL, 5501 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:03 INFO TaskSetManager: Starting task 1.0 in stage 15.0 (TID 58, localhost, partition 1, PROCESS_LOCAL, 5501 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:03 INFO TaskSetManager: Starting task 2.0 in stage 15.0 (TID 59, localhost, partition 2, PROCESS_LOCAL, 5501 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:03 INFO TaskSetManager: Starting task 3.0 in stage 15.0 (TID 60, localhost, partition 3, PROCESS_LOCAL, 5501 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:03 INFO Executor: Running task 2.0 in stage 15.0 (TID 59)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:03 INFO Executor: Running task 1.0 in stage 15.0 (TID 58)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:03 INFO Executor: Running task 0.0 in stage 15.0 (TID 57)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:03 INFO Executor: Running task 3.0 in stage 15.0 (TID 60)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:07 INFO Executor: Finished task 1.0 in stage 15.0 (TID 58). 1197 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:07 INFO TaskSetManager: Finished task 1.0 in stage 15.0 (TID 58) in 3986 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:07 INFO Executor: Finished task 2.0 in stage 15.0 (TID 59). 1197 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:07 INFO TaskSetManager: Finished task 2.0 in stage 15.0 (TID 59) in 3990 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:08 INFO Executor: Finished task 0.0 in stage 15.0 (TID 57). 1197 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:08 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 57) in 4079 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:08 INFO Executor: Finished task 3.0 in stage 15.0 (TID 60). 1197 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:08 INFO TaskSetManager: Finished task 3.0 in stage 15.0 (TID 60) in 4081 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:08 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:50:08 INFO DAGScheduler: ResultStage 15 (foreach at Query.scala:127) finished in 4.082 s[0m
[0m[[31merror[0m] [0m16/06/07 19:50:08 INFO DAGScheduler: Job 14 finished: foreach at Query.scala:127, took 4.091341 s[0m
[0m[[31merror[0m] [0m16/06/07 19:50:08 WARN BlockManager: Asked to remove block broadcast_15_piece0, which does not exist[0m
[0m[[0minfo[0m] [0mExecution time: 4.118532817999999s[0m
[0m[[31merror[0m] [0m16/06/07 19:50:08 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 172.16.54.31:33061 in memory (size: 7.9 KB, free: 2.4 GB)[0m
[0m[[0minfo[0m] [0mRunning execution DF: back-to-back filters iteration: 1, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:50:08 INFO ContextCleaner: Cleaned accumulator 1623[0m
[0m[[31merror[0m] [0m16/06/07 19:50:08 INFO ContextCleaner: Cleaned accumulator 1624[0m
[0m[[31merror[0m] [0m16/06/07 19:50:08 INFO ContextCleaner: Cleaned accumulator 1625[0m
[0m[[31merror[0m] [0m16/06/07 19:50:08 INFO SparkSqlParser: Parsing command: id % 100 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:50:08 INFO SparkSqlParser: Parsing command: id % 101 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:50:08 INFO SparkSqlParser: Parsing command: id % 102 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:50:08 INFO SparkSqlParser: Parsing command: id % 103 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:50:08 INFO SparkSqlParser: Parsing command: id % 100 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:50:08 INFO SparkSqlParser: Parsing command: id % 101 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:50:08 INFO SparkSqlParser: Parsing command: id % 102 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:50:08 INFO SparkSqlParser: Parsing command: id % 103 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:50:08 INFO SparkContext: Starting job: foreach at Query.scala:127[0m
[0m[[31merror[0m] [0m16/06/07 19:50:08 INFO DAGScheduler: Got job 15 (foreach at Query.scala:127) with 4 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:50:08 INFO DAGScheduler: Final stage: ResultStage 16 (foreach at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:08 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:50:08 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:50:08 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[73] at rdd at Query.scala:127), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:50:08 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 15.0 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:08 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 6.7 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:08 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 172.16.54.31:33061 (size: 6.7 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:08 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:50:08 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 16 (MapPartitionsRDD[73] at rdd at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:08 INFO TaskSchedulerImpl: Adding task set 16.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:50:08 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 61, localhost, partition 0, PROCESS_LOCAL, 5501 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:08 INFO TaskSetManager: Starting task 1.0 in stage 16.0 (TID 62, localhost, partition 1, PROCESS_LOCAL, 5501 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:08 INFO TaskSetManager: Starting task 2.0 in stage 16.0 (TID 63, localhost, partition 2, PROCESS_LOCAL, 5501 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:08 INFO TaskSetManager: Starting task 3.0 in stage 16.0 (TID 64, localhost, partition 3, PROCESS_LOCAL, 5501 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:08 INFO Executor: Running task 2.0 in stage 16.0 (TID 63)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:08 INFO Executor: Running task 0.0 in stage 16.0 (TID 61)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:08 INFO Executor: Running task 1.0 in stage 16.0 (TID 62)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:08 INFO Executor: Running task 3.0 in stage 16.0 (TID 64)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:11 INFO Executor: Finished task 2.0 in stage 16.0 (TID 63). 1197 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:11 INFO TaskSetManager: Finished task 2.0 in stage 16.0 (TID 63) in 3548 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:11 INFO Executor: Finished task 1.0 in stage 16.0 (TID 62). 1197 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:11 INFO TaskSetManager: Finished task 1.0 in stage 16.0 (TID 62) in 3571 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:11 INFO Executor: Finished task 0.0 in stage 16.0 (TID 61). 1197 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:11 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 61) in 3577 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:11 INFO Executor: Finished task 3.0 in stage 16.0 (TID 64). 1197 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:11 INFO TaskSetManager: Finished task 3.0 in stage 16.0 (TID 64) in 3601 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:11 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:50:11 INFO DAGScheduler: ResultStage 16 (foreach at Query.scala:127) finished in 3.602 s[0m
[0m[[31merror[0m] [0m16/06/07 19:50:11 INFO DAGScheduler: Job 15 finished: foreach at Query.scala:127, took 3.610648 s[0m
[0m[[0minfo[0m] [0mExecution time: 3.6302336449999997s[0m
[0m[[0minfo[0m] [0mRunning execution RDD: back-to-back filters iteration: 1, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:50:11 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 172.16.54.31:33061 in memory (size: 6.7 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:11 INFO ContextCleaner: Cleaned accumulator 1736[0m
[0m[[31merror[0m] [0m16/06/07 19:50:11 INFO ContextCleaner: Cleaned accumulator 1737[0m
[0m[[31merror[0m] [0m16/06/07 19:50:11 INFO ContextCleaner: Cleaned accumulator 1738[0m
[0m[[31merror[0m] [0m16/06/07 19:50:11 INFO SparkContext: Starting job: count at Benchmark.scala:455[0m
[0m[[31merror[0m] [0m16/06/07 19:50:11 INFO DAGScheduler: Got job 16 (count at Benchmark.scala:455) with 4 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:50:11 INFO DAGScheduler: Final stage: ResultStage 17 (count at Benchmark.scala:455)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:11 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:50:11 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:50:11 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[9] at filter at DatasetPerformance.scala:75), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:50:11 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 3.5 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:11 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 1991.0 B, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:11 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 172.16.54.31:33061 (size: 1991.0 B, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:11 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:50:11 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 17 (MapPartitionsRDD[9] at filter at DatasetPerformance.scala:75)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:11 INFO TaskSchedulerImpl: Adding task set 17.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:50:11 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 65, localhost, partition 0, PROCESS_LOCAL, 5418 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:11 INFO TaskSetManager: Starting task 1.0 in stage 17.0 (TID 66, localhost, partition 1, PROCESS_LOCAL, 5418 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:11 INFO TaskSetManager: Starting task 2.0 in stage 17.0 (TID 67, localhost, partition 2, PROCESS_LOCAL, 5418 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:11 INFO TaskSetManager: Starting task 3.0 in stage 17.0 (TID 68, localhost, partition 3, PROCESS_LOCAL, 5418 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:11 INFO Executor: Running task 0.0 in stage 17.0 (TID 65)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:11 INFO Executor: Running task 2.0 in stage 17.0 (TID 67)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:11 INFO Executor: Running task 1.0 in stage 17.0 (TID 66)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:11 INFO Executor: Running task 3.0 in stage 17.0 (TID 68)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:15 INFO Executor: Finished task 1.0 in stage 17.0 (TID 66). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:15 INFO TaskSetManager: Finished task 1.0 in stage 17.0 (TID 66) in 3701 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:15 INFO Executor: Finished task 2.0 in stage 17.0 (TID 67). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:15 INFO TaskSetManager: Finished task 2.0 in stage 17.0 (TID 67) in 3735 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:15 INFO Executor: Finished task 0.0 in stage 17.0 (TID 65). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:15 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 65) in 3860 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:15 INFO Executor: Finished task 3.0 in stage 17.0 (TID 68). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:15 INFO TaskSetManager: Finished task 3.0 in stage 17.0 (TID 68) in 3859 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:15 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:50:15 INFO DAGScheduler: ResultStage 17 (count at Benchmark.scala:455) finished in 3.862 s[0m
[0m[[31merror[0m] [0m16/06/07 19:50:15 INFO DAGScheduler: Job 16 finished: count at Benchmark.scala:455, took 3.866406 s[0m
[0m[[0minfo[0m] [0mExecution time: 3.8691797219999997s[0m
[0m[[0minfo[0m] [0mRunning execution DS: back-to-back maps iteration: 1, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:50:15 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 172.16.54.31:33061 in memory (size: 1991.0 B, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:15 WARN BlockManager: Asked to remove block broadcast_17_piece0, which does not exist[0m
[0m[[31merror[0m] [0m16/06/07 19:50:15 INFO SparkContext: Starting job: foreach at Query.scala:127[0m
[0m[[31merror[0m] [0m16/06/07 19:50:15 INFO DAGScheduler: Got job 17 (foreach at Query.scala:127) with 4 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:50:15 INFO DAGScheduler: Final stage: ResultStage 18 (foreach at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:15 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:50:15 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:50:15 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[78] at rdd at Query.scala:127), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:50:15 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 21.3 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:15 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 8.0 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:15 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 172.16.54.31:33061 (size: 8.0 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:15 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:50:15 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 18 (MapPartitionsRDD[78] at rdd at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:15 INFO TaskSchedulerImpl: Adding task set 18.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:50:15 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 69, localhost, partition 0, PROCESS_LOCAL, 5498 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:15 INFO TaskSetManager: Starting task 1.0 in stage 18.0 (TID 70, localhost, partition 1, PROCESS_LOCAL, 5498 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:15 INFO TaskSetManager: Starting task 2.0 in stage 18.0 (TID 71, localhost, partition 2, PROCESS_LOCAL, 5498 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:15 INFO TaskSetManager: Starting task 3.0 in stage 18.0 (TID 72, localhost, partition 3, PROCESS_LOCAL, 5498 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:15 INFO Executor: Running task 2.0 in stage 18.0 (TID 71)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:15 INFO Executor: Running task 0.0 in stage 18.0 (TID 69)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:15 INFO Executor: Running task 1.0 in stage 18.0 (TID 70)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:15 INFO Executor: Running task 3.0 in stage 18.0 (TID 72)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:19 INFO Executor: Finished task 2.0 in stage 18.0 (TID 71). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:19 INFO TaskSetManager: Finished task 2.0 in stage 18.0 (TID 71) in 3821 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:19 INFO Executor: Finished task 1.0 in stage 18.0 (TID 70). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:19 INFO TaskSetManager: Finished task 1.0 in stage 18.0 (TID 70) in 3920 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:20 INFO Executor: Finished task 0.0 in stage 18.0 (TID 69). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:20 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 69) in 4197 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:20 INFO Executor: Finished task 3.0 in stage 18.0 (TID 72). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:20 INFO TaskSetManager: Finished task 3.0 in stage 18.0 (TID 72) in 4212 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:20 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:50:20 INFO DAGScheduler: ResultStage 18 (foreach at Query.scala:127) finished in 4.217 s[0m
[0m[[31merror[0m] [0m16/06/07 19:50:20 INFO DAGScheduler: Job 17 finished: foreach at Query.scala:127, took 4.231286 s[0m
[0m[[0minfo[0m] [0mExecution time: 4.252893043s[0m
[0m[[0minfo[0m] [0mRunning execution DF: back-to-back maps iteration: 1, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:50:20 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 172.16.54.31:33061 in memory (size: 8.0 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:20 INFO ContextCleaner: Cleaned accumulator 1959[0m
[0m[[31merror[0m] [0m16/06/07 19:50:20 INFO ContextCleaner: Cleaned accumulator 1960[0m
[0m[[31merror[0m] [0m16/06/07 19:50:20 INFO SparkContext: Starting job: foreach at Query.scala:127[0m
[0m[[31merror[0m] [0m16/06/07 19:50:20 INFO DAGScheduler: Got job 18 (foreach at Query.scala:127) with 4 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:50:20 INFO DAGScheduler: Final stage: ResultStage 19 (foreach at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:20 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:50:20 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:50:20 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[83] at rdd at Query.scala:127), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:50:20 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 12.0 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:20 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 5.9 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:20 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 172.16.54.31:33061 (size: 5.9 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:20 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:50:20 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 19 (MapPartitionsRDD[83] at rdd at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:20 INFO TaskSchedulerImpl: Adding task set 19.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:50:20 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 73, localhost, partition 0, PROCESS_LOCAL, 5498 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:20 INFO TaskSetManager: Starting task 1.0 in stage 19.0 (TID 74, localhost, partition 1, PROCESS_LOCAL, 5498 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:20 INFO TaskSetManager: Starting task 2.0 in stage 19.0 (TID 75, localhost, partition 2, PROCESS_LOCAL, 5498 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:20 INFO TaskSetManager: Starting task 3.0 in stage 19.0 (TID 76, localhost, partition 3, PROCESS_LOCAL, 5498 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:20 INFO Executor: Running task 0.0 in stage 19.0 (TID 73)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:20 INFO Executor: Running task 1.0 in stage 19.0 (TID 74)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:20 INFO Executor: Running task 3.0 in stage 19.0 (TID 76)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:20 INFO Executor: Running task 2.0 in stage 19.0 (TID 75)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:23 INFO Executor: Finished task 0.0 in stage 19.0 (TID 73). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:23 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 73) in 3482 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:23 INFO Executor: Finished task 1.0 in stage 19.0 (TID 74). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:23 INFO TaskSetManager: Finished task 1.0 in stage 19.0 (TID 74) in 3568 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:23 INFO Executor: Finished task 2.0 in stage 19.0 (TID 75). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:23 INFO TaskSetManager: Finished task 2.0 in stage 19.0 (TID 75) in 3637 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:24 INFO Executor: Finished task 3.0 in stage 19.0 (TID 76). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:24 INFO TaskSetManager: Finished task 3.0 in stage 19.0 (TID 76) in 3733 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:24 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:50:24 INFO DAGScheduler: ResultStage 19 (foreach at Query.scala:127) finished in 3.734 s[0m
[0m[[31merror[0m] [0m16/06/07 19:50:24 INFO DAGScheduler: Job 18 finished: foreach at Query.scala:127, took 3.745634 s[0m
[0m[[31merror[0m] [0m16/06/07 19:50:24 INFO ContextCleaner: Cleaned accumulator 2071[0m
[0m[[31merror[0m] [0m16/06/07 19:50:24 INFO ContextCleaner: Cleaned accumulator 2072[0m
[0m[[0minfo[0m] [0mExecution time: 3.762306s[0m
[0m[[0minfo[0m] [0mRunning execution RDD: back-to-back maps iteration: 1, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:50:24 WARN BlockManager: Asked to remove block broadcast_19_piece0, which does not exist[0m
[0m[[31merror[0m] [0m16/06/07 19:50:24 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 172.16.54.31:33061 in memory (size: 5.9 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:24 INFO SparkContext: Starting job: count at Benchmark.scala:455[0m
[0m[[31merror[0m] [0m16/06/07 19:50:24 INFO DAGScheduler: Got job 19 (count at Benchmark.scala:455) with 4 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:50:24 INFO DAGScheduler: Final stage: ResultStage 20 (count at Benchmark.scala:455)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:24 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:50:24 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:50:24 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[14] at map at DatasetPerformance.scala:99), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:50:24 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 3.4 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:24 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 1990.0 B, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:24 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 172.16.54.31:33061 (size: 1990.0 B, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:24 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:50:24 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 20 (MapPartitionsRDD[14] at map at DatasetPerformance.scala:99)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:24 INFO TaskSchedulerImpl: Adding task set 20.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:50:24 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 77, localhost, partition 0, PROCESS_LOCAL, 5415 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:24 INFO TaskSetManager: Starting task 1.0 in stage 20.0 (TID 78, localhost, partition 1, PROCESS_LOCAL, 5415 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:24 INFO TaskSetManager: Starting task 2.0 in stage 20.0 (TID 79, localhost, partition 2, PROCESS_LOCAL, 5415 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:24 INFO TaskSetManager: Starting task 3.0 in stage 20.0 (TID 80, localhost, partition 3, PROCESS_LOCAL, 5415 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:24 INFO Executor: Running task 0.0 in stage 20.0 (TID 77)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:24 INFO Executor: Running task 1.0 in stage 20.0 (TID 78)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:24 INFO Executor: Running task 2.0 in stage 20.0 (TID 79)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:24 INFO Executor: Running task 3.0 in stage 20.0 (TID 80)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:28 INFO Executor: Finished task 3.0 in stage 20.0 (TID 80). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:28 INFO TaskSetManager: Finished task 3.0 in stage 20.0 (TID 80) in 4421 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:28 INFO Executor: Finished task 2.0 in stage 20.0 (TID 79). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:28 INFO TaskSetManager: Finished task 2.0 in stage 20.0 (TID 79) in 4561 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:28 INFO Executor: Finished task 1.0 in stage 20.0 (TID 78). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:28 INFO TaskSetManager: Finished task 1.0 in stage 20.0 (TID 78) in 4627 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:28 INFO Executor: Finished task 0.0 in stage 20.0 (TID 77). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:28 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 77) in 4679 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:28 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:50:28 INFO DAGScheduler: ResultStage 20 (count at Benchmark.scala:455) finished in 4.658 s[0m
[0m[[31merror[0m] [0m16/06/07 19:50:28 INFO DAGScheduler: Job 19 finished: count at Benchmark.scala:455, took 4.685845 s[0m
[0m[[31merror[0m] [0m16/06/07 19:50:28 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 172.16.54.31:33061 in memory (size: 1990.0 B, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:28 WARN BlockManager: Asked to remove block broadcast_20_piece0, which does not exist[0m
[0m[[0minfo[0m] [0mExecution time: 4.691563198s[0m
[0m[[0minfo[0m] [0mRunning execution DS: average iteration: 1, StandardRun=true[0m
[0m[[0minfo[0m] [0mExecution 'DS: average' failed: cannot resolve '`sum`' given input columns: [id];[0m
[0m[[0minfo[0m] [0mRunning execution DF: average iteration: 1, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:50:28 INFO SparkSqlParser: Parsing command: avg(id)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:28 INFO SparkSqlParser: Parsing command: avg(id)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:28 INFO SparkContext: Starting job: collect at Query.scala:126[0m
[0m[[31merror[0m] [0m16/06/07 19:50:28 INFO DAGScheduler: Registering RDD 87 (rdd at Query.scala:126)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:28 INFO DAGScheduler: Got job 20 (collect at Query.scala:126) with 1 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:50:28 INFO DAGScheduler: Final stage: ResultStage 22 (collect at Query.scala:126)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 21)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:28 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 21)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:28 INFO DAGScheduler: Submitting ShuffleMapStage 21 (MapPartitionsRDD[87] at rdd at Query.scala:126), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:50:28 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 12.4 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:28 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 5.9 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:28 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 172.16.54.31:33061 (size: 5.9 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:28 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:50:28 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 21 (MapPartitionsRDD[87] at rdd at Query.scala:126)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:28 INFO TaskSchedulerImpl: Adding task set 21.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:50:28 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 81, localhost, partition 0, PROCESS_LOCAL, 5477 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:28 INFO TaskSetManager: Starting task 1.0 in stage 21.0 (TID 82, localhost, partition 1, PROCESS_LOCAL, 5477 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:28 INFO TaskSetManager: Starting task 2.0 in stage 21.0 (TID 83, localhost, partition 2, PROCESS_LOCAL, 5477 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:28 INFO TaskSetManager: Starting task 3.0 in stage 21.0 (TID 84, localhost, partition 3, PROCESS_LOCAL, 5477 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:28 INFO Executor: Running task 1.0 in stage 21.0 (TID 82)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:28 INFO Executor: Running task 0.0 in stage 21.0 (TID 81)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:28 INFO Executor: Running task 2.0 in stage 21.0 (TID 83)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:28 INFO Executor: Running task 3.0 in stage 21.0 (TID 84)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:28 INFO Executor: Finished task 1.0 in stage 21.0 (TID 82). 1639 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:28 INFO TaskSetManager: Finished task 1.0 in stage 21.0 (TID 82) in 19 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:28 INFO Executor: Finished task 2.0 in stage 21.0 (TID 83). 1639 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:28 INFO TaskSetManager: Finished task 2.0 in stage 21.0 (TID 83) in 21 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO Executor: Finished task 3.0 in stage 21.0 (TID 84). 1639 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO Executor: Finished task 0.0 in stage 21.0 (TID 81). 1639 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO TaskSetManager: Finished task 3.0 in stage 21.0 (TID 84) in 26 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 81) in 29 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO DAGScheduler: ShuffleMapStage 21 (rdd at Query.scala:126) finished in 0.029 s[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO DAGScheduler: looking for newly runnable stages[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO DAGScheduler: running: Set()[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO DAGScheduler: waiting: Set(ResultStage 22)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO DAGScheduler: failed: Set()[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[91] at rdd at Query.scala:126), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 19.0 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 9.1 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 172.16.54.31:33061 (size: 9.1 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[91] at rdd at Query.scala:126)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 85, localhost, partition 0, ANY, 5389 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO Executor: Running task 0.0 in stage 22.0 (TID 85)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO Executor: Finished task 0.0 in stage 22.0 (TID 85). 3529 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 85) in 13 ms on localhost (1/1)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO DAGScheduler: ResultStage 22 (collect at Query.scala:126) finished in 0.015 s[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO DAGScheduler: Job 20 finished: collect at Query.scala:126, took 0.056709 s[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 172.16.54.31:33061 in memory (size: 9.1 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 172.16.54.31:33061 in memory (size: 5.9 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO ContextCleaner: Cleaned accumulator 2293[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO ContextCleaner: Cleaned accumulator 2294[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO ContextCleaner: Cleaned accumulator 2295[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO ContextCleaner: Cleaned accumulator 2296[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO ContextCleaner: Cleaned accumulator 2297[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO ContextCleaner: Cleaned accumulator 2298[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO ContextCleaner: Cleaned accumulator 2299[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO ContextCleaner: Cleaned accumulator 2300[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO ContextCleaner: Cleaned accumulator 2301[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO ContextCleaner: Cleaned accumulator 2302[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO ContextCleaner: Cleaned accumulator 2303[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO ContextCleaner: Cleaned accumulator 2304[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO ContextCleaner: Cleaned accumulator 2305[0m
[0m[[0minfo[0m] [0mExecution time: 0.08431772s[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO ContextCleaner: Cleaned accumulator 2306[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO ContextCleaner: Cleaned accumulator 2307[0m
[0m[[0minfo[0m] [0mRunning execution RDD: average iteration: 1, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO ContextCleaner: Cleaned accumulator 2308[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO ContextCleaner: Cleaned accumulator 2309[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO ContextCleaner: Cleaned shuffle 1[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO SparkContext: Starting job: reduce at DatasetPerformance.scala:139[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO DAGScheduler: Got job 21 (reduce at DatasetPerformance.scala:139) with 4 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO DAGScheduler: Final stage: ResultStage 23 (reduce at DatasetPerformance.scala:139)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[92] at map at DatasetPerformance.scala:139), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 2.9 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 1858.0 B, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 172.16.54.31:33061 (size: 1858.0 B, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 23 (MapPartitionsRDD[92] at map at DatasetPerformance.scala:139)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO TaskSchedulerImpl: Adding task set 23.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 86, localhost, partition 0, PROCESS_LOCAL, 5488 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO TaskSetManager: Starting task 1.0 in stage 23.0 (TID 87, localhost, partition 1, PROCESS_LOCAL, 5488 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO TaskSetManager: Starting task 2.0 in stage 23.0 (TID 88, localhost, partition 2, PROCESS_LOCAL, 5488 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO TaskSetManager: Starting task 3.0 in stage 23.0 (TID 89, localhost, partition 3, PROCESS_LOCAL, 5488 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO Executor: Running task 0.0 in stage 23.0 (TID 86)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO Executor: Running task 2.0 in stage 23.0 (TID 88)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO Executor: Running task 1.0 in stage 23.0 (TID 87)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO Executor: Running task 3.0 in stage 23.0 (TID 89)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO Executor: Finished task 0.0 in stage 23.0 (TID 86). 917 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO Executor: Finished task 1.0 in stage 23.0 (TID 87). 917 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 86) in 37 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO TaskSetManager: Finished task 1.0 in stage 23.0 (TID 87) in 37 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO Executor: Finished task 3.0 in stage 23.0 (TID 89). 917 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO TaskSetManager: Finished task 3.0 in stage 23.0 (TID 89) in 43 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO Executor: Finished task 2.0 in stage 23.0 (TID 88). 917 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO TaskSetManager: Finished task 2.0 in stage 23.0 (TID 88) in 51 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO DAGScheduler: ResultStage 23 (reduce at DatasetPerformance.scala:139) finished in 0.052 s[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO DAGScheduler: Job 21 finished: reduce at DatasetPerformance.scala:139, took 0.060523 s[0m
[0m[[0minfo[0m] [0mExecution time: 0.06588556400000001s[0m
[0m[[0minfo[0m] [0mRunning execution DS: range iteration: 2, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 172.16.54.31:33061 in memory (size: 1858.0 B, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO SparkContext: Starting job: foreach at Query.scala:127[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO DAGScheduler: Got job 22 (foreach at Query.scala:127) with 4 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO DAGScheduler: Final stage: ResultStage 24 (foreach at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[97] at rdd at Query.scala:127), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 9.9 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 5.1 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 172.16.54.31:33061 (size: 5.1 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 24 (MapPartitionsRDD[97] at rdd at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO TaskSchedulerImpl: Adding task set 24.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 90, localhost, partition 0, PROCESS_LOCAL, 5486 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO TaskSetManager: Starting task 1.0 in stage 24.0 (TID 91, localhost, partition 1, PROCESS_LOCAL, 5486 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO TaskSetManager: Starting task 2.0 in stage 24.0 (TID 92, localhost, partition 2, PROCESS_LOCAL, 5486 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO TaskSetManager: Starting task 3.0 in stage 24.0 (TID 93, localhost, partition 3, PROCESS_LOCAL, 5486 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO Executor: Running task 0.0 in stage 24.0 (TID 90)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO Executor: Running task 1.0 in stage 24.0 (TID 91)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO Executor: Running task 2.0 in stage 24.0 (TID 92)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:29 INFO Executor: Running task 3.0 in stage 24.0 (TID 93)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:32 INFO Executor: Finished task 2.0 in stage 24.0 (TID 92). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:32 INFO TaskSetManager: Finished task 2.0 in stage 24.0 (TID 92) in 3216 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:32 INFO Executor: Finished task 3.0 in stage 24.0 (TID 93). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:32 INFO TaskSetManager: Finished task 3.0 in stage 24.0 (TID 93) in 3294 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:32 INFO Executor: Finished task 0.0 in stage 24.0 (TID 90). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:32 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 90) in 3351 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:32 INFO Executor: Finished task 1.0 in stage 24.0 (TID 91). 1222 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:32 INFO TaskSetManager: Finished task 1.0 in stage 24.0 (TID 91) in 3400 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:32 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:50:32 INFO DAGScheduler: ResultStage 24 (foreach at Query.scala:127) finished in 3.401 s[0m
[0m[[31merror[0m] [0m16/06/07 19:50:32 INFO DAGScheduler: Job 22 finished: foreach at Query.scala:127, took 3.419999 s[0m
[0m[[31merror[0m] [0m16/06/07 19:50:32 INFO ContextCleaner: Cleaned accumulator 2575[0m
[0m[[0minfo[0m] [0mExecution time: 3.4445649709999997s[0m
[0m[[0minfo[0m] [0mRunning execution DF: range iteration: 2, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:50:32 WARN BlockManager: Asked to remove block broadcast_24_piece0, which does not exist[0m
[0m[[31merror[0m] [0m16/06/07 19:50:32 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 172.16.54.31:33061 in memory (size: 5.1 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:32 INFO ContextCleaner: Cleaned accumulator 2574[0m
[0m[[31merror[0m] [0m16/06/07 19:50:32 INFO SparkContext: Starting job: foreach at Query.scala:127[0m
[0m[[31merror[0m] [0m16/06/07 19:50:32 INFO DAGScheduler: Got job 23 (foreach at Query.scala:127) with 4 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:50:32 INFO DAGScheduler: Final stage: ResultStage 25 (foreach at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:32 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:50:32 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:50:32 INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[102] at rdd at Query.scala:127), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:50:32 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 9.9 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:32 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 5.1 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:32 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 172.16.54.31:33061 (size: 5.1 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:32 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:50:32 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 25 (MapPartitionsRDD[102] at rdd at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:32 INFO TaskSchedulerImpl: Adding task set 25.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:50:32 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 94, localhost, partition 0, PROCESS_LOCAL, 5486 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:32 INFO TaskSetManager: Starting task 1.0 in stage 25.0 (TID 95, localhost, partition 1, PROCESS_LOCAL, 5486 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:32 INFO TaskSetManager: Starting task 2.0 in stage 25.0 (TID 96, localhost, partition 2, PROCESS_LOCAL, 5486 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:32 INFO TaskSetManager: Starting task 3.0 in stage 25.0 (TID 97, localhost, partition 3, PROCESS_LOCAL, 5486 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:32 INFO Executor: Running task 2.0 in stage 25.0 (TID 96)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:32 INFO Executor: Running task 0.0 in stage 25.0 (TID 94)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:32 INFO Executor: Running task 1.0 in stage 25.0 (TID 95)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:32 INFO Executor: Running task 3.0 in stage 25.0 (TID 97)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:36 INFO Executor: Finished task 2.0 in stage 25.0 (TID 96). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:36 INFO TaskSetManager: Finished task 2.0 in stage 25.0 (TID 96) in 3231 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:36 INFO Executor: Finished task 1.0 in stage 25.0 (TID 95). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:36 INFO TaskSetManager: Finished task 1.0 in stage 25.0 (TID 95) in 3404 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:36 INFO Executor: Finished task 0.0 in stage 25.0 (TID 94). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:36 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 94) in 3413 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:36 INFO Executor: Finished task 3.0 in stage 25.0 (TID 97). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:36 INFO TaskSetManager: Finished task 3.0 in stage 25.0 (TID 97) in 3610 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:36 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:50:36 INFO DAGScheduler: ResultStage 25 (foreach at Query.scala:127) finished in 3.611 s[0m
[0m[[31merror[0m] [0m16/06/07 19:50:36 INFO DAGScheduler: Job 23 finished: foreach at Query.scala:127, took 3.620018 s[0m
[0m[[31merror[0m] [0m16/06/07 19:50:36 WARN BlockManager: Asked to remove block broadcast_25_piece0, which does not exist[0m
[0m[[0minfo[0m] [0mExecution time: 3.63058322s[0m
[0m[[0minfo[0m] [0mRunning execution RDD: range iteration: 2, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:50:36 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 172.16.54.31:33061 in memory (size: 5.1 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:36 INFO ContextCleaner: Cleaned accumulator 2686[0m
[0m[[31merror[0m] [0m16/06/07 19:50:36 INFO ContextCleaner: Cleaned accumulator 2687[0m
[0m[[31merror[0m] [0m16/06/07 19:50:36 INFO SparkContext: Starting job: count at Benchmark.scala:455[0m
[0m[[31merror[0m] [0m16/06/07 19:50:36 INFO DAGScheduler: Got job 24 (count at Benchmark.scala:455) with 4 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:50:36 INFO DAGScheduler: Final stage: ResultStage 26 (count at Benchmark.scala:455)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:36 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:50:36 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:50:36 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[4] at map at DatasetPerformance.scala:51), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:50:36 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 2.9 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:36 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 1860.0 B, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:36 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 172.16.54.31:33061 (size: 1860.0 B, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:36 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:50:36 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 26 (MapPartitionsRDD[4] at map at DatasetPerformance.scala:51)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:36 INFO TaskSchedulerImpl: Adding task set 26.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:50:36 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 98, localhost, partition 0, PROCESS_LOCAL, 5403 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:36 INFO TaskSetManager: Starting task 1.0 in stage 26.0 (TID 99, localhost, partition 1, PROCESS_LOCAL, 5403 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:36 INFO TaskSetManager: Starting task 2.0 in stage 26.0 (TID 100, localhost, partition 2, PROCESS_LOCAL, 5403 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:36 INFO TaskSetManager: Starting task 3.0 in stage 26.0 (TID 101, localhost, partition 3, PROCESS_LOCAL, 5403 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:36 INFO Executor: Running task 1.0 in stage 26.0 (TID 99)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:36 INFO Executor: Running task 2.0 in stage 26.0 (TID 100)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:36 INFO Executor: Running task 0.0 in stage 26.0 (TID 98)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:36 INFO Executor: Running task 3.0 in stage 26.0 (TID 101)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:37 INFO Executor: Finished task 0.0 in stage 26.0 (TID 98). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:37 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 98) in 1323 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:37 INFO Executor: Finished task 2.0 in stage 26.0 (TID 100). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:37 INFO TaskSetManager: Finished task 2.0 in stage 26.0 (TID 100) in 1461 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:37 INFO Executor: Finished task 1.0 in stage 26.0 (TID 99). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:37 INFO TaskSetManager: Finished task 1.0 in stage 26.0 (TID 99) in 1505 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:38 INFO Executor: Finished task 3.0 in stage 26.0 (TID 101). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:38 INFO TaskSetManager: Finished task 3.0 in stage 26.0 (TID 101) in 1554 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:38 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:50:38 INFO DAGScheduler: ResultStage 26 (count at Benchmark.scala:455) finished in 1.555 s[0m
[0m[[31merror[0m] [0m16/06/07 19:50:38 INFO DAGScheduler: Job 24 finished: count at Benchmark.scala:455, took 1.561598 s[0m
[0m[[0minfo[0m] [0mExecution time: 1.563296715s[0m
[0m[[0minfo[0m] [0mRunning execution DS: back-to-back filters iteration: 2, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:50:38 WARN BlockManager: Asked to remove block broadcast_26_piece0, which does not exist[0m
[0m[[31merror[0m] [0m16/06/07 19:50:38 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 172.16.54.31:33061 in memory (size: 1860.0 B, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:38 INFO SparkContext: Starting job: foreach at Query.scala:127[0m
[0m[[31merror[0m] [0m16/06/07 19:50:38 INFO DAGScheduler: Got job 25 (foreach at Query.scala:127) with 4 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:50:38 INFO DAGScheduler: Final stage: ResultStage 27 (foreach at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:38 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:50:38 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:50:38 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[107] at rdd at Query.scala:127), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:50:38 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 18.9 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:38 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 7.9 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:38 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 172.16.54.31:33061 (size: 7.9 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:38 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:50:38 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 27 (MapPartitionsRDD[107] at rdd at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:38 INFO TaskSchedulerImpl: Adding task set 27.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:50:38 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 102, localhost, partition 0, PROCESS_LOCAL, 5501 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:38 INFO TaskSetManager: Starting task 1.0 in stage 27.0 (TID 103, localhost, partition 1, PROCESS_LOCAL, 5501 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:38 INFO TaskSetManager: Starting task 2.0 in stage 27.0 (TID 104, localhost, partition 2, PROCESS_LOCAL, 5501 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:38 INFO TaskSetManager: Starting task 3.0 in stage 27.0 (TID 105, localhost, partition 3, PROCESS_LOCAL, 5501 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:38 INFO Executor: Running task 0.0 in stage 27.0 (TID 102)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:38 INFO Executor: Running task 2.0 in stage 27.0 (TID 104)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:38 INFO Executor: Running task 1.0 in stage 27.0 (TID 103)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:38 INFO Executor: Running task 3.0 in stage 27.0 (TID 105)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:42 INFO Executor: Finished task 3.0 in stage 27.0 (TID 105). 1197 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:42 INFO TaskSetManager: Finished task 3.0 in stage 27.0 (TID 105) in 4183 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:42 INFO Executor: Finished task 2.0 in stage 27.0 (TID 104). 1197 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:42 INFO TaskSetManager: Finished task 2.0 in stage 27.0 (TID 104) in 4191 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:42 INFO Executor: Finished task 0.0 in stage 27.0 (TID 102). 1197 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:42 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 102) in 4469 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:42 INFO Executor: Finished task 1.0 in stage 27.0 (TID 103). 1197 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:42 INFO TaskSetManager: Finished task 1.0 in stage 27.0 (TID 103) in 4575 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:42 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:50:42 INFO DAGScheduler: ResultStage 27 (foreach at Query.scala:127) finished in 4.576 s[0m
[0m[[31merror[0m] [0m16/06/07 19:50:42 INFO DAGScheduler: Job 25 finished: foreach at Query.scala:127, took 4.588719 s[0m
[0m[[31merror[0m] [0m16/06/07 19:50:42 WARN BlockManager: Asked to remove block broadcast_27_piece0, which does not exist[0m
[0m[[0minfo[0m] [0mExecution time: 4.6104779769999995s[0m
[0m[[0minfo[0m] [0mRunning execution DF: back-to-back filters iteration: 2, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:50:42 INFO SparkSqlParser: Parsing command: id % 100 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:50:42 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 172.16.54.31:33061 in memory (size: 7.9 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:42 INFO SparkSqlParser: Parsing command: id % 101 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:50:42 INFO ContextCleaner: Cleaned accumulator 2908[0m
[0m[[31merror[0m] [0m16/06/07 19:50:42 INFO ContextCleaner: Cleaned accumulator 2909[0m
[0m[[31merror[0m] [0m16/06/07 19:50:42 INFO ContextCleaner: Cleaned accumulator 2910[0m
[0m[[31merror[0m] [0m16/06/07 19:50:42 INFO SparkSqlParser: Parsing command: id % 102 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:50:42 INFO SparkSqlParser: Parsing command: id % 103 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:50:42 INFO SparkSqlParser: Parsing command: id % 100 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:50:42 INFO SparkSqlParser: Parsing command: id % 101 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:50:42 INFO SparkSqlParser: Parsing command: id % 102 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:50:42 INFO SparkSqlParser: Parsing command: id % 103 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:50:42 INFO SparkContext: Starting job: foreach at Query.scala:127[0m
[0m[[31merror[0m] [0m16/06/07 19:50:42 INFO DAGScheduler: Got job 26 (foreach at Query.scala:127) with 4 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:50:42 INFO DAGScheduler: Final stage: ResultStage 28 (foreach at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:42 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:50:42 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:50:42 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[112] at rdd at Query.scala:127), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:50:42 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 15.0 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:42 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 6.7 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:42 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 172.16.54.31:33061 (size: 6.7 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:42 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:50:42 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 28 (MapPartitionsRDD[112] at rdd at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:42 INFO TaskSchedulerImpl: Adding task set 28.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:50:42 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 106, localhost, partition 0, PROCESS_LOCAL, 5501 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:42 INFO TaskSetManager: Starting task 1.0 in stage 28.0 (TID 107, localhost, partition 1, PROCESS_LOCAL, 5501 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:42 INFO TaskSetManager: Starting task 2.0 in stage 28.0 (TID 108, localhost, partition 2, PROCESS_LOCAL, 5501 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:42 INFO TaskSetManager: Starting task 3.0 in stage 28.0 (TID 109, localhost, partition 3, PROCESS_LOCAL, 5501 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:42 INFO Executor: Running task 2.0 in stage 28.0 (TID 108)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:42 INFO Executor: Running task 3.0 in stage 28.0 (TID 109)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:42 INFO Executor: Running task 0.0 in stage 28.0 (TID 106)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:42 INFO Executor: Running task 1.0 in stage 28.0 (TID 107)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:46 INFO Executor: Finished task 3.0 in stage 28.0 (TID 109). 1197 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:46 INFO TaskSetManager: Finished task 3.0 in stage 28.0 (TID 109) in 3697 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:46 INFO Executor: Finished task 1.0 in stage 28.0 (TID 107). 1197 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:46 INFO TaskSetManager: Finished task 1.0 in stage 28.0 (TID 107) in 3783 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:46 INFO Executor: Finished task 2.0 in stage 28.0 (TID 108). 1197 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:46 INFO TaskSetManager: Finished task 2.0 in stage 28.0 (TID 108) in 3845 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:46 INFO Executor: Finished task 0.0 in stage 28.0 (TID 106). 1197 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:46 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 106) in 3877 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:46 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:50:46 INFO DAGScheduler: ResultStage 28 (foreach at Query.scala:127) finished in 3.877 s[0m
[0m[[31merror[0m] [0m16/06/07 19:50:46 INFO DAGScheduler: Job 26 finished: foreach at Query.scala:127, took 3.886282 s[0m
[0m[[31merror[0m] [0m16/06/07 19:50:46 INFO ContextCleaner: Cleaned accumulator 3021[0m
[0m[[31merror[0m] [0m16/06/07 19:50:46 INFO ContextCleaner: Cleaned accumulator 3022[0m
[0m[[31merror[0m] [0m16/06/07 19:50:46 INFO ContextCleaner: Cleaned accumulator 3023[0m
[0m[[0minfo[0m] [0mExecution time: 3.90609924s[0m
[0m[[0minfo[0m] [0mRunning execution RDD: back-to-back filters iteration: 2, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:50:46 WARN BlockManager: Asked to remove block broadcast_28_piece0, which does not exist[0m
[0m[[31merror[0m] [0m16/06/07 19:50:46 INFO SparkContext: Starting job: count at Benchmark.scala:455[0m
[0m[[31merror[0m] [0m16/06/07 19:50:46 INFO DAGScheduler: Got job 27 (count at Benchmark.scala:455) with 4 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:50:46 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 172.16.54.31:33061 in memory (size: 6.7 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:46 INFO DAGScheduler: Final stage: ResultStage 29 (count at Benchmark.scala:455)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:46 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:50:46 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:50:46 INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[9] at filter at DatasetPerformance.scala:75), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:50:46 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 3.5 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:46 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 1991.0 B, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:46 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 172.16.54.31:33061 (size: 1991.0 B, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:46 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:50:46 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 29 (MapPartitionsRDD[9] at filter at DatasetPerformance.scala:75)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:46 INFO TaskSchedulerImpl: Adding task set 29.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:50:46 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 110, localhost, partition 0, PROCESS_LOCAL, 5418 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:46 INFO TaskSetManager: Starting task 1.0 in stage 29.0 (TID 111, localhost, partition 1, PROCESS_LOCAL, 5418 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:46 INFO TaskSetManager: Starting task 2.0 in stage 29.0 (TID 112, localhost, partition 2, PROCESS_LOCAL, 5418 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:46 INFO TaskSetManager: Starting task 3.0 in stage 29.0 (TID 113, localhost, partition 3, PROCESS_LOCAL, 5418 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:46 INFO Executor: Running task 1.0 in stage 29.0 (TID 111)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:46 INFO Executor: Running task 2.0 in stage 29.0 (TID 112)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:46 INFO Executor: Running task 0.0 in stage 29.0 (TID 110)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:46 INFO Executor: Running task 3.0 in stage 29.0 (TID 113)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:50 INFO Executor: Finished task 0.0 in stage 29.0 (TID 110). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:50 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 110) in 3474 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:50 INFO Executor: Finished task 3.0 in stage 29.0 (TID 113). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:50 INFO TaskSetManager: Finished task 3.0 in stage 29.0 (TID 113) in 3572 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:50 INFO Executor: Finished task 1.0 in stage 29.0 (TID 111). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:50 INFO TaskSetManager: Finished task 1.0 in stage 29.0 (TID 111) in 3693 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:50 INFO Executor: Finished task 2.0 in stage 29.0 (TID 112). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:50 INFO TaskSetManager: Finished task 2.0 in stage 29.0 (TID 112) in 3785 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:50 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:50:50 INFO DAGScheduler: ResultStage 29 (count at Benchmark.scala:455) finished in 3.788 s[0m
[0m[[31merror[0m] [0m16/06/07 19:50:50 INFO DAGScheduler: Job 27 finished: count at Benchmark.scala:455, took 3.793338 s[0m
[0m[[0minfo[0m] [0mExecution time: 3.79496735s[0m
[0m[[0minfo[0m] [0mRunning execution DS: back-to-back maps iteration: 2, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:50:50 WARN BlockManager: Asked to remove block broadcast_29_piece0, which does not exist[0m
[0m[[31merror[0m] [0m16/06/07 19:50:50 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 172.16.54.31:33061 in memory (size: 1991.0 B, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:50 INFO SparkContext: Starting job: foreach at Query.scala:127[0m
[0m[[31merror[0m] [0m16/06/07 19:50:50 INFO DAGScheduler: Got job 28 (foreach at Query.scala:127) with 4 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:50:50 INFO DAGScheduler: Final stage: ResultStage 30 (foreach at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:50 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:50:50 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:50:50 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[117] at rdd at Query.scala:127), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:50:50 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 21.3 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:50 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 8.0 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:50 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 172.16.54.31:33061 (size: 8.0 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:50 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:50:50 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 30 (MapPartitionsRDD[117] at rdd at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:50 INFO TaskSchedulerImpl: Adding task set 30.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:50:50 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 114, localhost, partition 0, PROCESS_LOCAL, 5498 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:50 INFO TaskSetManager: Starting task 1.0 in stage 30.0 (TID 115, localhost, partition 1, PROCESS_LOCAL, 5498 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:50 INFO TaskSetManager: Starting task 2.0 in stage 30.0 (TID 116, localhost, partition 2, PROCESS_LOCAL, 5498 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:50 INFO TaskSetManager: Starting task 3.0 in stage 30.0 (TID 117, localhost, partition 3, PROCESS_LOCAL, 5498 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:50 INFO Executor: Running task 0.0 in stage 30.0 (TID 114)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:50 INFO Executor: Running task 2.0 in stage 30.0 (TID 116)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:50 INFO Executor: Running task 1.0 in stage 30.0 (TID 115)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:50 INFO Executor: Running task 3.0 in stage 30.0 (TID 117)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:54 INFO Executor: Finished task 0.0 in stage 30.0 (TID 114). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:54 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 114) in 3859 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:54 INFO Executor: Finished task 3.0 in stage 30.0 (TID 117). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:54 INFO TaskSetManager: Finished task 3.0 in stage 30.0 (TID 117) in 4053 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:54 INFO Executor: Finished task 2.0 in stage 30.0 (TID 116). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:54 INFO TaskSetManager: Finished task 2.0 in stage 30.0 (TID 116) in 4091 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:55 INFO Executor: Finished task 1.0 in stage 30.0 (TID 115). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:55 INFO TaskSetManager: Finished task 1.0 in stage 30.0 (TID 115) in 4203 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:55 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:50:55 INFO DAGScheduler: ResultStage 30 (foreach at Query.scala:127) finished in 4.205 s[0m
[0m[[31merror[0m] [0m16/06/07 19:50:55 INFO DAGScheduler: Job 28 finished: foreach at Query.scala:127, took 4.224137 s[0m
[0m[[0minfo[0m] [0mExecution time: 4.24239099s[0m
[0m[[0minfo[0m] [0mRunning execution DF: back-to-back maps iteration: 2, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:50:55 WARN BlockManager: Asked to remove block broadcast_30_piece0, which does not exist[0m
[0m[[31merror[0m] [0m16/06/07 19:50:55 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 172.16.54.31:33061 in memory (size: 8.0 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:55 INFO ContextCleaner: Cleaned accumulator 3244[0m
[0m[[31merror[0m] [0m16/06/07 19:50:55 INFO ContextCleaner: Cleaned accumulator 3245[0m
[0m[[31merror[0m] [0m16/06/07 19:50:55 INFO SparkContext: Starting job: foreach at Query.scala:127[0m
[0m[[31merror[0m] [0m16/06/07 19:50:55 INFO DAGScheduler: Got job 29 (foreach at Query.scala:127) with 4 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:50:55 INFO DAGScheduler: Final stage: ResultStage 31 (foreach at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:55 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:50:55 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:50:55 INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[122] at rdd at Query.scala:127), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:50:55 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 12.0 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:55 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 5.9 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:55 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 172.16.54.31:33061 (size: 5.9 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:55 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:50:55 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 31 (MapPartitionsRDD[122] at rdd at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:55 INFO TaskSchedulerImpl: Adding task set 31.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:50:55 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 118, localhost, partition 0, PROCESS_LOCAL, 5498 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:55 INFO TaskSetManager: Starting task 1.0 in stage 31.0 (TID 119, localhost, partition 1, PROCESS_LOCAL, 5498 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:55 INFO TaskSetManager: Starting task 2.0 in stage 31.0 (TID 120, localhost, partition 2, PROCESS_LOCAL, 5498 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:55 INFO TaskSetManager: Starting task 3.0 in stage 31.0 (TID 121, localhost, partition 3, PROCESS_LOCAL, 5498 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:55 INFO Executor: Running task 0.0 in stage 31.0 (TID 118)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:55 INFO Executor: Running task 2.0 in stage 31.0 (TID 120)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:55 INFO Executor: Running task 1.0 in stage 31.0 (TID 119)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:55 INFO Executor: Running task 3.0 in stage 31.0 (TID 121)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:59 INFO Executor: Finished task 1.0 in stage 31.0 (TID 119). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:59 INFO TaskSetManager: Finished task 1.0 in stage 31.0 (TID 119) in 3970 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:59 INFO Executor: Finished task 0.0 in stage 31.0 (TID 118). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:59 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 118) in 3983 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:59 INFO Executor: Finished task 2.0 in stage 31.0 (TID 120). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:59 INFO TaskSetManager: Finished task 2.0 in stage 31.0 (TID 120) in 4057 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:59 INFO Executor: Finished task 3.0 in stage 31.0 (TID 121). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:50:59 INFO TaskSetManager: Finished task 3.0 in stage 31.0 (TID 121) in 4183 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:59 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:50:59 INFO DAGScheduler: ResultStage 31 (foreach at Query.scala:127) finished in 4.184 s[0m
[0m[[31merror[0m] [0m16/06/07 19:50:59 INFO DAGScheduler: Job 29 finished: foreach at Query.scala:127, took 4.193492 s[0m
[0m[[31merror[0m] [0m16/06/07 19:50:59 WARN BlockManager: Asked to remove block broadcast_31_piece0, which does not exist[0m
[0m[[0minfo[0m] [0mExecution time: 4.207552058999999s[0m
[0m[[0minfo[0m] [0mRunning execution RDD: back-to-back maps iteration: 2, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:50:59 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 172.16.54.31:33061 in memory (size: 5.9 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:59 INFO ContextCleaner: Cleaned accumulator 3356[0m
[0m[[31merror[0m] [0m16/06/07 19:50:59 INFO ContextCleaner: Cleaned accumulator 3357[0m
[0m[[31merror[0m] [0m16/06/07 19:50:59 INFO SparkContext: Starting job: count at Benchmark.scala:455[0m
[0m[[31merror[0m] [0m16/06/07 19:50:59 INFO DAGScheduler: Got job 30 (count at Benchmark.scala:455) with 4 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:50:59 INFO DAGScheduler: Final stage: ResultStage 32 (count at Benchmark.scala:455)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:59 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:50:59 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:50:59 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[14] at map at DatasetPerformance.scala:99), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:50:59 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 3.4 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:59 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 1990.0 B, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:59 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 172.16.54.31:33061 (size: 1990.0 B, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:59 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:50:59 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 32 (MapPartitionsRDD[14] at map at DatasetPerformance.scala:99)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:59 INFO TaskSchedulerImpl: Adding task set 32.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:50:59 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 122, localhost, partition 0, PROCESS_LOCAL, 5415 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:59 INFO TaskSetManager: Starting task 1.0 in stage 32.0 (TID 123, localhost, partition 1, PROCESS_LOCAL, 5415 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:59 INFO TaskSetManager: Starting task 2.0 in stage 32.0 (TID 124, localhost, partition 2, PROCESS_LOCAL, 5415 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:59 INFO TaskSetManager: Starting task 3.0 in stage 32.0 (TID 125, localhost, partition 3, PROCESS_LOCAL, 5415 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:59 INFO Executor: Running task 2.0 in stage 32.0 (TID 124)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:59 INFO Executor: Running task 0.0 in stage 32.0 (TID 122)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:59 INFO Executor: Running task 1.0 in stage 32.0 (TID 123)[0m
[0m[[31merror[0m] [0m16/06/07 19:50:59 INFO Executor: Running task 3.0 in stage 32.0 (TID 125)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO Executor: Finished task 1.0 in stage 32.0 (TID 123). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO TaskSetManager: Finished task 1.0 in stage 32.0 (TID 123) in 4640 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO Executor: Finished task 0.0 in stage 32.0 (TID 122). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 122) in 4903 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO Executor: Finished task 3.0 in stage 32.0 (TID 125). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO TaskSetManager: Finished task 3.0 in stage 32.0 (TID 125) in 4926 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO Executor: Finished task 2.0 in stage 32.0 (TID 124). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO TaskSetManager: Finished task 2.0 in stage 32.0 (TID 124) in 4969 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO DAGScheduler: ResultStage 32 (count at Benchmark.scala:455) finished in 4.970 s[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO DAGScheduler: Job 30 finished: count at Benchmark.scala:455, took 4.975058 s[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 WARN BlockManager: Asked to remove block broadcast_32_piece0, which does not exist[0m
[0m[[0minfo[0m] [0mExecution time: 4.977009562s[0m
[0m[[0minfo[0m] [0mRunning execution DS: average iteration: 2, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 172.16.54.31:33061 in memory (size: 1990.0 B, free: 2.4 GB)[0m
[0m[[0minfo[0m] [0mExecution 'DS: average' failed: cannot resolve '`sum`' given input columns: [id];[0m
[0m[[0minfo[0m] [0mRunning execution DF: average iteration: 2, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO SparkSqlParser: Parsing command: avg(id)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO SparkSqlParser: Parsing command: avg(id)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO SparkContext: Starting job: collect at Query.scala:126[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO DAGScheduler: Registering RDD 126 (rdd at Query.scala:126)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO DAGScheduler: Got job 31 (collect at Query.scala:126) with 1 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO DAGScheduler: Final stage: ResultStage 34 (collect at Query.scala:126)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 33)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 33)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO DAGScheduler: Submitting ShuffleMapStage 33 (MapPartitionsRDD[126] at rdd at Query.scala:126), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 12.4 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 5.9 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 172.16.54.31:33061 (size: 5.9 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 33 (MapPartitionsRDD[126] at rdd at Query.scala:126)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO TaskSchedulerImpl: Adding task set 33.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 126, localhost, partition 0, PROCESS_LOCAL, 5477 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO TaskSetManager: Starting task 1.0 in stage 33.0 (TID 127, localhost, partition 1, PROCESS_LOCAL, 5477 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO TaskSetManager: Starting task 2.0 in stage 33.0 (TID 128, localhost, partition 2, PROCESS_LOCAL, 5477 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO TaskSetManager: Starting task 3.0 in stage 33.0 (TID 129, localhost, partition 3, PROCESS_LOCAL, 5477 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO Executor: Running task 0.0 in stage 33.0 (TID 126)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO Executor: Running task 2.0 in stage 33.0 (TID 128)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO Executor: Running task 1.0 in stage 33.0 (TID 127)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO Executor: Running task 3.0 in stage 33.0 (TID 129)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO Executor: Finished task 2.0 in stage 33.0 (TID 128). 1639 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO Executor: Finished task 1.0 in stage 33.0 (TID 127). 1639 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO TaskSetManager: Finished task 2.0 in stage 33.0 (TID 128) in 12 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO TaskSetManager: Finished task 1.0 in stage 33.0 (TID 127) in 14 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO Executor: Finished task 3.0 in stage 33.0 (TID 129). 1639 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO TaskSetManager: Finished task 3.0 in stage 33.0 (TID 129) in 14 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO Executor: Finished task 0.0 in stage 33.0 (TID 126). 1639 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO DAGScheduler: ShuffleMapStage 33 (rdd at Query.scala:126) finished in 0.021 s[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO DAGScheduler: looking for newly runnable stages[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO DAGScheduler: running: Set()[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO DAGScheduler: waiting: Set(ResultStage 34)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO DAGScheduler: failed: Set()[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[130] at rdd at Query.scala:126), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 19.0 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 9.1 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 172.16.54.31:33061 (size: 9.1 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 126) in 20 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[130] at rdd at Query.scala:126)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 130, localhost, partition 0, ANY, 5389 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO Executor: Running task 0.0 in stage 34.0 (TID 130)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO Executor: Finished task 0.0 in stage 34.0 (TID 130). 3529 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 130) in 6 ms on localhost (1/1)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO DAGScheduler: ResultStage 34 (collect at Query.scala:126) finished in 0.007 s[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO DAGScheduler: Job 31 finished: collect at Query.scala:126, took 0.040539 s[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 WARN BlockManager: Asked to remove block broadcast_33_piece0, which does not exist[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 172.16.54.31:33061 in memory (size: 9.1 KB, free: 2.4 GB)[0m
[0m[[0minfo[0m] [0mExecution time: 0.061039206s[0m
[0m[[0minfo[0m] [0mRunning execution RDD: average iteration: 2, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 172.16.54.31:33061 in memory (size: 5.9 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO ContextCleaner: Cleaned accumulator 3578[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO ContextCleaner: Cleaned accumulator 3579[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO ContextCleaner: Cleaned accumulator 3580[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO ContextCleaner: Cleaned accumulator 3581[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO ContextCleaner: Cleaned accumulator 3582[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO ContextCleaner: Cleaned accumulator 3583[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO ContextCleaner: Cleaned accumulator 3584[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO ContextCleaner: Cleaned accumulator 3585[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO ContextCleaner: Cleaned accumulator 3586[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO ContextCleaner: Cleaned accumulator 3587[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO ContextCleaner: Cleaned accumulator 3588[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO ContextCleaner: Cleaned accumulator 3589[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO ContextCleaner: Cleaned accumulator 3590[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO ContextCleaner: Cleaned accumulator 3591[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO ContextCleaner: Cleaned accumulator 3592[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO ContextCleaner: Cleaned accumulator 3593[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO ContextCleaner: Cleaned accumulator 3594[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO ContextCleaner: Cleaned shuffle 2[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO SparkContext: Starting job: reduce at DatasetPerformance.scala:139[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO DAGScheduler: Got job 32 (reduce at DatasetPerformance.scala:139) with 4 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO DAGScheduler: Final stage: ResultStage 35 (reduce at DatasetPerformance.scala:139)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[131] at map at DatasetPerformance.scala:139), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 2.9 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 1858.0 B, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 172.16.54.31:33061 (size: 1858.0 B, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 35 (MapPartitionsRDD[131] at map at DatasetPerformance.scala:139)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO TaskSchedulerImpl: Adding task set 35.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 131, localhost, partition 0, PROCESS_LOCAL, 5488 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO TaskSetManager: Starting task 1.0 in stage 35.0 (TID 132, localhost, partition 1, PROCESS_LOCAL, 5488 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO TaskSetManager: Starting task 2.0 in stage 35.0 (TID 133, localhost, partition 2, PROCESS_LOCAL, 5488 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO TaskSetManager: Starting task 3.0 in stage 35.0 (TID 134, localhost, partition 3, PROCESS_LOCAL, 5488 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO Executor: Running task 2.0 in stage 35.0 (TID 133)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO Executor: Running task 1.0 in stage 35.0 (TID 132)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO Executor: Running task 0.0 in stage 35.0 (TID 131)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO Executor: Running task 3.0 in stage 35.0 (TID 134)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO Executor: Finished task 2.0 in stage 35.0 (TID 133). 917 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO Executor: Finished task 1.0 in stage 35.0 (TID 132). 917 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO TaskSetManager: Finished task 2.0 in stage 35.0 (TID 133) in 28 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO TaskSetManager: Finished task 1.0 in stage 35.0 (TID 132) in 28 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO Executor: Finished task 0.0 in stage 35.0 (TID 131). 917 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 131) in 34 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO Executor: Finished task 3.0 in stage 35.0 (TID 134). 917 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO TaskSetManager: Finished task 3.0 in stage 35.0 (TID 134) in 34 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO DAGScheduler: ResultStage 35 (reduce at DatasetPerformance.scala:139) finished in 0.036 s[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO DAGScheduler: Job 32 finished: reduce at DatasetPerformance.scala:139, took 0.041501 s[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 WARN BlockManager: Asked to remove block broadcast_35_piece0, which does not exist[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 172.16.54.31:33061 in memory (size: 1858.0 B, free: 2.4 GB)[0m
[0m[[0minfo[0m] [0mExecution time: 0.045305748s[0m
[0m[[0minfo[0m] [0mRunning execution DS: range iteration: 2, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO SparkContext: Starting job: foreach at Query.scala:127[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO DAGScheduler: Got job 33 (foreach at Query.scala:127) with 4 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO DAGScheduler: Final stage: ResultStage 36 (foreach at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[136] at rdd at Query.scala:127), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 9.9 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 5.1 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 172.16.54.31:33061 (size: 5.1 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 36 (MapPartitionsRDD[136] at rdd at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO TaskSchedulerImpl: Adding task set 36.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 135, localhost, partition 0, PROCESS_LOCAL, 5486 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO TaskSetManager: Starting task 1.0 in stage 36.0 (TID 136, localhost, partition 1, PROCESS_LOCAL, 5486 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO TaskSetManager: Starting task 2.0 in stage 36.0 (TID 137, localhost, partition 2, PROCESS_LOCAL, 5486 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO TaskSetManager: Starting task 3.0 in stage 36.0 (TID 138, localhost, partition 3, PROCESS_LOCAL, 5486 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO Executor: Running task 1.0 in stage 36.0 (TID 136)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO Executor: Running task 0.0 in stage 36.0 (TID 135)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO Executor: Running task 2.0 in stage 36.0 (TID 137)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:04 INFO Executor: Running task 3.0 in stage 36.0 (TID 138)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:07 INFO Executor: Finished task 1.0 in stage 36.0 (TID 136). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:07 INFO TaskSetManager: Finished task 1.0 in stage 36.0 (TID 136) in 3135 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:08 INFO Executor: Finished task 2.0 in stage 36.0 (TID 137). 1222 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:08 INFO TaskSetManager: Finished task 2.0 in stage 36.0 (TID 137) in 3596 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:08 INFO Executor: Finished task 0.0 in stage 36.0 (TID 135). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:08 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 135) in 3611 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:08 INFO Executor: Finished task 3.0 in stage 36.0 (TID 138). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:08 INFO TaskSetManager: Finished task 3.0 in stage 36.0 (TID 138) in 3665 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:08 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:51:08 INFO DAGScheduler: ResultStage 36 (foreach at Query.scala:127) finished in 3.666 s[0m
[0m[[31merror[0m] [0m16/06/07 19:51:08 INFO DAGScheduler: Job 33 finished: foreach at Query.scala:127, took 3.681852 s[0m
[0m[[0minfo[0m] [0mExecution time: 3.69435274s[0m
[0m[[0minfo[0m] [0mRunning execution DF: range iteration: 2, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:51:08 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 172.16.54.31:33061 in memory (size: 5.1 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:08 INFO ContextCleaner: Cleaned accumulator 3859[0m
[0m[[31merror[0m] [0m16/06/07 19:51:08 INFO ContextCleaner: Cleaned accumulator 3860[0m
[0m[[31merror[0m] [0m16/06/07 19:51:08 INFO SparkContext: Starting job: foreach at Query.scala:127[0m
[0m[[31merror[0m] [0m16/06/07 19:51:08 INFO DAGScheduler: Got job 34 (foreach at Query.scala:127) with 4 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:51:08 INFO DAGScheduler: Final stage: ResultStage 37 (foreach at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:08 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:51:08 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:51:08 INFO DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[141] at rdd at Query.scala:127), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:51:08 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 9.9 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:08 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 5.1 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:08 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 172.16.54.31:33061 (size: 5.1 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:08 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:51:08 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 37 (MapPartitionsRDD[141] at rdd at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:08 INFO TaskSchedulerImpl: Adding task set 37.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:51:08 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 139, localhost, partition 0, PROCESS_LOCAL, 5486 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:08 INFO TaskSetManager: Starting task 1.0 in stage 37.0 (TID 140, localhost, partition 1, PROCESS_LOCAL, 5486 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:08 INFO TaskSetManager: Starting task 2.0 in stage 37.0 (TID 141, localhost, partition 2, PROCESS_LOCAL, 5486 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:08 INFO TaskSetManager: Starting task 3.0 in stage 37.0 (TID 142, localhost, partition 3, PROCESS_LOCAL, 5486 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:08 INFO Executor: Running task 3.0 in stage 37.0 (TID 142)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:08 INFO Executor: Running task 1.0 in stage 37.0 (TID 140)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:08 INFO Executor: Running task 2.0 in stage 37.0 (TID 141)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:08 INFO Executor: Running task 0.0 in stage 37.0 (TID 139)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:11 INFO Executor: Finished task 1.0 in stage 37.0 (TID 140). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:11 INFO TaskSetManager: Finished task 1.0 in stage 37.0 (TID 140) in 3254 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:11 INFO Executor: Finished task 2.0 in stage 37.0 (TID 141). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:11 INFO TaskSetManager: Finished task 2.0 in stage 37.0 (TID 141) in 3283 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:11 INFO Executor: Finished task 0.0 in stage 37.0 (TID 139). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:11 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 139) in 3393 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:11 INFO Executor: Finished task 3.0 in stage 37.0 (TID 142). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:11 INFO TaskSetManager: Finished task 3.0 in stage 37.0 (TID 142) in 3446 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:11 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:51:11 INFO DAGScheduler: ResultStage 37 (foreach at Query.scala:127) finished in 3.449 s[0m
[0m[[31merror[0m] [0m16/06/07 19:51:11 INFO DAGScheduler: Job 34 finished: foreach at Query.scala:127, took 3.453428 s[0m
[0m[[31merror[0m] [0m16/06/07 19:51:12 WARN BlockManager: Asked to remove block broadcast_37_piece0, which does not exist[0m
[0m[[0minfo[0m] [0mExecution time: 3.462199326s[0m
[0m[[0minfo[0m] [0mRunning execution RDD: range iteration: 2, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:51:12 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 172.16.54.31:33061 in memory (size: 5.1 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:12 INFO SparkContext: Starting job: count at Benchmark.scala:455[0m
[0m[[31merror[0m] [0m16/06/07 19:51:12 INFO DAGScheduler: Got job 35 (count at Benchmark.scala:455) with 4 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:51:12 INFO DAGScheduler: Final stage: ResultStage 38 (count at Benchmark.scala:455)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:12 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:51:12 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:51:12 INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[4] at map at DatasetPerformance.scala:51), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:51:12 INFO ContextCleaner: Cleaned accumulator 3971[0m
[0m[[31merror[0m] [0m16/06/07 19:51:12 INFO ContextCleaner: Cleaned accumulator 3972[0m
[0m[[31merror[0m] [0m16/06/07 19:51:12 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 2.9 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:12 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 1860.0 B, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:12 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 172.16.54.31:33061 (size: 1860.0 B, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:12 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:51:12 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 38 (MapPartitionsRDD[4] at map at DatasetPerformance.scala:51)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:12 INFO TaskSchedulerImpl: Adding task set 38.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:51:12 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 143, localhost, partition 0, PROCESS_LOCAL, 5403 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:12 INFO TaskSetManager: Starting task 1.0 in stage 38.0 (TID 144, localhost, partition 1, PROCESS_LOCAL, 5403 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:12 INFO TaskSetManager: Starting task 2.0 in stage 38.0 (TID 145, localhost, partition 2, PROCESS_LOCAL, 5403 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:12 INFO TaskSetManager: Starting task 3.0 in stage 38.0 (TID 146, localhost, partition 3, PROCESS_LOCAL, 5403 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:12 INFO Executor: Running task 0.0 in stage 38.0 (TID 143)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:12 INFO Executor: Running task 1.0 in stage 38.0 (TID 144)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:12 INFO Executor: Running task 2.0 in stage 38.0 (TID 145)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:12 INFO Executor: Running task 3.0 in stage 38.0 (TID 146)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:13 INFO Executor: Finished task 1.0 in stage 38.0 (TID 144). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:13 INFO TaskSetManager: Finished task 1.0 in stage 38.0 (TID 144) in 1399 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:13 INFO Executor: Finished task 2.0 in stage 38.0 (TID 145). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:13 INFO TaskSetManager: Finished task 2.0 in stage 38.0 (TID 145) in 1484 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:13 INFO Executor: Finished task 0.0 in stage 38.0 (TID 143). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:13 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 143) in 1492 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:13 INFO Executor: Finished task 3.0 in stage 38.0 (TID 146). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:13 INFO TaskSetManager: Finished task 3.0 in stage 38.0 (TID 146) in 1520 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:13 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:51:13 INFO DAGScheduler: ResultStage 38 (count at Benchmark.scala:455) finished in 1.522 s[0m
[0m[[31merror[0m] [0m16/06/07 19:51:13 INFO DAGScheduler: Job 35 finished: count at Benchmark.scala:455, took 1.528519 s[0m
[0m[[0minfo[0m] [0mExecution time: 1.530340132s[0m
[0m[[0minfo[0m] [0mRunning execution DS: back-to-back filters iteration: 2, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:51:13 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 172.16.54.31:33061 in memory (size: 1860.0 B, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:13 WARN BlockManager: Asked to remove block broadcast_38_piece0, which does not exist[0m
[0m[[31merror[0m] [0m16/06/07 19:51:13 INFO SparkContext: Starting job: foreach at Query.scala:127[0m
[0m[[31merror[0m] [0m16/06/07 19:51:13 INFO DAGScheduler: Got job 36 (foreach at Query.scala:127) with 4 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:51:13 INFO DAGScheduler: Final stage: ResultStage 39 (foreach at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:13 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:51:13 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:51:13 INFO DAGScheduler: Submitting ResultStage 39 (MapPartitionsRDD[146] at rdd at Query.scala:127), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:51:13 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 18.9 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:13 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 7.9 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:13 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 172.16.54.31:33061 (size: 7.9 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:13 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:51:13 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 39 (MapPartitionsRDD[146] at rdd at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:13 INFO TaskSchedulerImpl: Adding task set 39.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:51:13 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 147, localhost, partition 0, PROCESS_LOCAL, 5501 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:13 INFO TaskSetManager: Starting task 1.0 in stage 39.0 (TID 148, localhost, partition 1, PROCESS_LOCAL, 5501 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:13 INFO TaskSetManager: Starting task 2.0 in stage 39.0 (TID 149, localhost, partition 2, PROCESS_LOCAL, 5501 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:13 INFO TaskSetManager: Starting task 3.0 in stage 39.0 (TID 150, localhost, partition 3, PROCESS_LOCAL, 5501 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:13 INFO Executor: Running task 0.0 in stage 39.0 (TID 147)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:13 INFO Executor: Running task 1.0 in stage 39.0 (TID 148)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:13 INFO Executor: Running task 3.0 in stage 39.0 (TID 150)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:13 INFO Executor: Running task 2.0 in stage 39.0 (TID 149)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:17 INFO Executor: Finished task 3.0 in stage 39.0 (TID 150). 1197 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:17 INFO TaskSetManager: Finished task 3.0 in stage 39.0 (TID 150) in 3994 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:17 INFO Executor: Finished task 1.0 in stage 39.0 (TID 148). 1197 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:17 INFO TaskSetManager: Finished task 1.0 in stage 39.0 (TID 148) in 4086 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:17 INFO Executor: Finished task 2.0 in stage 39.0 (TID 149). 1197 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:17 INFO TaskSetManager: Finished task 2.0 in stage 39.0 (TID 149) in 4158 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:17 INFO Executor: Finished task 0.0 in stage 39.0 (TID 147). 1197 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:17 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 147) in 4203 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:17 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:51:17 INFO DAGScheduler: ResultStage 39 (foreach at Query.scala:127) finished in 4.203 s[0m
[0m[[31merror[0m] [0m16/06/07 19:51:17 INFO DAGScheduler: Job 36 finished: foreach at Query.scala:127, took 4.213422 s[0m
[0m[[0minfo[0m] [0mExecution time: 4.234821403s[0m
[0m[[0minfo[0m] [0mRunning execution DF: back-to-back filters iteration: 2, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:51:18 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 172.16.54.31:33061 in memory (size: 7.9 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:18 INFO SparkSqlParser: Parsing command: id % 100 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:51:18 INFO ContextCleaner: Cleaned accumulator 4193[0m
[0m[[31merror[0m] [0m16/06/07 19:51:18 INFO ContextCleaner: Cleaned accumulator 4194[0m
[0m[[31merror[0m] [0m16/06/07 19:51:18 INFO ContextCleaner: Cleaned accumulator 4195[0m
[0m[[31merror[0m] [0m16/06/07 19:51:18 INFO SparkSqlParser: Parsing command: id % 101 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:51:18 INFO SparkSqlParser: Parsing command: id % 102 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:51:18 INFO SparkSqlParser: Parsing command: id % 103 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:51:18 INFO SparkSqlParser: Parsing command: id % 100 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:51:18 INFO SparkSqlParser: Parsing command: id % 101 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:51:18 INFO SparkSqlParser: Parsing command: id % 102 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:51:18 INFO SparkSqlParser: Parsing command: id % 103 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:51:18 INFO SparkContext: Starting job: foreach at Query.scala:127[0m
[0m[[31merror[0m] [0m16/06/07 19:51:18 INFO DAGScheduler: Got job 37 (foreach at Query.scala:127) with 4 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:51:18 INFO DAGScheduler: Final stage: ResultStage 40 (foreach at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:18 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:51:18 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:51:18 INFO DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[151] at rdd at Query.scala:127), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:51:18 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 15.0 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:18 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 6.7 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:18 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 172.16.54.31:33061 (size: 6.7 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:18 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:51:18 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 40 (MapPartitionsRDD[151] at rdd at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:18 INFO TaskSchedulerImpl: Adding task set 40.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:51:18 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 151, localhost, partition 0, PROCESS_LOCAL, 5501 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:18 INFO TaskSetManager: Starting task 1.0 in stage 40.0 (TID 152, localhost, partition 1, PROCESS_LOCAL, 5501 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:18 INFO TaskSetManager: Starting task 2.0 in stage 40.0 (TID 153, localhost, partition 2, PROCESS_LOCAL, 5501 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:18 INFO TaskSetManager: Starting task 3.0 in stage 40.0 (TID 154, localhost, partition 3, PROCESS_LOCAL, 5501 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:18 INFO Executor: Running task 0.0 in stage 40.0 (TID 151)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:18 INFO Executor: Running task 1.0 in stage 40.0 (TID 152)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:18 INFO Executor: Running task 2.0 in stage 40.0 (TID 153)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:18 INFO Executor: Running task 3.0 in stage 40.0 (TID 154)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:21 INFO Executor: Finished task 0.0 in stage 40.0 (TID 151). 1197 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:21 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 151) in 3658 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:21 INFO Executor: Finished task 1.0 in stage 40.0 (TID 152). 1197 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:21 INFO TaskSetManager: Finished task 1.0 in stage 40.0 (TID 152) in 3711 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:21 INFO Executor: Finished task 2.0 in stage 40.0 (TID 153). 1197 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:21 INFO TaskSetManager: Finished task 2.0 in stage 40.0 (TID 153) in 3788 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:21 INFO Executor: Finished task 3.0 in stage 40.0 (TID 154). 1197 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:21 INFO TaskSetManager: Finished task 3.0 in stage 40.0 (TID 154) in 3918 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:21 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:51:21 INFO DAGScheduler: ResultStage 40 (foreach at Query.scala:127) finished in 3.889 s[0m
[0m[[31merror[0m] [0m16/06/07 19:51:21 INFO DAGScheduler: Job 37 finished: foreach at Query.scala:127, took 3.930403 s[0m
[0m[[0minfo[0m] [0mExecution time: 3.9483038780000004s[0m
[0m[[0minfo[0m] [0mRunning execution RDD: back-to-back filters iteration: 2, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:51:22 WARN BlockManager: Asked to remove block broadcast_40_piece0, which does not exist[0m
[0m[[31merror[0m] [0m16/06/07 19:51:22 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 172.16.54.31:33061 in memory (size: 6.7 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:22 INFO ContextCleaner: Cleaned accumulator 4306[0m
[0m[[31merror[0m] [0m16/06/07 19:51:22 INFO ContextCleaner: Cleaned accumulator 4307[0m
[0m[[31merror[0m] [0m16/06/07 19:51:22 INFO ContextCleaner: Cleaned accumulator 4308[0m
[0m[[31merror[0m] [0m16/06/07 19:51:22 INFO SparkContext: Starting job: count at Benchmark.scala:455[0m
[0m[[31merror[0m] [0m16/06/07 19:51:22 INFO DAGScheduler: Got job 38 (count at Benchmark.scala:455) with 4 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:51:22 INFO DAGScheduler: Final stage: ResultStage 41 (count at Benchmark.scala:455)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:22 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:51:22 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:51:22 INFO DAGScheduler: Submitting ResultStage 41 (MapPartitionsRDD[9] at filter at DatasetPerformance.scala:75), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:51:22 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 3.5 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:22 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 1991.0 B, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:22 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 172.16.54.31:33061 (size: 1991.0 B, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:22 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:51:22 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 41 (MapPartitionsRDD[9] at filter at DatasetPerformance.scala:75)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:22 INFO TaskSchedulerImpl: Adding task set 41.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:51:22 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 155, localhost, partition 0, PROCESS_LOCAL, 5418 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:22 INFO TaskSetManager: Starting task 1.0 in stage 41.0 (TID 156, localhost, partition 1, PROCESS_LOCAL, 5418 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:22 INFO TaskSetManager: Starting task 2.0 in stage 41.0 (TID 157, localhost, partition 2, PROCESS_LOCAL, 5418 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:22 INFO TaskSetManager: Starting task 3.0 in stage 41.0 (TID 158, localhost, partition 3, PROCESS_LOCAL, 5418 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:22 INFO Executor: Running task 0.0 in stage 41.0 (TID 155)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:22 INFO Executor: Running task 1.0 in stage 41.0 (TID 156)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:22 INFO Executor: Running task 2.0 in stage 41.0 (TID 157)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:22 INFO Executor: Running task 3.0 in stage 41.0 (TID 158)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:25 INFO Executor: Finished task 1.0 in stage 41.0 (TID 156). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:25 INFO TaskSetManager: Finished task 1.0 in stage 41.0 (TID 156) in 3603 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:25 INFO Executor: Finished task 2.0 in stage 41.0 (TID 157). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:25 INFO TaskSetManager: Finished task 2.0 in stage 41.0 (TID 157) in 3742 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:25 INFO Executor: Finished task 3.0 in stage 41.0 (TID 158). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:25 INFO TaskSetManager: Finished task 3.0 in stage 41.0 (TID 158) in 3892 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:25 INFO Executor: Finished task 0.0 in stage 41.0 (TID 155). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:25 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 155) in 3926 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:25 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:51:25 INFO DAGScheduler: ResultStage 41 (count at Benchmark.scala:455) finished in 3.927 s[0m
[0m[[31merror[0m] [0m16/06/07 19:51:25 INFO DAGScheduler: Job 38 finished: count at Benchmark.scala:455, took 3.935271 s[0m
[0m[[0minfo[0m] [0mExecution time: 3.9367086049999997s[0m
[0m[[0minfo[0m] [0mRunning execution DS: back-to-back maps iteration: 2, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:51:26 WARN BlockManager: Asked to remove block broadcast_41_piece0, which does not exist[0m
[0m[[31merror[0m] [0m16/06/07 19:51:26 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 172.16.54.31:33061 in memory (size: 1991.0 B, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:26 INFO SparkContext: Starting job: foreach at Query.scala:127[0m
[0m[[31merror[0m] [0m16/06/07 19:51:26 INFO DAGScheduler: Got job 39 (foreach at Query.scala:127) with 4 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:51:26 INFO DAGScheduler: Final stage: ResultStage 42 (foreach at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:26 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:51:26 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:51:26 INFO DAGScheduler: Submitting ResultStage 42 (MapPartitionsRDD[156] at rdd at Query.scala:127), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:51:26 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 21.3 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:26 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 8.0 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:26 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 172.16.54.31:33061 (size: 8.0 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:26 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:51:26 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 42 (MapPartitionsRDD[156] at rdd at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:26 INFO TaskSchedulerImpl: Adding task set 42.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:51:26 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 159, localhost, partition 0, PROCESS_LOCAL, 5498 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:26 INFO TaskSetManager: Starting task 1.0 in stage 42.0 (TID 160, localhost, partition 1, PROCESS_LOCAL, 5498 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:26 INFO TaskSetManager: Starting task 2.0 in stage 42.0 (TID 161, localhost, partition 2, PROCESS_LOCAL, 5498 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:26 INFO TaskSetManager: Starting task 3.0 in stage 42.0 (TID 162, localhost, partition 3, PROCESS_LOCAL, 5498 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:26 INFO Executor: Running task 0.0 in stage 42.0 (TID 159)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:26 INFO Executor: Running task 1.0 in stage 42.0 (TID 160)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:26 INFO Executor: Running task 2.0 in stage 42.0 (TID 161)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:26 INFO Executor: Running task 3.0 in stage 42.0 (TID 162)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:29 INFO Executor: Finished task 0.0 in stage 42.0 (TID 159). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:29 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 159) in 3853 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:30 INFO Executor: Finished task 3.0 in stage 42.0 (TID 162). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:30 INFO TaskSetManager: Finished task 3.0 in stage 42.0 (TID 162) in 3875 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:30 INFO Executor: Finished task 1.0 in stage 42.0 (TID 160). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:30 INFO TaskSetManager: Finished task 1.0 in stage 42.0 (TID 160) in 3894 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:30 INFO Executor: Finished task 2.0 in stage 42.0 (TID 161). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:30 INFO TaskSetManager: Finished task 2.0 in stage 42.0 (TID 161) in 4119 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:30 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:51:30 INFO DAGScheduler: ResultStage 42 (foreach at Query.scala:127) finished in 4.120 s[0m
[0m[[31merror[0m] [0m16/06/07 19:51:30 INFO DAGScheduler: Job 39 finished: foreach at Query.scala:127, took 4.127151 s[0m
[0m[[31merror[0m] [0m16/06/07 19:51:30 INFO ContextCleaner: Cleaned accumulator 4529[0m
[0m[[31merror[0m] [0m16/06/07 19:51:30 INFO ContextCleaner: Cleaned accumulator 4530[0m
[0m[[0minfo[0m] [0mExecution time: 4.141263529s[0m
[0m[[31merror[0m] [0m16/06/07 19:51:30 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 172.16.54.31:33061 in memory (size: 8.0 KB, free: 2.4 GB)[0m
[0m[[0minfo[0m] [0mRunning execution DF: back-to-back maps iteration: 2, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:51:30 WARN BlockManager: Asked to remove block broadcast_42_piece0, which does not exist[0m
[0m[[31merror[0m] [0m16/06/07 19:51:30 INFO SparkContext: Starting job: foreach at Query.scala:127[0m
[0m[[31merror[0m] [0m16/06/07 19:51:30 INFO DAGScheduler: Got job 40 (foreach at Query.scala:127) with 4 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:51:30 INFO DAGScheduler: Final stage: ResultStage 43 (foreach at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:30 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:51:30 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:51:30 INFO DAGScheduler: Submitting ResultStage 43 (MapPartitionsRDD[161] at rdd at Query.scala:127), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:51:30 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 12.0 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:30 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 5.9 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:30 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 172.16.54.31:33061 (size: 5.9 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:30 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:51:30 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 43 (MapPartitionsRDD[161] at rdd at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:30 INFO TaskSchedulerImpl: Adding task set 43.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:51:30 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 163, localhost, partition 0, PROCESS_LOCAL, 5498 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:30 INFO TaskSetManager: Starting task 1.0 in stage 43.0 (TID 164, localhost, partition 1, PROCESS_LOCAL, 5498 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:30 INFO TaskSetManager: Starting task 2.0 in stage 43.0 (TID 165, localhost, partition 2, PROCESS_LOCAL, 5498 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:30 INFO TaskSetManager: Starting task 3.0 in stage 43.0 (TID 166, localhost, partition 3, PROCESS_LOCAL, 5498 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:30 INFO Executor: Running task 0.0 in stage 43.0 (TID 163)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:30 INFO Executor: Running task 1.0 in stage 43.0 (TID 164)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:30 INFO Executor: Running task 3.0 in stage 43.0 (TID 166)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:30 INFO Executor: Running task 2.0 in stage 43.0 (TID 165)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:33 INFO Executor: Finished task 1.0 in stage 43.0 (TID 164). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:33 INFO TaskSetManager: Finished task 1.0 in stage 43.0 (TID 164) in 3368 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:33 INFO Executor: Finished task 2.0 in stage 43.0 (TID 165). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:33 INFO TaskSetManager: Finished task 2.0 in stage 43.0 (TID 165) in 3550 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:34 INFO Executor: Finished task 3.0 in stage 43.0 (TID 166). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:34 INFO TaskSetManager: Finished task 3.0 in stage 43.0 (TID 166) in 3651 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:34 INFO Executor: Finished task 0.0 in stage 43.0 (TID 163). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:34 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 163) in 3696 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:34 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:51:34 INFO DAGScheduler: ResultStage 43 (foreach at Query.scala:127) finished in 3.696 s[0m
[0m[[31merror[0m] [0m16/06/07 19:51:34 INFO DAGScheduler: Job 40 finished: foreach at Query.scala:127, took 3.702601 s[0m
[0m[[31merror[0m] [0m16/06/07 19:51:34 INFO ContextCleaner: Cleaned accumulator 4641[0m
[0m[[31merror[0m] [0m16/06/07 19:51:34 INFO ContextCleaner: Cleaned accumulator 4642[0m
[0m[[0minfo[0m] [0mExecution time: 3.7128123580000003s[0m
[0m[[0minfo[0m] [0mRunning execution RDD: back-to-back maps iteration: 2, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:51:34 WARN BlockManager: Asked to remove block broadcast_43_piece0, which does not exist[0m
[0m[[31merror[0m] [0m16/06/07 19:51:34 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 172.16.54.31:33061 in memory (size: 5.9 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:34 INFO SparkContext: Starting job: count at Benchmark.scala:455[0m
[0m[[31merror[0m] [0m16/06/07 19:51:34 INFO DAGScheduler: Got job 41 (count at Benchmark.scala:455) with 4 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:51:34 INFO DAGScheduler: Final stage: ResultStage 44 (count at Benchmark.scala:455)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:34 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:51:34 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:51:34 INFO DAGScheduler: Submitting ResultStage 44 (MapPartitionsRDD[14] at map at DatasetPerformance.scala:99), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:51:34 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 3.4 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:34 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 1990.0 B, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:34 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 172.16.54.31:33061 (size: 1990.0 B, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:34 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:51:34 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 44 (MapPartitionsRDD[14] at map at DatasetPerformance.scala:99)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:34 INFO TaskSchedulerImpl: Adding task set 44.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:51:34 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 167, localhost, partition 0, PROCESS_LOCAL, 5415 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:34 INFO TaskSetManager: Starting task 1.0 in stage 44.0 (TID 168, localhost, partition 1, PROCESS_LOCAL, 5415 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:34 INFO TaskSetManager: Starting task 2.0 in stage 44.0 (TID 169, localhost, partition 2, PROCESS_LOCAL, 5415 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:34 INFO TaskSetManager: Starting task 3.0 in stage 44.0 (TID 170, localhost, partition 3, PROCESS_LOCAL, 5415 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:34 INFO Executor: Running task 3.0 in stage 44.0 (TID 170)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:34 INFO Executor: Running task 1.0 in stage 44.0 (TID 168)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:34 INFO Executor: Running task 0.0 in stage 44.0 (TID 167)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:34 INFO Executor: Running task 2.0 in stage 44.0 (TID 169)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:38 INFO Executor: Finished task 0.0 in stage 44.0 (TID 167). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:38 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 167) in 4752 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO Executor: Finished task 1.0 in stage 44.0 (TID 168). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO TaskSetManager: Finished task 1.0 in stage 44.0 (TID 168) in 4989 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO Executor: Finished task 2.0 in stage 44.0 (TID 169). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO TaskSetManager: Finished task 2.0 in stage 44.0 (TID 169) in 5094 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO Executor: Finished task 3.0 in stage 44.0 (TID 170). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO TaskSetManager: Finished task 3.0 in stage 44.0 (TID 170) in 5146 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO DAGScheduler: ResultStage 44 (count at Benchmark.scala:455) finished in 5.148 s[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO DAGScheduler: Job 41 finished: count at Benchmark.scala:455, took 5.151758 s[0m
[0m[[0minfo[0m] [0mExecution time: 5.153412994s[0m
[0m[[0minfo[0m] [0mRunning execution DS: average iteration: 2, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 172.16.54.31:33061 in memory (size: 1990.0 B, free: 2.4 GB)[0m
[0m[[0minfo[0m] [0mExecution 'DS: average' failed: cannot resolve '`sum`' given input columns: [id];[0m
[0m[[0minfo[0m] [0mRunning execution DF: average iteration: 2, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO SparkSqlParser: Parsing command: avg(id)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO SparkSqlParser: Parsing command: avg(id)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO SparkContext: Starting job: collect at Query.scala:126[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO DAGScheduler: Registering RDD 165 (rdd at Query.scala:126)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO DAGScheduler: Got job 42 (collect at Query.scala:126) with 1 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO DAGScheduler: Final stage: ResultStage 46 (collect at Query.scala:126)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 45)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 45)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO DAGScheduler: Submitting ShuffleMapStage 45 (MapPartitionsRDD[165] at rdd at Query.scala:126), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 12.4 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 5.9 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 172.16.54.31:33061 (size: 5.9 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 45 (MapPartitionsRDD[165] at rdd at Query.scala:126)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO TaskSchedulerImpl: Adding task set 45.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 171, localhost, partition 0, PROCESS_LOCAL, 5477 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO TaskSetManager: Starting task 1.0 in stage 45.0 (TID 172, localhost, partition 1, PROCESS_LOCAL, 5477 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO TaskSetManager: Starting task 2.0 in stage 45.0 (TID 173, localhost, partition 2, PROCESS_LOCAL, 5477 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO TaskSetManager: Starting task 3.0 in stage 45.0 (TID 174, localhost, partition 3, PROCESS_LOCAL, 5477 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO Executor: Running task 2.0 in stage 45.0 (TID 173)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO Executor: Running task 0.0 in stage 45.0 (TID 171)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO Executor: Running task 1.0 in stage 45.0 (TID 172)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO Executor: Running task 3.0 in stage 45.0 (TID 174)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO Executor: Finished task 1.0 in stage 45.0 (TID 172). 1639 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO Executor: Finished task 2.0 in stage 45.0 (TID 173). 1639 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO TaskSetManager: Finished task 1.0 in stage 45.0 (TID 172) in 10 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO TaskSetManager: Finished task 2.0 in stage 45.0 (TID 173) in 12 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO Executor: Finished task 3.0 in stage 45.0 (TID 174). 1639 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO TaskSetManager: Finished task 3.0 in stage 45.0 (TID 174) in 13 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO Executor: Finished task 0.0 in stage 45.0 (TID 171). 1639 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 171) in 19 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO DAGScheduler: ShuffleMapStage 45 (rdd at Query.scala:126) finished in 0.019 s[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO DAGScheduler: looking for newly runnable stages[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO DAGScheduler: running: Set()[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO DAGScheduler: waiting: Set(ResultStage 46)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO DAGScheduler: failed: Set()[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO DAGScheduler: Submitting ResultStage 46 (MapPartitionsRDD[169] at rdd at Query.scala:126), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 19.0 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 9.1 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 172.16.54.31:33061 (size: 9.1 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 46 (MapPartitionsRDD[169] at rdd at Query.scala:126)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO TaskSchedulerImpl: Adding task set 46.0 with 1 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 175, localhost, partition 0, ANY, 5389 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO Executor: Running task 0.0 in stage 46.0 (TID 175)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO Executor: Finished task 0.0 in stage 46.0 (TID 175). 3529 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 175) in 12 ms on localhost (1/1)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO DAGScheduler: ResultStage 46 (collect at Query.scala:126) finished in 0.013 s[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO DAGScheduler: Job 42 finished: collect at Query.scala:126, took 0.040356 s[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO ContextCleaner: Cleaned accumulator 4863[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO ContextCleaner: Cleaned accumulator 4864[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO ContextCleaner: Cleaned accumulator 4865[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO ContextCleaner: Cleaned accumulator 4866[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO ContextCleaner: Cleaned accumulator 4867[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO ContextCleaner: Cleaned accumulator 4868[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO ContextCleaner: Cleaned accumulator 4869[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO ContextCleaner: Cleaned accumulator 4870[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO ContextCleaner: Cleaned accumulator 4871[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO ContextCleaner: Cleaned accumulator 4872[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO ContextCleaner: Cleaned accumulator 4873[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO ContextCleaner: Cleaned accumulator 4874[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO ContextCleaner: Cleaned accumulator 4875[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO ContextCleaner: Cleaned accumulator 4876[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO ContextCleaner: Cleaned accumulator 4877[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO ContextCleaner: Cleaned accumulator 4878[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO ContextCleaner: Cleaned accumulator 4879[0m
[0m[[0minfo[0m] [0mExecution time: 0.060495605s[0m
[0m[[0minfo[0m] [0mRunning execution RDD: average iteration: 2, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO ContextCleaner: Cleaned shuffle 3[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 172.16.54.31:33061 in memory (size: 9.1 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 WARN BlockManager: Asked to remove block broadcast_45_piece0, which does not exist[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 172.16.54.31:33061 in memory (size: 5.9 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO SparkContext: Starting job: reduce at DatasetPerformance.scala:139[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO DAGScheduler: Got job 43 (reduce at DatasetPerformance.scala:139) with 4 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO DAGScheduler: Final stage: ResultStage 47 (reduce at DatasetPerformance.scala:139)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO DAGScheduler: Submitting ResultStage 47 (MapPartitionsRDD[170] at map at DatasetPerformance.scala:139), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 2.9 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 1858.0 B, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 172.16.54.31:33061 (size: 1858.0 B, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 47 (MapPartitionsRDD[170] at map at DatasetPerformance.scala:139)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO TaskSchedulerImpl: Adding task set 47.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 176, localhost, partition 0, PROCESS_LOCAL, 5488 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO TaskSetManager: Starting task 1.0 in stage 47.0 (TID 177, localhost, partition 1, PROCESS_LOCAL, 5488 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO TaskSetManager: Starting task 2.0 in stage 47.0 (TID 178, localhost, partition 2, PROCESS_LOCAL, 5488 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO TaskSetManager: Starting task 3.0 in stage 47.0 (TID 179, localhost, partition 3, PROCESS_LOCAL, 5488 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO Executor: Running task 0.0 in stage 47.0 (TID 176)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO Executor: Running task 1.0 in stage 47.0 (TID 177)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO Executor: Running task 2.0 in stage 47.0 (TID 178)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO Executor: Running task 3.0 in stage 47.0 (TID 179)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO Executor: Finished task 1.0 in stage 47.0 (TID 177). 917 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO TaskSetManager: Finished task 1.0 in stage 47.0 (TID 177) in 19 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO Executor: Finished task 3.0 in stage 47.0 (TID 179). 917 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO TaskSetManager: Finished task 3.0 in stage 47.0 (TID 179) in 23 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO Executor: Finished task 0.0 in stage 47.0 (TID 176). 917 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 176) in 29 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO Executor: Finished task 2.0 in stage 47.0 (TID 178). 917 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO TaskSetManager: Finished task 2.0 in stage 47.0 (TID 178) in 28 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO DAGScheduler: ResultStage 47 (reduce at DatasetPerformance.scala:139) finished in 0.031 s[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO DAGScheduler: Job 43 finished: reduce at DatasetPerformance.scala:139, took 0.035591 s[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 WARN BlockManager: Asked to remove block broadcast_47_piece0, which does not exist[0m
[0m[[0minfo[0m] [0mExecution time: 0.039515346s[0m
[0m[[0minfo[0m] [0mRunning execution DS: range iteration: 3, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 172.16.54.31:33061 in memory (size: 1858.0 B, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO SparkContext: Starting job: foreach at Query.scala:127[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO DAGScheduler: Got job 44 (foreach at Query.scala:127) with 4 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO DAGScheduler: Final stage: ResultStage 48 (foreach at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[175] at rdd at Query.scala:127), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 9.9 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 5.1 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 172.16.54.31:33061 (size: 5.1 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 48 (MapPartitionsRDD[175] at rdd at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO TaskSchedulerImpl: Adding task set 48.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 180, localhost, partition 0, PROCESS_LOCAL, 5486 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO TaskSetManager: Starting task 1.0 in stage 48.0 (TID 181, localhost, partition 1, PROCESS_LOCAL, 5486 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO TaskSetManager: Starting task 2.0 in stage 48.0 (TID 182, localhost, partition 2, PROCESS_LOCAL, 5486 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO TaskSetManager: Starting task 3.0 in stage 48.0 (TID 183, localhost, partition 3, PROCESS_LOCAL, 5486 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO Executor: Running task 2.0 in stage 48.0 (TID 182)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO Executor: Running task 1.0 in stage 48.0 (TID 181)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO Executor: Running task 3.0 in stage 48.0 (TID 183)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:39 INFO Executor: Running task 0.0 in stage 48.0 (TID 180)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:42 INFO Executor: Finished task 3.0 in stage 48.0 (TID 183). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:42 INFO TaskSetManager: Finished task 3.0 in stage 48.0 (TID 183) in 3280 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:43 INFO Executor: Finished task 2.0 in stage 48.0 (TID 182). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:43 INFO TaskSetManager: Finished task 2.0 in stage 48.0 (TID 182) in 3548 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:43 INFO Executor: Finished task 1.0 in stage 48.0 (TID 181). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:43 INFO TaskSetManager: Finished task 1.0 in stage 48.0 (TID 181) in 3675 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:43 INFO Executor: Finished task 0.0 in stage 48.0 (TID 180). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:43 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 180) in 3861 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:43 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:51:43 INFO DAGScheduler: ResultStage 48 (foreach at Query.scala:127) finished in 3.862 s[0m
[0m[[31merror[0m] [0m16/06/07 19:51:43 INFO DAGScheduler: Job 44 finished: foreach at Query.scala:127, took 3.870645 s[0m
[0m[[0minfo[0m] [0mExecution time: 3.881342013s[0m
[0m[[0minfo[0m] [0mRunning execution DF: range iteration: 3, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:51:43 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 172.16.54.31:33061 in memory (size: 5.1 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:43 WARN BlockManager: Asked to remove block broadcast_48_piece0, which does not exist[0m
[0m[[31merror[0m] [0m16/06/07 19:51:43 INFO ContextCleaner: Cleaned accumulator 5144[0m
[0m[[31merror[0m] [0m16/06/07 19:51:43 INFO ContextCleaner: Cleaned accumulator 5145[0m
[0m[[31merror[0m] [0m16/06/07 19:51:43 INFO SparkContext: Starting job: foreach at Query.scala:127[0m
[0m[[31merror[0m] [0m16/06/07 19:51:43 INFO DAGScheduler: Got job 45 (foreach at Query.scala:127) with 4 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:51:43 INFO DAGScheduler: Final stage: ResultStage 49 (foreach at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:43 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:51:43 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:51:43 INFO DAGScheduler: Submitting ResultStage 49 (MapPartitionsRDD[180] at rdd at Query.scala:127), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:51:43 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 9.9 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:43 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 5.1 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:43 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 172.16.54.31:33061 (size: 5.1 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:43 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:51:43 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 49 (MapPartitionsRDD[180] at rdd at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:43 INFO TaskSchedulerImpl: Adding task set 49.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:51:43 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 184, localhost, partition 0, PROCESS_LOCAL, 5486 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:43 INFO TaskSetManager: Starting task 1.0 in stage 49.0 (TID 185, localhost, partition 1, PROCESS_LOCAL, 5486 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:43 INFO TaskSetManager: Starting task 2.0 in stage 49.0 (TID 186, localhost, partition 2, PROCESS_LOCAL, 5486 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:43 INFO TaskSetManager: Starting task 3.0 in stage 49.0 (TID 187, localhost, partition 3, PROCESS_LOCAL, 5486 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:43 INFO Executor: Running task 0.0 in stage 49.0 (TID 184)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:43 INFO Executor: Running task 1.0 in stage 49.0 (TID 185)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:43 INFO Executor: Running task 2.0 in stage 49.0 (TID 186)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:43 INFO Executor: Running task 3.0 in stage 49.0 (TID 187)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:46 INFO Executor: Finished task 1.0 in stage 49.0 (TID 185). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:46 INFO TaskSetManager: Finished task 1.0 in stage 49.0 (TID 185) in 3225 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:47 INFO Executor: Finished task 0.0 in stage 49.0 (TID 184). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:47 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 184) in 3356 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:47 INFO Executor: Finished task 3.0 in stage 49.0 (TID 187). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:47 INFO TaskSetManager: Finished task 3.0 in stage 49.0 (TID 187) in 3420 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:47 INFO Executor: Finished task 2.0 in stage 49.0 (TID 186). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:47 INFO TaskSetManager: Finished task 2.0 in stage 49.0 (TID 186) in 3491 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:47 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:51:47 INFO DAGScheduler: ResultStage 49 (foreach at Query.scala:127) finished in 3.493 s[0m
[0m[[31merror[0m] [0m16/06/07 19:51:47 INFO DAGScheduler: Job 45 finished: foreach at Query.scala:127, took 3.499110 s[0m
[0m[[31merror[0m] [0m16/06/07 19:51:47 INFO ContextCleaner: Cleaned accumulator 5256[0m
[0m[[31merror[0m] [0m16/06/07 19:51:47 INFO ContextCleaner: Cleaned accumulator 5257[0m
[0m[[0minfo[0m] [0mExecution time: 3.50673546s[0m
[0m[[0minfo[0m] [0mRunning execution RDD: range iteration: 3, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:51:47 WARN BlockManager: Asked to remove block broadcast_49_piece0, which does not exist[0m
[0m[[31merror[0m] [0m16/06/07 19:51:47 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 172.16.54.31:33061 in memory (size: 5.1 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:47 INFO SparkContext: Starting job: count at Benchmark.scala:455[0m
[0m[[31merror[0m] [0m16/06/07 19:51:47 INFO DAGScheduler: Got job 46 (count at Benchmark.scala:455) with 4 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:51:47 INFO DAGScheduler: Final stage: ResultStage 50 (count at Benchmark.scala:455)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:47 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:51:47 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:51:47 INFO DAGScheduler: Submitting ResultStage 50 (MapPartitionsRDD[4] at map at DatasetPerformance.scala:51), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:51:47 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 2.9 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:47 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 1860.0 B, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:47 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 172.16.54.31:33061 (size: 1860.0 B, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:47 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:51:47 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 50 (MapPartitionsRDD[4] at map at DatasetPerformance.scala:51)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:47 INFO TaskSchedulerImpl: Adding task set 50.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:51:47 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 188, localhost, partition 0, PROCESS_LOCAL, 5403 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:47 INFO TaskSetManager: Starting task 1.0 in stage 50.0 (TID 189, localhost, partition 1, PROCESS_LOCAL, 5403 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:47 INFO TaskSetManager: Starting task 2.0 in stage 50.0 (TID 190, localhost, partition 2, PROCESS_LOCAL, 5403 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:47 INFO TaskSetManager: Starting task 3.0 in stage 50.0 (TID 191, localhost, partition 3, PROCESS_LOCAL, 5403 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:47 INFO Executor: Running task 2.0 in stage 50.0 (TID 190)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:47 INFO Executor: Running task 1.0 in stage 50.0 (TID 189)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:47 INFO Executor: Running task 3.0 in stage 50.0 (TID 191)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:47 INFO Executor: Running task 0.0 in stage 50.0 (TID 188)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:48 INFO Executor: Finished task 1.0 in stage 50.0 (TID 189). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:48 INFO TaskSetManager: Finished task 1.0 in stage 50.0 (TID 189) in 1379 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:48 INFO Executor: Finished task 2.0 in stage 50.0 (TID 190). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:48 INFO TaskSetManager: Finished task 2.0 in stage 50.0 (TID 190) in 1445 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:48 INFO Executor: Finished task 0.0 in stage 50.0 (TID 188). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:48 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 188) in 1461 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:48 INFO Executor: Finished task 3.0 in stage 50.0 (TID 191). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:48 INFO TaskSetManager: Finished task 3.0 in stage 50.0 (TID 191) in 1481 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:48 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:51:48 INFO DAGScheduler: ResultStage 50 (count at Benchmark.scala:455) finished in 1.482 s[0m
[0m[[31merror[0m] [0m16/06/07 19:51:48 INFO DAGScheduler: Job 46 finished: count at Benchmark.scala:455, took 1.487817 s[0m
[0m[[0minfo[0m] [0mExecution time: 1.489973111s[0m
[0m[[0minfo[0m] [0mRunning execution DS: back-to-back filters iteration: 3, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:51:48 WARN BlockManager: Asked to remove block broadcast_50_piece0, which does not exist[0m
[0m[[31merror[0m] [0m16/06/07 19:51:48 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 172.16.54.31:33061 in memory (size: 1860.0 B, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:48 INFO SparkContext: Starting job: foreach at Query.scala:127[0m
[0m[[31merror[0m] [0m16/06/07 19:51:48 INFO DAGScheduler: Got job 47 (foreach at Query.scala:127) with 4 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:51:48 INFO DAGScheduler: Final stage: ResultStage 51 (foreach at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:48 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:51:48 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:51:48 INFO DAGScheduler: Submitting ResultStage 51 (MapPartitionsRDD[185] at rdd at Query.scala:127), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:51:48 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 18.9 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:48 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 7.9 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:48 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 172.16.54.31:33061 (size: 7.9 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:48 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:51:48 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 51 (MapPartitionsRDD[185] at rdd at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:48 INFO TaskSchedulerImpl: Adding task set 51.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:51:48 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 192, localhost, partition 0, PROCESS_LOCAL, 5501 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:48 INFO TaskSetManager: Starting task 1.0 in stage 51.0 (TID 193, localhost, partition 1, PROCESS_LOCAL, 5501 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:48 INFO TaskSetManager: Starting task 2.0 in stage 51.0 (TID 194, localhost, partition 2, PROCESS_LOCAL, 5501 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:48 INFO TaskSetManager: Starting task 3.0 in stage 51.0 (TID 195, localhost, partition 3, PROCESS_LOCAL, 5501 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:48 INFO Executor: Running task 0.0 in stage 51.0 (TID 192)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:48 INFO Executor: Running task 1.0 in stage 51.0 (TID 193)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:48 INFO Executor: Running task 2.0 in stage 51.0 (TID 194)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:48 INFO Executor: Running task 3.0 in stage 51.0 (TID 195)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:52 INFO Executor: Finished task 0.0 in stage 51.0 (TID 192). 1197 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:52 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 192) in 3913 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:52 INFO Executor: Finished task 2.0 in stage 51.0 (TID 194). 1197 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:52 INFO TaskSetManager: Finished task 2.0 in stage 51.0 (TID 194) in 4102 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:52 INFO Executor: Finished task 3.0 in stage 51.0 (TID 195). 1197 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:52 INFO TaskSetManager: Finished task 3.0 in stage 51.0 (TID 195) in 4118 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:52 INFO Executor: Finished task 1.0 in stage 51.0 (TID 193). 1197 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:52 INFO TaskSetManager: Finished task 1.0 in stage 51.0 (TID 193) in 4159 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:52 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:51:52 INFO DAGScheduler: ResultStage 51 (foreach at Query.scala:127) finished in 4.159 s[0m
[0m[[31merror[0m] [0m16/06/07 19:51:52 INFO DAGScheduler: Job 47 finished: foreach at Query.scala:127, took 4.168158 s[0m
[0m[[31merror[0m] [0m16/06/07 19:51:53 INFO ContextCleaner: Cleaned accumulator 5478[0m
[0m[[31merror[0m] [0m16/06/07 19:51:53 INFO ContextCleaner: Cleaned accumulator 5479[0m
[0m[[31merror[0m] [0m16/06/07 19:51:53 INFO ContextCleaner: Cleaned accumulator 5480[0m
[0m[[0minfo[0m] [0mExecution time: 4.189171019000001s[0m
[0m[[0minfo[0m] [0mRunning execution DF: back-to-back filters iteration: 3, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:51:53 WARN BlockManager: Asked to remove block broadcast_51_piece0, which does not exist[0m
[0m[[31merror[0m] [0m16/06/07 19:51:53 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 172.16.54.31:33061 in memory (size: 7.9 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:53 INFO SparkSqlParser: Parsing command: id % 100 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:51:53 INFO SparkSqlParser: Parsing command: id % 101 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:51:53 INFO SparkSqlParser: Parsing command: id % 102 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:51:53 INFO SparkSqlParser: Parsing command: id % 103 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:51:53 INFO SparkSqlParser: Parsing command: id % 100 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:51:53 INFO SparkSqlParser: Parsing command: id % 101 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:51:53 INFO SparkSqlParser: Parsing command: id % 102 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:51:53 INFO SparkSqlParser: Parsing command: id % 103 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:51:53 INFO SparkContext: Starting job: foreach at Query.scala:127[0m
[0m[[31merror[0m] [0m16/06/07 19:51:53 INFO DAGScheduler: Got job 48 (foreach at Query.scala:127) with 4 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:51:53 INFO DAGScheduler: Final stage: ResultStage 52 (foreach at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:53 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:51:53 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:51:53 INFO DAGScheduler: Submitting ResultStage 52 (MapPartitionsRDD[190] at rdd at Query.scala:127), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:51:53 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 15.0 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:53 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 6.7 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:53 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 172.16.54.31:33061 (size: 6.7 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:53 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:51:53 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 52 (MapPartitionsRDD[190] at rdd at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:53 INFO TaskSchedulerImpl: Adding task set 52.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:51:53 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 196, localhost, partition 0, PROCESS_LOCAL, 5501 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:53 INFO TaskSetManager: Starting task 1.0 in stage 52.0 (TID 197, localhost, partition 1, PROCESS_LOCAL, 5501 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:53 INFO TaskSetManager: Starting task 2.0 in stage 52.0 (TID 198, localhost, partition 2, PROCESS_LOCAL, 5501 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:53 INFO TaskSetManager: Starting task 3.0 in stage 52.0 (TID 199, localhost, partition 3, PROCESS_LOCAL, 5501 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:53 INFO Executor: Running task 1.0 in stage 52.0 (TID 197)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:53 INFO Executor: Running task 0.0 in stage 52.0 (TID 196)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:53 INFO Executor: Running task 2.0 in stage 52.0 (TID 198)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:53 INFO Executor: Running task 3.0 in stage 52.0 (TID 199)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:56 INFO Executor: Finished task 2.0 in stage 52.0 (TID 198). 1197 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:56 INFO TaskSetManager: Finished task 2.0 in stage 52.0 (TID 198) in 3614 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:56 INFO Executor: Finished task 0.0 in stage 52.0 (TID 196). 1197 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:56 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 196) in 3686 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:56 INFO Executor: Finished task 1.0 in stage 52.0 (TID 197). 1197 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:56 INFO TaskSetManager: Finished task 1.0 in stage 52.0 (TID 197) in 3694 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:56 INFO Executor: Finished task 3.0 in stage 52.0 (TID 199). 1197 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:51:56 INFO TaskSetManager: Finished task 3.0 in stage 52.0 (TID 199) in 3739 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:56 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:51:56 INFO DAGScheduler: ResultStage 52 (foreach at Query.scala:127) finished in 3.742 s[0m
[0m[[31merror[0m] [0m16/06/07 19:51:56 INFO DAGScheduler: Job 48 finished: foreach at Query.scala:127, took 3.749977 s[0m
[0m[[0minfo[0m] [0mExecution time: 3.766381366s[0m
[0m[[0minfo[0m] [0mRunning execution RDD: back-to-back filters iteration: 3, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:51:56 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 172.16.54.31:33061 in memory (size: 6.7 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:56 WARN BlockManager: Asked to remove block broadcast_52_piece0, which does not exist[0m
[0m[[31merror[0m] [0m16/06/07 19:51:56 INFO ContextCleaner: Cleaned accumulator 5591[0m
[0m[[31merror[0m] [0m16/06/07 19:51:56 INFO ContextCleaner: Cleaned accumulator 5592[0m
[0m[[31merror[0m] [0m16/06/07 19:51:56 INFO ContextCleaner: Cleaned accumulator 5593[0m
[0m[[31merror[0m] [0m16/06/07 19:51:56 INFO SparkContext: Starting job: count at Benchmark.scala:455[0m
[0m[[31merror[0m] [0m16/06/07 19:51:56 INFO DAGScheduler: Got job 49 (count at Benchmark.scala:455) with 4 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:51:56 INFO DAGScheduler: Final stage: ResultStage 53 (count at Benchmark.scala:455)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:56 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:51:56 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:51:56 INFO DAGScheduler: Submitting ResultStage 53 (MapPartitionsRDD[9] at filter at DatasetPerformance.scala:75), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:51:56 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 3.5 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:56 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 1991.0 B, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:56 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 172.16.54.31:33061 (size: 1991.0 B, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:56 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:51:56 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 53 (MapPartitionsRDD[9] at filter at DatasetPerformance.scala:75)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:56 INFO TaskSchedulerImpl: Adding task set 53.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:51:56 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 200, localhost, partition 0, PROCESS_LOCAL, 5418 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:56 INFO TaskSetManager: Starting task 1.0 in stage 53.0 (TID 201, localhost, partition 1, PROCESS_LOCAL, 5418 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:56 INFO TaskSetManager: Starting task 2.0 in stage 53.0 (TID 202, localhost, partition 2, PROCESS_LOCAL, 5418 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:56 INFO TaskSetManager: Starting task 3.0 in stage 53.0 (TID 203, localhost, partition 3, PROCESS_LOCAL, 5418 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:56 INFO Executor: Running task 1.0 in stage 53.0 (TID 201)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:56 INFO Executor: Running task 0.0 in stage 53.0 (TID 200)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:56 INFO Executor: Running task 2.0 in stage 53.0 (TID 202)[0m
[0m[[31merror[0m] [0m16/06/07 19:51:56 INFO Executor: Running task 3.0 in stage 53.0 (TID 203)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:00 INFO Executor: Finished task 1.0 in stage 53.0 (TID 201). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:00 INFO TaskSetManager: Finished task 1.0 in stage 53.0 (TID 201) in 3805 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:00 INFO Executor: Finished task 3.0 in stage 53.0 (TID 203). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:00 INFO TaskSetManager: Finished task 3.0 in stage 53.0 (TID 203) in 3842 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:00 INFO Executor: Finished task 2.0 in stage 53.0 (TID 202). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:00 INFO TaskSetManager: Finished task 2.0 in stage 53.0 (TID 202) in 3852 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:00 INFO Executor: Finished task 0.0 in stage 53.0 (TID 200). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:00 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 200) in 3857 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:00 INFO DAGScheduler: ResultStage 53 (count at Benchmark.scala:455) finished in 3.857 s[0m
[0m[[31merror[0m] [0m16/06/07 19:52:00 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:52:00 INFO DAGScheduler: Job 49 finished: count at Benchmark.scala:455, took 3.860531 s[0m
[0m[[0minfo[0m] [0mExecution time: 3.8621416020000003s[0m
[0m[[0minfo[0m] [0mRunning execution DS: back-to-back maps iteration: 3, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:52:00 WARN BlockManager: Asked to remove block broadcast_53_piece0, which does not exist[0m
[0m[[31merror[0m] [0m16/06/07 19:52:00 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 172.16.54.31:33061 in memory (size: 1991.0 B, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:00 INFO SparkContext: Starting job: foreach at Query.scala:127[0m
[0m[[31merror[0m] [0m16/06/07 19:52:00 INFO DAGScheduler: Got job 50 (foreach at Query.scala:127) with 4 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:52:00 INFO DAGScheduler: Final stage: ResultStage 54 (foreach at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:00 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:52:00 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:52:00 INFO DAGScheduler: Submitting ResultStage 54 (MapPartitionsRDD[195] at rdd at Query.scala:127), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:52:00 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 21.3 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:00 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 8.0 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:00 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 172.16.54.31:33061 (size: 8.0 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:00 INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:52:00 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 54 (MapPartitionsRDD[195] at rdd at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:00 INFO TaskSchedulerImpl: Adding task set 54.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:52:00 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 204, localhost, partition 0, PROCESS_LOCAL, 5498 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:00 INFO TaskSetManager: Starting task 1.0 in stage 54.0 (TID 205, localhost, partition 1, PROCESS_LOCAL, 5498 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:00 INFO TaskSetManager: Starting task 2.0 in stage 54.0 (TID 206, localhost, partition 2, PROCESS_LOCAL, 5498 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:00 INFO TaskSetManager: Starting task 3.0 in stage 54.0 (TID 207, localhost, partition 3, PROCESS_LOCAL, 5498 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:00 INFO Executor: Running task 1.0 in stage 54.0 (TID 205)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:00 INFO Executor: Running task 3.0 in stage 54.0 (TID 207)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:00 INFO Executor: Running task 2.0 in stage 54.0 (TID 206)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:00 INFO Executor: Running task 0.0 in stage 54.0 (TID 204)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:05 INFO Executor: Finished task 1.0 in stage 54.0 (TID 205). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:05 INFO TaskSetManager: Finished task 1.0 in stage 54.0 (TID 205) in 4080 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:05 INFO Executor: Finished task 2.0 in stage 54.0 (TID 206). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:05 INFO TaskSetManager: Finished task 2.0 in stage 54.0 (TID 206) in 4174 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:05 INFO Executor: Finished task 3.0 in stage 54.0 (TID 207). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:05 INFO TaskSetManager: Finished task 3.0 in stage 54.0 (TID 207) in 4251 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:05 INFO Executor: Finished task 0.0 in stage 54.0 (TID 204). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:05 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 204) in 4261 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:05 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:52:05 INFO DAGScheduler: ResultStage 54 (foreach at Query.scala:127) finished in 4.262 s[0m
[0m[[31merror[0m] [0m16/06/07 19:52:05 INFO DAGScheduler: Job 50 finished: foreach at Query.scala:127, took 4.270226 s[0m
[0m[[0minfo[0m] [0mExecution time: 4.288611441s[0m
[0m[[31merror[0m] [0m16/06/07 19:52:05 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 172.16.54.31:33061 in memory (size: 8.0 KB, free: 2.4 GB)[0m
[0m[[0minfo[0m] [0mRunning execution DF: back-to-back maps iteration: 3, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:52:05 WARN BlockManager: Asked to remove block broadcast_54_piece0, which does not exist[0m
[0m[[31merror[0m] [0m16/06/07 19:52:05 INFO ContextCleaner: Cleaned accumulator 5814[0m
[0m[[31merror[0m] [0m16/06/07 19:52:05 INFO ContextCleaner: Cleaned accumulator 5815[0m
[0m[[31merror[0m] [0m16/06/07 19:52:05 INFO SparkContext: Starting job: foreach at Query.scala:127[0m
[0m[[31merror[0m] [0m16/06/07 19:52:05 INFO DAGScheduler: Got job 51 (foreach at Query.scala:127) with 4 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:52:05 INFO DAGScheduler: Final stage: ResultStage 55 (foreach at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:05 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:52:05 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:52:05 INFO DAGScheduler: Submitting ResultStage 55 (MapPartitionsRDD[200] at rdd at Query.scala:127), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:52:05 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 12.0 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:05 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 5.9 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:05 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 172.16.54.31:33061 (size: 5.9 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:05 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:52:05 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 55 (MapPartitionsRDD[200] at rdd at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:05 INFO TaskSchedulerImpl: Adding task set 55.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:52:05 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 208, localhost, partition 0, PROCESS_LOCAL, 5498 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:05 INFO TaskSetManager: Starting task 1.0 in stage 55.0 (TID 209, localhost, partition 1, PROCESS_LOCAL, 5498 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:05 INFO TaskSetManager: Starting task 2.0 in stage 55.0 (TID 210, localhost, partition 2, PROCESS_LOCAL, 5498 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:05 INFO TaskSetManager: Starting task 3.0 in stage 55.0 (TID 211, localhost, partition 3, PROCESS_LOCAL, 5498 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:05 INFO Executor: Running task 2.0 in stage 55.0 (TID 210)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:05 INFO Executor: Running task 0.0 in stage 55.0 (TID 208)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:05 INFO Executor: Running task 3.0 in stage 55.0 (TID 211)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:05 INFO Executor: Running task 1.0 in stage 55.0 (TID 209)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:08 INFO Executor: Finished task 0.0 in stage 55.0 (TID 208). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:08 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 208) in 3437 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:08 INFO Executor: Finished task 1.0 in stage 55.0 (TID 209). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:08 INFO TaskSetManager: Finished task 1.0 in stage 55.0 (TID 209) in 3618 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:09 INFO Executor: Finished task 3.0 in stage 55.0 (TID 211). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:09 INFO TaskSetManager: Finished task 3.0 in stage 55.0 (TID 211) in 3687 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:09 INFO Executor: Finished task 2.0 in stage 55.0 (TID 210). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:09 INFO TaskSetManager: Finished task 2.0 in stage 55.0 (TID 210) in 3768 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:09 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:52:09 INFO DAGScheduler: ResultStage 55 (foreach at Query.scala:127) finished in 3.769 s[0m
[0m[[31merror[0m] [0m16/06/07 19:52:09 INFO DAGScheduler: Job 51 finished: foreach at Query.scala:127, took 3.774659 s[0m
[0m[[0minfo[0m] [0mExecution time: 3.782203927s[0m
[0m[[0minfo[0m] [0mRunning execution RDD: back-to-back maps iteration: 3, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:52:09 WARN BlockManager: Asked to remove block broadcast_55_piece0, which does not exist[0m
[0m[[31merror[0m] [0m16/06/07 19:52:09 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 172.16.54.31:33061 in memory (size: 5.9 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:09 INFO ContextCleaner: Cleaned accumulator 5926[0m
[0m[[31merror[0m] [0m16/06/07 19:52:09 INFO ContextCleaner: Cleaned accumulator 5927[0m
[0m[[31merror[0m] [0m16/06/07 19:52:09 INFO SparkContext: Starting job: count at Benchmark.scala:455[0m
[0m[[31merror[0m] [0m16/06/07 19:52:09 INFO DAGScheduler: Got job 52 (count at Benchmark.scala:455) with 4 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:52:09 INFO DAGScheduler: Final stage: ResultStage 56 (count at Benchmark.scala:455)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:09 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:52:09 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:52:09 INFO DAGScheduler: Submitting ResultStage 56 (MapPartitionsRDD[14] at map at DatasetPerformance.scala:99), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:52:09 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 3.4 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:09 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 1990.0 B, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:09 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 172.16.54.31:33061 (size: 1990.0 B, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:09 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:52:09 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 56 (MapPartitionsRDD[14] at map at DatasetPerformance.scala:99)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:09 INFO TaskSchedulerImpl: Adding task set 56.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:52:09 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 212, localhost, partition 0, PROCESS_LOCAL, 5415 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:09 INFO TaskSetManager: Starting task 1.0 in stage 56.0 (TID 213, localhost, partition 1, PROCESS_LOCAL, 5415 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:09 INFO TaskSetManager: Starting task 2.0 in stage 56.0 (TID 214, localhost, partition 2, PROCESS_LOCAL, 5415 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:09 INFO TaskSetManager: Starting task 3.0 in stage 56.0 (TID 215, localhost, partition 3, PROCESS_LOCAL, 5415 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:09 INFO Executor: Running task 0.0 in stage 56.0 (TID 212)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:09 INFO Executor: Running task 1.0 in stage 56.0 (TID 213)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:09 INFO Executor: Running task 2.0 in stage 56.0 (TID 214)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:09 INFO Executor: Running task 3.0 in stage 56.0 (TID 215)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:13 INFO Executor: Finished task 0.0 in stage 56.0 (TID 212). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:13 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 212) in 4560 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:13 INFO Executor: Finished task 3.0 in stage 56.0 (TID 215). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:13 INFO TaskSetManager: Finished task 3.0 in stage 56.0 (TID 215) in 4592 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:13 INFO Executor: Finished task 1.0 in stage 56.0 (TID 213). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:13 INFO TaskSetManager: Finished task 1.0 in stage 56.0 (TID 213) in 4660 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:13 INFO Executor: Finished task 2.0 in stage 56.0 (TID 214). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:13 INFO TaskSetManager: Finished task 2.0 in stage 56.0 (TID 214) in 4742 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:13 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:52:13 INFO DAGScheduler: ResultStage 56 (count at Benchmark.scala:455) finished in 4.743 s[0m
[0m[[31merror[0m] [0m16/06/07 19:52:13 INFO DAGScheduler: Job 52 finished: count at Benchmark.scala:455, took 4.747988 s[0m
[0m[[0minfo[0m] [0mExecution time: 4.749187795s[0m
[0m[[0minfo[0m] [0mRunning execution DS: average iteration: 3, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:52:13 WARN BlockManager: Asked to remove block broadcast_56_piece0, which does not exist[0m
[0m[[31merror[0m] [0m16/06/07 19:52:13 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 172.16.54.31:33061 in memory (size: 1990.0 B, free: 2.4 GB)[0m
[0m[[0minfo[0m] [0mExecution 'DS: average' failed: cannot resolve '`sum`' given input columns: [id];[0m
[0m[[0minfo[0m] [0mRunning execution DF: average iteration: 3, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO SparkSqlParser: Parsing command: avg(id)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO SparkSqlParser: Parsing command: avg(id)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO SparkContext: Starting job: collect at Query.scala:126[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO DAGScheduler: Registering RDD 204 (rdd at Query.scala:126)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO DAGScheduler: Got job 53 (collect at Query.scala:126) with 1 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO DAGScheduler: Final stage: ResultStage 58 (collect at Query.scala:126)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 57)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 57)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO DAGScheduler: Submitting ShuffleMapStage 57 (MapPartitionsRDD[204] at rdd at Query.scala:126), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 12.4 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 5.9 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 172.16.54.31:33061 (size: 5.9 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 57 (MapPartitionsRDD[204] at rdd at Query.scala:126)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO TaskSchedulerImpl: Adding task set 57.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 216, localhost, partition 0, PROCESS_LOCAL, 5477 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO TaskSetManager: Starting task 1.0 in stage 57.0 (TID 217, localhost, partition 1, PROCESS_LOCAL, 5477 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO TaskSetManager: Starting task 2.0 in stage 57.0 (TID 218, localhost, partition 2, PROCESS_LOCAL, 5477 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO TaskSetManager: Starting task 3.0 in stage 57.0 (TID 219, localhost, partition 3, PROCESS_LOCAL, 5477 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO Executor: Running task 1.0 in stage 57.0 (TID 217)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO Executor: Running task 0.0 in stage 57.0 (TID 216)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO Executor: Running task 3.0 in stage 57.0 (TID 219)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO Executor: Running task 2.0 in stage 57.0 (TID 218)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO Executor: Finished task 1.0 in stage 57.0 (TID 217). 1639 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO Executor: Finished task 2.0 in stage 57.0 (TID 218). 1639 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO Executor: Finished task 0.0 in stage 57.0 (TID 216). 1639 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO TaskSetManager: Finished task 2.0 in stage 57.0 (TID 218) in 12 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 216) in 13 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO TaskSetManager: Finished task 1.0 in stage 57.0 (TID 217) in 12 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO Executor: Finished task 3.0 in stage 57.0 (TID 219). 1726 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO TaskSetManager: Finished task 3.0 in stage 57.0 (TID 219) in 16 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO DAGScheduler: ShuffleMapStage 57 (rdd at Query.scala:126) finished in 0.017 s[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO DAGScheduler: looking for newly runnable stages[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO DAGScheduler: running: Set()[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO DAGScheduler: waiting: Set(ResultStage 58)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO DAGScheduler: failed: Set()[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO DAGScheduler: Submitting ResultStage 58 (MapPartitionsRDD[208] at rdd at Query.scala:126), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 19.0 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 9.1 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 172.16.54.31:33061 (size: 9.1 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 58 (MapPartitionsRDD[208] at rdd at Query.scala:126)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO TaskSchedulerImpl: Adding task set 58.0 with 1 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 220, localhost, partition 0, ANY, 5389 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO Executor: Running task 0.0 in stage 58.0 (TID 220)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO Executor: Finished task 0.0 in stage 58.0 (TID 220). 3529 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 220) in 5 ms on localhost (1/1)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO DAGScheduler: ResultStage 58 (collect at Query.scala:126) finished in 0.005 s[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO DAGScheduler: Job 53 finished: collect at Query.scala:126, took 0.034470 s[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO ContextCleaner: Cleaned accumulator 6148[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO ContextCleaner: Cleaned accumulator 6149[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO ContextCleaner: Cleaned accumulator 6150[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO ContextCleaner: Cleaned accumulator 6151[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO ContextCleaner: Cleaned accumulator 6152[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO ContextCleaner: Cleaned accumulator 6153[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO ContextCleaner: Cleaned accumulator 6154[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO ContextCleaner: Cleaned accumulator 6155[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO ContextCleaner: Cleaned accumulator 6156[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO ContextCleaner: Cleaned accumulator 6157[0m
[0m[[0minfo[0m] [0mExecution time: 0.058869939s[0m
[0m[[0minfo[0m] [0mRunning execution RDD: average iteration: 3, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 172.16.54.31:33061 in memory (size: 5.9 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 172.16.54.31:33061 in memory (size: 9.1 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO ContextCleaner: Cleaned accumulator 6158[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO ContextCleaner: Cleaned accumulator 6159[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO ContextCleaner: Cleaned accumulator 6160[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO ContextCleaner: Cleaned accumulator 6161[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO ContextCleaner: Cleaned accumulator 6162[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO ContextCleaner: Cleaned accumulator 6163[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO ContextCleaner: Cleaned accumulator 6164[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO ContextCleaner: Cleaned shuffle 4[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO SparkContext: Starting job: reduce at DatasetPerformance.scala:139[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO DAGScheduler: Got job 54 (reduce at DatasetPerformance.scala:139) with 4 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO DAGScheduler: Final stage: ResultStage 59 (reduce at DatasetPerformance.scala:139)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO DAGScheduler: Submitting ResultStage 59 (MapPartitionsRDD[209] at map at DatasetPerformance.scala:139), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 2.9 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 1858.0 B, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 172.16.54.31:33061 (size: 1858.0 B, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 59 (MapPartitionsRDD[209] at map at DatasetPerformance.scala:139)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO TaskSchedulerImpl: Adding task set 59.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 221, localhost, partition 0, PROCESS_LOCAL, 5488 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO TaskSetManager: Starting task 1.0 in stage 59.0 (TID 222, localhost, partition 1, PROCESS_LOCAL, 5488 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO TaskSetManager: Starting task 2.0 in stage 59.0 (TID 223, localhost, partition 2, PROCESS_LOCAL, 5488 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO TaskSetManager: Starting task 3.0 in stage 59.0 (TID 224, localhost, partition 3, PROCESS_LOCAL, 5488 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO Executor: Running task 0.0 in stage 59.0 (TID 221)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO Executor: Running task 1.0 in stage 59.0 (TID 222)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO Executor: Running task 2.0 in stage 59.0 (TID 223)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO Executor: Running task 3.0 in stage 59.0 (TID 224)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO Executor: Finished task 2.0 in stage 59.0 (TID 223). 917 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO TaskSetManager: Finished task 2.0 in stage 59.0 (TID 223) in 20 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO Executor: Finished task 0.0 in stage 59.0 (TID 221). 917 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 221) in 22 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO Executor: Finished task 1.0 in stage 59.0 (TID 222). 917 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO TaskSetManager: Finished task 1.0 in stage 59.0 (TID 222) in 27 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO Executor: Finished task 3.0 in stage 59.0 (TID 224). 917 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO TaskSetManager: Finished task 3.0 in stage 59.0 (TID 224) in 33 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO DAGScheduler: ResultStage 59 (reduce at DatasetPerformance.scala:139) finished in 0.035 s[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO DAGScheduler: Job 54 finished: reduce at DatasetPerformance.scala:139, took 0.039840 s[0m
[0m[[0minfo[0m] [0mExecution time: 0.044455602s[0m
[0m[[0minfo[0m] [0mRunning execution DS: range iteration: 3, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 WARN BlockManager: Asked to remove block broadcast_59_piece0, which does not exist[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 172.16.54.31:33061 in memory (size: 1858.0 B, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO SparkContext: Starting job: foreach at Query.scala:127[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO DAGScheduler: Got job 55 (foreach at Query.scala:127) with 4 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO DAGScheduler: Final stage: ResultStage 60 (foreach at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO DAGScheduler: Submitting ResultStage 60 (MapPartitionsRDD[214] at rdd at Query.scala:127), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 9.9 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 5.1 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 172.16.54.31:33061 (size: 5.1 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 60 (MapPartitionsRDD[214] at rdd at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO TaskSchedulerImpl: Adding task set 60.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 225, localhost, partition 0, PROCESS_LOCAL, 5486 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO TaskSetManager: Starting task 1.0 in stage 60.0 (TID 226, localhost, partition 1, PROCESS_LOCAL, 5486 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO TaskSetManager: Starting task 2.0 in stage 60.0 (TID 227, localhost, partition 2, PROCESS_LOCAL, 5486 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO TaskSetManager: Starting task 3.0 in stage 60.0 (TID 228, localhost, partition 3, PROCESS_LOCAL, 5486 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO Executor: Running task 1.0 in stage 60.0 (TID 226)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO Executor: Running task 0.0 in stage 60.0 (TID 225)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO Executor: Running task 3.0 in stage 60.0 (TID 228)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:14 INFO Executor: Running task 2.0 in stage 60.0 (TID 227)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:17 INFO Executor: Finished task 1.0 in stage 60.0 (TID 226). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:17 INFO TaskSetManager: Finished task 1.0 in stage 60.0 (TID 226) in 3639 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:17 INFO Executor: Finished task 0.0 in stage 60.0 (TID 225). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:17 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 225) in 3689 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:18 INFO Executor: Finished task 3.0 in stage 60.0 (TID 228). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:18 INFO TaskSetManager: Finished task 3.0 in stage 60.0 (TID 228) in 3746 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:18 INFO Executor: Finished task 2.0 in stage 60.0 (TID 227). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:18 INFO TaskSetManager: Finished task 2.0 in stage 60.0 (TID 227) in 3786 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:18 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:52:18 INFO DAGScheduler: ResultStage 60 (foreach at Query.scala:127) finished in 3.787 s[0m
[0m[[31merror[0m] [0m16/06/07 19:52:18 INFO DAGScheduler: Job 55 finished: foreach at Query.scala:127, took 3.791290 s[0m
[0m[[31merror[0m] [0m16/06/07 19:52:18 INFO ContextCleaner: Cleaned accumulator 6429[0m
[0m[[31merror[0m] [0m16/06/07 19:52:18 INFO ContextCleaner: Cleaned accumulator 6430[0m
[0m[[0minfo[0m] [0mExecution time: 3.7988286240000004s[0m
[0m[[0minfo[0m] [0mRunning execution DF: range iteration: 3, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:52:18 WARN BlockManager: Asked to remove block broadcast_60_piece0, which does not exist[0m
[0m[[31merror[0m] [0m16/06/07 19:52:18 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 172.16.54.31:33061 in memory (size: 5.1 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:18 INFO SparkContext: Starting job: foreach at Query.scala:127[0m
[0m[[31merror[0m] [0m16/06/07 19:52:18 INFO DAGScheduler: Got job 56 (foreach at Query.scala:127) with 4 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:52:18 INFO DAGScheduler: Final stage: ResultStage 61 (foreach at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:18 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:52:18 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:52:18 INFO DAGScheduler: Submitting ResultStage 61 (MapPartitionsRDD[219] at rdd at Query.scala:127), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:52:18 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 9.9 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:18 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 5.1 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:18 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 172.16.54.31:33061 (size: 5.1 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:18 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:52:18 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 61 (MapPartitionsRDD[219] at rdd at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:18 INFO TaskSchedulerImpl: Adding task set 61.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:52:18 INFO TaskSetManager: Starting task 0.0 in stage 61.0 (TID 229, localhost, partition 0, PROCESS_LOCAL, 5486 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:18 INFO TaskSetManager: Starting task 1.0 in stage 61.0 (TID 230, localhost, partition 1, PROCESS_LOCAL, 5486 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:18 INFO TaskSetManager: Starting task 2.0 in stage 61.0 (TID 231, localhost, partition 2, PROCESS_LOCAL, 5486 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:18 INFO TaskSetManager: Starting task 3.0 in stage 61.0 (TID 232, localhost, partition 3, PROCESS_LOCAL, 5486 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:18 INFO Executor: Running task 0.0 in stage 61.0 (TID 229)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:18 INFO Executor: Running task 1.0 in stage 61.0 (TID 230)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:18 INFO Executor: Running task 2.0 in stage 61.0 (TID 231)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:18 INFO Executor: Running task 3.0 in stage 61.0 (TID 232)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:21 INFO Executor: Finished task 0.0 in stage 61.0 (TID 229). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:21 INFO TaskSetManager: Finished task 0.0 in stage 61.0 (TID 229) in 3525 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:21 INFO Executor: Finished task 3.0 in stage 61.0 (TID 232). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:21 INFO TaskSetManager: Finished task 3.0 in stage 61.0 (TID 232) in 3538 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:21 INFO Executor: Finished task 2.0 in stage 61.0 (TID 231). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:21 INFO TaskSetManager: Finished task 2.0 in stage 61.0 (TID 231) in 3558 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:21 INFO Executor: Finished task 1.0 in stage 61.0 (TID 230). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:21 INFO TaskSetManager: Finished task 1.0 in stage 61.0 (TID 230) in 3597 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:21 INFO TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:52:21 INFO DAGScheduler: ResultStage 61 (foreach at Query.scala:127) finished in 3.598 s[0m
[0m[[31merror[0m] [0m16/06/07 19:52:21 INFO DAGScheduler: Job 56 finished: foreach at Query.scala:127, took 3.603340 s[0m
[0m[[31merror[0m] [0m16/06/07 19:52:21 INFO ContextCleaner: Cleaned accumulator 6541[0m
[0m[[31merror[0m] [0m16/06/07 19:52:21 INFO ContextCleaner: Cleaned accumulator 6542[0m
[0m[[0minfo[0m] [0mExecution time: 3.610854713s[0m
[0m[[0minfo[0m] [0mRunning execution RDD: range iteration: 3, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:52:21 WARN BlockManager: Asked to remove block broadcast_61_piece0, which does not exist[0m
[0m[[31merror[0m] [0m16/06/07 19:52:21 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 172.16.54.31:33061 in memory (size: 5.1 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:21 INFO SparkContext: Starting job: count at Benchmark.scala:455[0m
[0m[[31merror[0m] [0m16/06/07 19:52:21 INFO DAGScheduler: Got job 57 (count at Benchmark.scala:455) with 4 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:52:21 INFO DAGScheduler: Final stage: ResultStage 62 (count at Benchmark.scala:455)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:21 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:52:21 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:52:21 INFO DAGScheduler: Submitting ResultStage 62 (MapPartitionsRDD[4] at map at DatasetPerformance.scala:51), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:52:21 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 2.9 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:21 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 1860.0 B, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:21 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 172.16.54.31:33061 (size: 1860.0 B, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:21 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:52:21 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 62 (MapPartitionsRDD[4] at map at DatasetPerformance.scala:51)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:21 INFO TaskSchedulerImpl: Adding task set 62.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:52:21 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 233, localhost, partition 0, PROCESS_LOCAL, 5403 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:21 INFO TaskSetManager: Starting task 1.0 in stage 62.0 (TID 234, localhost, partition 1, PROCESS_LOCAL, 5403 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:21 INFO TaskSetManager: Starting task 2.0 in stage 62.0 (TID 235, localhost, partition 2, PROCESS_LOCAL, 5403 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:21 INFO TaskSetManager: Starting task 3.0 in stage 62.0 (TID 236, localhost, partition 3, PROCESS_LOCAL, 5403 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:21 INFO Executor: Running task 0.0 in stage 62.0 (TID 233)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:21 INFO Executor: Running task 1.0 in stage 62.0 (TID 234)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:21 INFO Executor: Running task 3.0 in stage 62.0 (TID 236)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:21 INFO Executor: Running task 2.0 in stage 62.0 (TID 235)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:23 INFO Executor: Finished task 0.0 in stage 62.0 (TID 233). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:23 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 233) in 1339 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:23 INFO Executor: Finished task 1.0 in stage 62.0 (TID 234). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:23 INFO TaskSetManager: Finished task 1.0 in stage 62.0 (TID 234) in 1398 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:23 INFO Executor: Finished task 2.0 in stage 62.0 (TID 235). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:23 INFO TaskSetManager: Finished task 2.0 in stage 62.0 (TID 235) in 1401 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:23 INFO Executor: Finished task 3.0 in stage 62.0 (TID 236). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:23 INFO TaskSetManager: Finished task 3.0 in stage 62.0 (TID 236) in 1465 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:23 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:52:23 INFO DAGScheduler: ResultStage 62 (count at Benchmark.scala:455) finished in 1.466 s[0m
[0m[[31merror[0m] [0m16/06/07 19:52:23 INFO DAGScheduler: Job 57 finished: count at Benchmark.scala:455, took 1.470727 s[0m
[0m[[31merror[0m] [0m16/06/07 19:52:23 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 172.16.54.31:33061 in memory (size: 1860.0 B, free: 2.4 GB)[0m
[0m[[0minfo[0m] [0mExecution time: 1.4716540310000001s[0m
[0m[[0minfo[0m] [0mRunning execution DS: back-to-back filters iteration: 3, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:52:23 INFO SparkContext: Starting job: foreach at Query.scala:127[0m
[0m[[31merror[0m] [0m16/06/07 19:52:23 INFO DAGScheduler: Got job 58 (foreach at Query.scala:127) with 4 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:52:23 INFO DAGScheduler: Final stage: ResultStage 63 (foreach at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:23 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:52:23 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:52:23 INFO DAGScheduler: Submitting ResultStage 63 (MapPartitionsRDD[224] at rdd at Query.scala:127), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:52:23 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 18.9 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:23 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 7.9 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:23 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 172.16.54.31:33061 (size: 7.9 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:23 INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:52:23 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 63 (MapPartitionsRDD[224] at rdd at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:23 INFO TaskSchedulerImpl: Adding task set 63.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:52:23 INFO TaskSetManager: Starting task 0.0 in stage 63.0 (TID 237, localhost, partition 0, PROCESS_LOCAL, 5501 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:23 INFO TaskSetManager: Starting task 1.0 in stage 63.0 (TID 238, localhost, partition 1, PROCESS_LOCAL, 5501 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:23 INFO TaskSetManager: Starting task 2.0 in stage 63.0 (TID 239, localhost, partition 2, PROCESS_LOCAL, 5501 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:23 INFO TaskSetManager: Starting task 3.0 in stage 63.0 (TID 240, localhost, partition 3, PROCESS_LOCAL, 5501 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:23 INFO Executor: Running task 0.0 in stage 63.0 (TID 237)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:23 INFO Executor: Running task 1.0 in stage 63.0 (TID 238)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:23 INFO Executor: Running task 2.0 in stage 63.0 (TID 239)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:23 INFO Executor: Running task 3.0 in stage 63.0 (TID 240)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:27 INFO Executor: Finished task 0.0 in stage 63.0 (TID 237). 1197 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:27 INFO TaskSetManager: Finished task 0.0 in stage 63.0 (TID 237) in 3888 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:27 INFO Executor: Finished task 1.0 in stage 63.0 (TID 238). 1197 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:27 INFO TaskSetManager: Finished task 1.0 in stage 63.0 (TID 238) in 3954 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:27 INFO Executor: Finished task 3.0 in stage 63.0 (TID 240). 1197 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:27 INFO TaskSetManager: Finished task 3.0 in stage 63.0 (TID 240) in 4093 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:27 INFO Executor: Finished task 2.0 in stage 63.0 (TID 239). 1197 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:27 INFO TaskSetManager: Finished task 2.0 in stage 63.0 (TID 239) in 4238 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:27 INFO TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:52:27 INFO DAGScheduler: ResultStage 63 (foreach at Query.scala:127) finished in 4.239 s[0m
[0m[[31merror[0m] [0m16/06/07 19:52:27 INFO DAGScheduler: Job 58 finished: foreach at Query.scala:127, took 4.247498 s[0m
[0m[[0minfo[0m] [0mExecution time: 4.271180773s[0m
[0m[[0minfo[0m] [0mRunning execution DF: back-to-back filters iteration: 3, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:52:27 WARN BlockManager: Asked to remove block broadcast_63_piece0, which does not exist[0m
[0m[[31merror[0m] [0m16/06/07 19:52:27 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 172.16.54.31:33061 in memory (size: 7.9 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:27 INFO ContextCleaner: Cleaned accumulator 6763[0m
[0m[[31merror[0m] [0m16/06/07 19:52:27 INFO ContextCleaner: Cleaned accumulator 6765[0m
[0m[[31merror[0m] [0m16/06/07 19:52:27 INFO ContextCleaner: Cleaned accumulator 6764[0m
[0m[[31merror[0m] [0m16/06/07 19:52:27 INFO SparkSqlParser: Parsing command: id % 100 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:52:27 INFO SparkSqlParser: Parsing command: id % 101 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:52:27 INFO SparkSqlParser: Parsing command: id % 102 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:52:27 INFO SparkSqlParser: Parsing command: id % 103 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:52:27 INFO SparkSqlParser: Parsing command: id % 100 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:52:27 INFO SparkSqlParser: Parsing command: id % 101 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:52:27 INFO SparkSqlParser: Parsing command: id % 102 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:52:27 INFO SparkSqlParser: Parsing command: id % 103 != 0[0m
[0m[[31merror[0m] [0m16/06/07 19:52:27 INFO SparkContext: Starting job: foreach at Query.scala:127[0m
[0m[[31merror[0m] [0m16/06/07 19:52:27 INFO DAGScheduler: Got job 59 (foreach at Query.scala:127) with 4 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:52:27 INFO DAGScheduler: Final stage: ResultStage 64 (foreach at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:27 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:52:27 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:52:27 INFO DAGScheduler: Submitting ResultStage 64 (MapPartitionsRDD[229] at rdd at Query.scala:127), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:52:27 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 15.0 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:27 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 6.7 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:27 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 172.16.54.31:33061 (size: 6.7 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:27 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:52:27 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 64 (MapPartitionsRDD[229] at rdd at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:27 INFO TaskSchedulerImpl: Adding task set 64.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:52:27 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 241, localhost, partition 0, PROCESS_LOCAL, 5501 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:27 INFO TaskSetManager: Starting task 1.0 in stage 64.0 (TID 242, localhost, partition 1, PROCESS_LOCAL, 5501 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:27 INFO TaskSetManager: Starting task 2.0 in stage 64.0 (TID 243, localhost, partition 2, PROCESS_LOCAL, 5501 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:27 INFO TaskSetManager: Starting task 3.0 in stage 64.0 (TID 244, localhost, partition 3, PROCESS_LOCAL, 5501 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:27 INFO Executor: Running task 0.0 in stage 64.0 (TID 241)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:27 INFO Executor: Running task 1.0 in stage 64.0 (TID 242)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:27 INFO Executor: Running task 2.0 in stage 64.0 (TID 243)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:27 INFO Executor: Running task 3.0 in stage 64.0 (TID 244)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:31 INFO Executor: Finished task 2.0 in stage 64.0 (TID 243). 1197 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:31 INFO TaskSetManager: Finished task 2.0 in stage 64.0 (TID 243) in 3612 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:31 INFO Executor: Finished task 3.0 in stage 64.0 (TID 244). 1197 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:31 INFO TaskSetManager: Finished task 3.0 in stage 64.0 (TID 244) in 3627 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:31 INFO Executor: Finished task 0.0 in stage 64.0 (TID 241). 1197 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:31 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 241) in 3678 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:31 INFO Executor: Finished task 1.0 in stage 64.0 (TID 242). 1197 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:31 INFO TaskSetManager: Finished task 1.0 in stage 64.0 (TID 242) in 3769 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:31 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:52:31 INFO DAGScheduler: ResultStage 64 (foreach at Query.scala:127) finished in 3.769 s[0m
[0m[[31merror[0m] [0m16/06/07 19:52:31 INFO DAGScheduler: Job 59 finished: foreach at Query.scala:127, took 3.777642 s[0m
[0m[[0minfo[0m] [0mExecution time: 3.790063185s[0m
[0m[[0minfo[0m] [0mRunning execution RDD: back-to-back filters iteration: 3, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:52:31 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 172.16.54.31:33061 in memory (size: 6.7 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:31 INFO ContextCleaner: Cleaned accumulator 6876[0m
[0m[[31merror[0m] [0m16/06/07 19:52:31 INFO ContextCleaner: Cleaned accumulator 6877[0m
[0m[[31merror[0m] [0m16/06/07 19:52:31 INFO ContextCleaner: Cleaned accumulator 6878[0m
[0m[[31merror[0m] [0m16/06/07 19:52:31 INFO SparkContext: Starting job: count at Benchmark.scala:455[0m
[0m[[31merror[0m] [0m16/06/07 19:52:31 INFO DAGScheduler: Got job 60 (count at Benchmark.scala:455) with 4 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:52:31 INFO DAGScheduler: Final stage: ResultStage 65 (count at Benchmark.scala:455)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:31 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:52:31 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:52:31 INFO DAGScheduler: Submitting ResultStage 65 (MapPartitionsRDD[9] at filter at DatasetPerformance.scala:75), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:52:31 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 3.5 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:31 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 1991.0 B, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:31 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 172.16.54.31:33061 (size: 1991.0 B, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:31 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:52:31 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 65 (MapPartitionsRDD[9] at filter at DatasetPerformance.scala:75)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:31 INFO TaskSchedulerImpl: Adding task set 65.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:52:31 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 245, localhost, partition 0, PROCESS_LOCAL, 5418 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:31 INFO TaskSetManager: Starting task 1.0 in stage 65.0 (TID 246, localhost, partition 1, PROCESS_LOCAL, 5418 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:31 INFO TaskSetManager: Starting task 2.0 in stage 65.0 (TID 247, localhost, partition 2, PROCESS_LOCAL, 5418 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:31 INFO TaskSetManager: Starting task 3.0 in stage 65.0 (TID 248, localhost, partition 3, PROCESS_LOCAL, 5418 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:31 INFO Executor: Running task 0.0 in stage 65.0 (TID 245)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:31 INFO Executor: Running task 2.0 in stage 65.0 (TID 247)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:31 INFO Executor: Running task 3.0 in stage 65.0 (TID 248)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:31 INFO Executor: Running task 1.0 in stage 65.0 (TID 246)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:35 INFO Executor: Finished task 2.0 in stage 65.0 (TID 247). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:35 INFO TaskSetManager: Finished task 2.0 in stage 65.0 (TID 247) in 3487 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:35 INFO Executor: Finished task 3.0 in stage 65.0 (TID 248). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:35 INFO TaskSetManager: Finished task 3.0 in stage 65.0 (TID 248) in 3542 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:35 INFO Executor: Finished task 0.0 in stage 65.0 (TID 245). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:35 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 245) in 3784 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:35 INFO Executor: Finished task 1.0 in stage 65.0 (TID 246). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:35 INFO TaskSetManager: Finished task 1.0 in stage 65.0 (TID 246) in 3798 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:35 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:52:35 INFO DAGScheduler: ResultStage 65 (count at Benchmark.scala:455) finished in 3.799 s[0m
[0m[[31merror[0m] [0m16/06/07 19:52:35 INFO DAGScheduler: Job 60 finished: count at Benchmark.scala:455, took 3.803405 s[0m
[0m[[0minfo[0m] [0mExecution time: 3.804794454s[0m
[0m[[0minfo[0m] [0mRunning execution DS: back-to-back maps iteration: 3, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:52:35 WARN BlockManager: Asked to remove block broadcast_65_piece0, which does not exist[0m
[0m[[31merror[0m] [0m16/06/07 19:52:35 INFO BlockManagerInfo: Removed broadcast_65_piece0 on 172.16.54.31:33061 in memory (size: 1991.0 B, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:35 INFO SparkContext: Starting job: foreach at Query.scala:127[0m
[0m[[31merror[0m] [0m16/06/07 19:52:35 INFO DAGScheduler: Got job 61 (foreach at Query.scala:127) with 4 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:52:35 INFO DAGScheduler: Final stage: ResultStage 66 (foreach at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:35 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:52:35 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:52:35 INFO DAGScheduler: Submitting ResultStage 66 (MapPartitionsRDD[234] at rdd at Query.scala:127), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:52:35 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 21.3 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:35 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 8.0 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:35 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 172.16.54.31:33061 (size: 8.0 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:35 INFO SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:52:35 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 66 (MapPartitionsRDD[234] at rdd at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:35 INFO TaskSchedulerImpl: Adding task set 66.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:52:35 INFO TaskSetManager: Starting task 0.0 in stage 66.0 (TID 249, localhost, partition 0, PROCESS_LOCAL, 5498 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:35 INFO TaskSetManager: Starting task 1.0 in stage 66.0 (TID 250, localhost, partition 1, PROCESS_LOCAL, 5498 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:35 INFO TaskSetManager: Starting task 2.0 in stage 66.0 (TID 251, localhost, partition 2, PROCESS_LOCAL, 5498 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:35 INFO TaskSetManager: Starting task 3.0 in stage 66.0 (TID 252, localhost, partition 3, PROCESS_LOCAL, 5498 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:35 INFO Executor: Running task 1.0 in stage 66.0 (TID 250)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:35 INFO Executor: Running task 2.0 in stage 66.0 (TID 251)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:35 INFO Executor: Running task 0.0 in stage 66.0 (TID 249)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:35 INFO Executor: Running task 3.0 in stage 66.0 (TID 252)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:39 INFO Executor: Finished task 3.0 in stage 66.0 (TID 252). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:39 INFO TaskSetManager: Finished task 3.0 in stage 66.0 (TID 252) in 3646 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:39 INFO Executor: Finished task 2.0 in stage 66.0 (TID 251). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:39 INFO TaskSetManager: Finished task 2.0 in stage 66.0 (TID 251) in 3674 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:39 INFO Executor: Finished task 1.0 in stage 66.0 (TID 250). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:39 INFO TaskSetManager: Finished task 1.0 in stage 66.0 (TID 250) in 3912 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:39 INFO Executor: Finished task 0.0 in stage 66.0 (TID 249). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:39 INFO TaskSetManager: Finished task 0.0 in stage 66.0 (TID 249) in 4048 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:39 INFO TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:52:39 INFO DAGScheduler: ResultStage 66 (foreach at Query.scala:127) finished in 4.048 s[0m
[0m[[31merror[0m] [0m16/06/07 19:52:39 INFO DAGScheduler: Job 61 finished: foreach at Query.scala:127, took 4.055134 s[0m
[0m[[31merror[0m] [0m16/06/07 19:52:39 INFO ContextCleaner: Cleaned accumulator 7099[0m
[0m[[31merror[0m] [0m16/06/07 19:52:39 INFO ContextCleaner: Cleaned accumulator 7100[0m
[0m[[31merror[0m] [0m16/06/07 19:52:39 WARN BlockManager: Asked to remove block broadcast_66_piece0, which does not exist[0m
[0m[[0minfo[0m] [0mExecution time: 4.069440068s[0m
[0m[[0minfo[0m] [0mRunning execution DF: back-to-back maps iteration: 3, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:52:39 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 172.16.54.31:33061 in memory (size: 8.0 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:39 INFO SparkContext: Starting job: foreach at Query.scala:127[0m
[0m[[31merror[0m] [0m16/06/07 19:52:39 INFO DAGScheduler: Got job 62 (foreach at Query.scala:127) with 4 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:52:39 INFO DAGScheduler: Final stage: ResultStage 67 (foreach at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:39 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:52:39 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:52:39 INFO DAGScheduler: Submitting ResultStage 67 (MapPartitionsRDD[239] at rdd at Query.scala:127), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:52:39 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 12.0 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:39 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 5.9 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:39 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 172.16.54.31:33061 (size: 5.9 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:39 INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:52:39 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 67 (MapPartitionsRDD[239] at rdd at Query.scala:127)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:39 INFO TaskSchedulerImpl: Adding task set 67.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:52:39 INFO TaskSetManager: Starting task 0.0 in stage 67.0 (TID 253, localhost, partition 0, PROCESS_LOCAL, 5498 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:39 INFO TaskSetManager: Starting task 1.0 in stage 67.0 (TID 254, localhost, partition 1, PROCESS_LOCAL, 5498 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:39 INFO TaskSetManager: Starting task 2.0 in stage 67.0 (TID 255, localhost, partition 2, PROCESS_LOCAL, 5498 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:39 INFO TaskSetManager: Starting task 3.0 in stage 67.0 (TID 256, localhost, partition 3, PROCESS_LOCAL, 5498 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:39 INFO Executor: Running task 0.0 in stage 67.0 (TID 253)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:39 INFO Executor: Running task 3.0 in stage 67.0 (TID 256)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:39 INFO Executor: Running task 1.0 in stage 67.0 (TID 254)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:39 INFO Executor: Running task 2.0 in stage 67.0 (TID 255)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:43 INFO Executor: Finished task 2.0 in stage 67.0 (TID 255). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:43 INFO TaskSetManager: Finished task 2.0 in stage 67.0 (TID 255) in 3356 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:43 INFO Executor: Finished task 0.0 in stage 67.0 (TID 253). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:43 INFO TaskSetManager: Finished task 0.0 in stage 67.0 (TID 253) in 3496 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:43 INFO Executor: Finished task 3.0 in stage 67.0 (TID 256). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:43 INFO TaskSetManager: Finished task 3.0 in stage 67.0 (TID 256) in 3503 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:43 INFO Executor: Finished task 1.0 in stage 67.0 (TID 254). 1135 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:43 INFO TaskSetManager: Finished task 1.0 in stage 67.0 (TID 254) in 3644 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:43 INFO TaskSchedulerImpl: Removed TaskSet 67.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:52:43 INFO DAGScheduler: ResultStage 67 (foreach at Query.scala:127) finished in 3.647 s[0m
[0m[[31merror[0m] [0m16/06/07 19:52:43 INFO DAGScheduler: Job 62 finished: foreach at Query.scala:127, took 3.652210 s[0m
[0m[[31merror[0m] [0m16/06/07 19:52:43 INFO ContextCleaner: Cleaned accumulator 7211[0m
[0m[[31merror[0m] [0m16/06/07 19:52:43 INFO ContextCleaner: Cleaned accumulator 7212[0m
[0m[[31merror[0m] [0m16/06/07 19:52:43 WARN BlockManager: Asked to remove block broadcast_67_piece0, which does not exist[0m
[0m[[0minfo[0m] [0mExecution time: 3.6611642069999997s[0m
[0m[[0minfo[0m] [0mRunning execution RDD: back-to-back maps iteration: 3, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:52:43 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 172.16.54.31:33061 in memory (size: 5.9 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:43 INFO SparkContext: Starting job: count at Benchmark.scala:455[0m
[0m[[31merror[0m] [0m16/06/07 19:52:43 INFO DAGScheduler: Got job 63 (count at Benchmark.scala:455) with 4 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:52:43 INFO DAGScheduler: Final stage: ResultStage 68 (count at Benchmark.scala:455)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:43 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:52:43 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:52:43 INFO DAGScheduler: Submitting ResultStage 68 (MapPartitionsRDD[14] at map at DatasetPerformance.scala:99), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:52:43 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 3.4 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:43 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 1990.0 B, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:43 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 172.16.54.31:33061 (size: 1990.0 B, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:43 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:52:43 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 68 (MapPartitionsRDD[14] at map at DatasetPerformance.scala:99)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:43 INFO TaskSchedulerImpl: Adding task set 68.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:52:43 INFO TaskSetManager: Starting task 0.0 in stage 68.0 (TID 257, localhost, partition 0, PROCESS_LOCAL, 5415 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:43 INFO TaskSetManager: Starting task 1.0 in stage 68.0 (TID 258, localhost, partition 1, PROCESS_LOCAL, 5415 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:43 INFO TaskSetManager: Starting task 2.0 in stage 68.0 (TID 259, localhost, partition 2, PROCESS_LOCAL, 5415 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:43 INFO TaskSetManager: Starting task 3.0 in stage 68.0 (TID 260, localhost, partition 3, PROCESS_LOCAL, 5415 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:43 INFO Executor: Running task 0.0 in stage 68.0 (TID 257)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:43 INFO Executor: Running task 2.0 in stage 68.0 (TID 259)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:43 INFO Executor: Running task 1.0 in stage 68.0 (TID 258)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:43 INFO Executor: Running task 3.0 in stage 68.0 (TID 260)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:47 INFO Executor: Finished task 2.0 in stage 68.0 (TID 259). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:47 INFO TaskSetManager: Finished task 2.0 in stage 68.0 (TID 259) in 4471 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:47 INFO Executor: Finished task 1.0 in stage 68.0 (TID 258). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:47 INFO TaskSetManager: Finished task 1.0 in stage 68.0 (TID 258) in 4514 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:47 INFO Executor: Finished task 0.0 in stage 68.0 (TID 257). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:47 INFO TaskSetManager: Finished task 0.0 in stage 68.0 (TID 257) in 4536 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO Executor: Finished task 3.0 in stage 68.0 (TID 260). 867 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO TaskSetManager: Finished task 3.0 in stage 68.0 (TID 260) in 4641 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO DAGScheduler: ResultStage 68 (count at Benchmark.scala:455) finished in 4.643 s[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO TaskSchedulerImpl: Removed TaskSet 68.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO DAGScheduler: Job 63 finished: count at Benchmark.scala:455, took 4.648036 s[0m
[0m[[0minfo[0m] [0mExecution time: 4.64990917s[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 WARN BlockManager: Asked to remove block broadcast_68_piece0, which does not exist[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO BlockManagerInfo: Removed broadcast_68_piece0 on 172.16.54.31:33061 in memory (size: 1990.0 B, free: 2.4 GB)[0m
[0m[[0minfo[0m] [0mRunning execution DS: average iteration: 3, StandardRun=true[0m
[0m[[0minfo[0m] [0mExecution 'DS: average' failed: cannot resolve '`sum`' given input columns: [id];[0m
[0m[[0minfo[0m] [0mRunning execution DF: average iteration: 3, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO SparkSqlParser: Parsing command: avg(id)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO SparkSqlParser: Parsing command: avg(id)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO SparkContext: Starting job: collect at Query.scala:126[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO DAGScheduler: Registering RDD 243 (rdd at Query.scala:126)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO DAGScheduler: Got job 64 (collect at Query.scala:126) with 1 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO DAGScheduler: Final stage: ResultStage 70 (collect at Query.scala:126)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 69)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 69)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO DAGScheduler: Submitting ShuffleMapStage 69 (MapPartitionsRDD[243] at rdd at Query.scala:126), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 12.4 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 5.9 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 172.16.54.31:33061 (size: 5.9 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 69 (MapPartitionsRDD[243] at rdd at Query.scala:126)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO TaskSchedulerImpl: Adding task set 69.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO TaskSetManager: Starting task 0.0 in stage 69.0 (TID 261, localhost, partition 0, PROCESS_LOCAL, 5477 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO TaskSetManager: Starting task 1.0 in stage 69.0 (TID 262, localhost, partition 1, PROCESS_LOCAL, 5477 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO TaskSetManager: Starting task 2.0 in stage 69.0 (TID 263, localhost, partition 2, PROCESS_LOCAL, 5477 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO TaskSetManager: Starting task 3.0 in stage 69.0 (TID 264, localhost, partition 3, PROCESS_LOCAL, 5477 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO Executor: Running task 2.0 in stage 69.0 (TID 263)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO Executor: Running task 1.0 in stage 69.0 (TID 262)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO Executor: Running task 0.0 in stage 69.0 (TID 261)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO Executor: Running task 3.0 in stage 69.0 (TID 264)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO Executor: Finished task 3.0 in stage 69.0 (TID 264). 1639 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO Executor: Finished task 1.0 in stage 69.0 (TID 262). 1639 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO Executor: Finished task 0.0 in stage 69.0 (TID 261). 1639 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO TaskSetManager: Finished task 3.0 in stage 69.0 (TID 264) in 10 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO TaskSetManager: Finished task 1.0 in stage 69.0 (TID 262) in 12 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO TaskSetManager: Finished task 0.0 in stage 69.0 (TID 261) in 13 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO Executor: Finished task 2.0 in stage 69.0 (TID 263). 1639 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO TaskSetManager: Finished task 2.0 in stage 69.0 (TID 263) in 16 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO DAGScheduler: ShuffleMapStage 69 (rdd at Query.scala:126) finished in 0.019 s[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO DAGScheduler: looking for newly runnable stages[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO DAGScheduler: running: Set()[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO DAGScheduler: waiting: Set(ResultStage 70)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO DAGScheduler: failed: Set()[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO DAGScheduler: Submitting ResultStage 70 (MapPartitionsRDD[247] at rdd at Query.scala:126), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 19.0 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 9.1 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 172.16.54.31:33061 (size: 9.1 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 70 (MapPartitionsRDD[247] at rdd at Query.scala:126)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO TaskSchedulerImpl: Adding task set 70.0 with 1 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO TaskSetManager: Starting task 0.0 in stage 70.0 (TID 265, localhost, partition 0, ANY, 5389 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO Executor: Running task 0.0 in stage 70.0 (TID 265)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO Executor: Finished task 0.0 in stage 70.0 (TID 265). 3529 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO TaskSetManager: Finished task 0.0 in stage 70.0 (TID 265) in 5 ms on localhost (1/1)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO TaskSchedulerImpl: Removed TaskSet 70.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO DAGScheduler: ResultStage 70 (collect at Query.scala:126) finished in 0.005 s[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO DAGScheduler: Job 64 finished: collect at Query.scala:126, took 0.030879 s[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO ContextCleaner: Cleaned accumulator 7433[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO ContextCleaner: Cleaned accumulator 7434[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO ContextCleaner: Cleaned accumulator 7435[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO ContextCleaner: Cleaned accumulator 7436[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 WARN BlockManager: Asked to remove block broadcast_69_piece0, which does not exist[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO BlockManagerInfo: Removed broadcast_69_piece0 on 172.16.54.31:33061 in memory (size: 5.9 KB, free: 2.4 GB)[0m
[0m[[0minfo[0m] [0mExecution time: 0.047782641s[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO ContextCleaner: Cleaned accumulator 7437[0m
[0m[[0minfo[0m] [0mRunning execution RDD: average iteration: 3, StandardRun=true[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO BlockManagerInfo: Removed broadcast_70_piece0 on 172.16.54.31:33061 in memory (size: 9.1 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO SparkContext: Starting job: reduce at DatasetPerformance.scala:139[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO DAGScheduler: Got job 65 (reduce at DatasetPerformance.scala:139) with 4 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO DAGScheduler: Final stage: ResultStage 71 (reduce at DatasetPerformance.scala:139)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO DAGScheduler: Submitting ResultStage 71 (MapPartitionsRDD[248] at map at DatasetPerformance.scala:139), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 2.9 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 1858.0 B, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 172.16.54.31:33061 (size: 1858.0 B, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 71 (MapPartitionsRDD[248] at map at DatasetPerformance.scala:139)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO TaskSchedulerImpl: Adding task set 71.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO TaskSetManager: Starting task 0.0 in stage 71.0 (TID 266, localhost, partition 0, PROCESS_LOCAL, 5488 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO TaskSetManager: Starting task 1.0 in stage 71.0 (TID 267, localhost, partition 1, PROCESS_LOCAL, 5488 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO TaskSetManager: Starting task 2.0 in stage 71.0 (TID 268, localhost, partition 2, PROCESS_LOCAL, 5488 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO TaskSetManager: Starting task 3.0 in stage 71.0 (TID 269, localhost, partition 3, PROCESS_LOCAL, 5488 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO Executor: Running task 1.0 in stage 71.0 (TID 267)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO Executor: Running task 2.0 in stage 71.0 (TID 268)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO Executor: Running task 3.0 in stage 71.0 (TID 269)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO Executor: Running task 0.0 in stage 71.0 (TID 266)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO Executor: Finished task 0.0 in stage 71.0 (TID 266). 917 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO TaskSetManager: Finished task 0.0 in stage 71.0 (TID 266) in 16 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO Executor: Finished task 1.0 in stage 71.0 (TID 267). 917 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO Executor: Finished task 3.0 in stage 71.0 (TID 269). 830 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO Executor: Finished task 2.0 in stage 71.0 (TID 268). 917 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO TaskSetManager: Finished task 1.0 in stage 71.0 (TID 267) in 23 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO TaskSetManager: Finished task 3.0 in stage 71.0 (TID 269) in 25 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO TaskSetManager: Finished task 2.0 in stage 71.0 (TID 268) in 27 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO TaskSchedulerImpl: Removed TaskSet 71.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO DAGScheduler: ResultStage 71 (reduce at DatasetPerformance.scala:139) finished in 0.028 s[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO DAGScheduler: Job 65 finished: reduce at DatasetPerformance.scala:139, took 0.032567 s[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 WARN BlockManager: Asked to remove block broadcast_71_piece0, which does not exist[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO BlockManagerInfo: Removed broadcast_71_piece0 on 172.16.54.31:33061 in memory (size: 1858.0 B, free: 2.4 GB)[0m
[0m[[0minfo[0m] [0mExecution time: 0.035095274s[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO ContextCleaner: Cleaned shuffle 5[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO ContextCleaner: Cleaned accumulator 7449[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO ContextCleaner: Cleaned accumulator 7448[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO ContextCleaner: Cleaned accumulator 7447[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO ContextCleaner: Cleaned accumulator 7446[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO ContextCleaner: Cleaned accumulator 7445[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO ContextCleaner: Cleaned accumulator 7444[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO ContextCleaner: Cleaned accumulator 7443[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO ContextCleaner: Cleaned accumulator 7442[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO ContextCleaner: Cleaned accumulator 7441[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO ContextCleaner: Cleaned accumulator 7440[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO ContextCleaner: Cleaned accumulator 7439[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO ContextCleaner: Cleaned accumulator 7438[0m
[0m[[0minfo[0m] [0mResults written to table: 'sqlPerformance' at file:/home/charanjits/Documents/ideaProjects/finalProjectImaginea/spark-tpcds-perf-master/performance//timestamp=1465309156735[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO CodeGenerator: Code generated in 64.996391 ms[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO DefaultWriterContainer: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO SparkContext: Starting job: save at Benchmark.scala:251[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO DAGScheduler: Got job 66 (save at Benchmark.scala:251) with 1 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO DAGScheduler: Final stage: ResultStage 72 (save at Benchmark.scala:251)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO DAGScheduler: Parents of final stage: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO DAGScheduler: Missing parents: List()[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO DAGScheduler: Submitting ResultStage 72 (CoalescedRDD[251] at save at Benchmark.scala:251), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 51.1 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 18.7 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 172.16.54.31:33061 (size: 18.7 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 72 (CoalescedRDD[251] at save at Benchmark.scala:251)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO TaskSchedulerImpl: Adding task set 72.0 with 1 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO TaskSetManager: Starting task 0.0 in stage 72.0 (TID 270, localhost, partition 0, PROCESS_LOCAL, 85160 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:48 INFO Executor: Running task 0.0 in stage 72.0 (TID 270)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO DefaultWriterContainer: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO FileOutputCommitter: Saved output of task 'attempt_201606071952_0072_m_000000_0' to file:/home/charanjits/Documents/ideaProjects/finalProjectImaginea/spark-tpcds-perf-master/performance/timestamp=1465309156735/_temporary/0/task_201606071952_0072_m_000000[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO SparkHadoopMapRedUtil: attempt_201606071952_0072_m_000000_0: Committed[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO Executor: Finished task 0.0 in stage 72.0 (TID 270). 968 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO TaskSetManager: Finished task 0.0 in stage 72.0 (TID 270) in 98 ms on localhost (1/1)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO TaskSchedulerImpl: Removed TaskSet 72.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO DAGScheduler: ResultStage 72 (save at Benchmark.scala:251) finished in 0.098 s[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO DAGScheduler: Job 66 finished: save at Benchmark.scala:251, took 0.124957 s[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO DefaultWriterContainer: Job job_201606071952_0000 committed.[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO ListingFileCatalog: Listing file:/home/charanjits/Documents/ideaProjects/finalProjectImaginea/spark-tpcds-perf-master/performance/timestamp=1465309156735 on driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO SparkSqlParser: Parsing command: currentRuns[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO CodeGenerator: Code generated in 34.186499 ms[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO CodeGenerator: Code generated in 13.120367 ms[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO CodeGenerator: Code generated in 37.404652 ms[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO CodeGenerator: Code generated in 26.279365 ms[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO SparkContext: Starting job: show at RunBenchmark.scala:101[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO DAGScheduler: Registering RDD 259 (show at RunBenchmark.scala:101)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO DAGScheduler: Got job 67 (show at RunBenchmark.scala:101) with 1 output partitions[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO DAGScheduler: Final stage: ResultStage 74 (show at RunBenchmark.scala:101)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 73)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 73)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO DAGScheduler: Submitting ShuffleMapStage 73 (MapPartitionsRDD[259] at show at RunBenchmark.scala:101), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 258.5 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 47.7 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 172.16.54.31:33061 (size: 47.7 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 73 (MapPartitionsRDD[259] at show at RunBenchmark.scala:101)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO TaskSchedulerImpl: Adding task set 73.0 with 4 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO TaskSetManager: Starting task 0.0 in stage 73.0 (TID 271, localhost, partition 0, PROCESS_LOCAL, 5378 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO TaskSetManager: Starting task 1.0 in stage 73.0 (TID 272, localhost, partition 1, PROCESS_LOCAL, 31039 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO TaskSetManager: Starting task 2.0 in stage 73.0 (TID 273, localhost, partition 2, PROCESS_LOCAL, 31135 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO TaskSetManager: Starting task 3.0 in stage 73.0 (TID 274, localhost, partition 3, PROCESS_LOCAL, 31183 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO Executor: Running task 0.0 in stage 73.0 (TID 271)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO Executor: Running task 2.0 in stage 73.0 (TID 273)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO Executor: Running task 3.0 in stage 73.0 (TID 274)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO Executor: Running task 1.0 in stage 73.0 (TID 272)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO CodeGenerator: Code generated in 36.831186 ms[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO CodeGenerator: Code generated in 9.819403 ms[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO CodeGenerator: Code generated in 19.395571 ms[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO CodeGenerator: Code generated in 11.651515 ms[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO CodeGenerator: Code generated in 14.592327 ms[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO CodeGenerator: Code generated in 29.642485 ms[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO Executor: Finished task 0.0 in stage 73.0 (TID 271). 1700 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO TaskSetManager: Finished task 0.0 in stage 73.0 (TID 271) in 206 ms on localhost (1/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO Executor: Finished task 1.0 in stage 73.0 (TID 272). 1969 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO TaskSetManager: Finished task 1.0 in stage 73.0 (TID 272) in 207 ms on localhost (2/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO Executor: Finished task 2.0 in stage 73.0 (TID 273). 1969 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO Executor: Finished task 3.0 in stage 73.0 (TID 274). 1969 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO TaskSetManager: Finished task 2.0 in stage 73.0 (TID 273) in 209 ms on localhost (3/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO TaskSetManager: Finished task 3.0 in stage 73.0 (TID 274) in 210 ms on localhost (4/4)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO TaskSchedulerImpl: Removed TaskSet 73.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO DAGScheduler: ShuffleMapStage 73 (show at RunBenchmark.scala:101) finished in 0.211 s[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO DAGScheduler: looking for newly runnable stages[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO DAGScheduler: running: Set()[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO DAGScheduler: waiting: Set(ResultStage 74)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO DAGScheduler: failed: Set()[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO DAGScheduler: Submitting ResultStage 74 (MapPartitionsRDD[263] at show at RunBenchmark.scala:101), which has no missing parents[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 264.0 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 49.5 KB, free 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 172.16.54.31:33061 (size: 49.5 KB, free: 2.4 GB)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1001[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 74 (MapPartitionsRDD[263] at show at RunBenchmark.scala:101)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO TaskSchedulerImpl: Adding task set 74.0 with 1 tasks[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO TaskSetManager: Starting task 0.0 in stage 74.0 (TID 275, localhost, partition 0, ANY, 5280 bytes)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO Executor: Running task 0.0 in stage 74.0 (TID 275)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 4 blocks[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO Executor: Finished task 0.0 in stage 74.0 (TID 275). 5041 bytes result sent to driver[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO TaskSetManager: Finished task 0.0 in stage 74.0 (TID 275) in 46 ms on localhost (1/1)[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO TaskSchedulerImpl: Removed TaskSet 74.0, whose tasks have all completed, from pool [0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO DAGScheduler: ResultStage 74 (show at RunBenchmark.scala:101) finished in 0.046 s[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO DAGScheduler: Job 67 finished: show at RunBenchmark.scala:101, took 0.281463 s[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO CodeGenerator: Code generated in 15.083927 ms[0m
[0m[[0minfo[0m] [0m+-------------------------+-----------+-----------+------------------+------------------+[0m
[0m[[0minfo[0m] [0m|name                     |minTimeMs  |maxTimeMs  |avgTimeMs         |stdDev            |[0m
[0m[[0minfo[0m] [0m+-------------------------+-----------+-----------+------------------+------------------+[0m
[0m[[0minfo[0m] [0m|DF: average              |47.782641  |293.341033 |100.97435733333333|94.99249223644195 |[0m
[0m[[0minfo[0m] [0m|DF: back-to-back filters |3630.233645|4010.398432|3841.9132910000003|139.30385027423128|[0m
[0m[[0minfo[0m] [0m|DF: back-to-back maps    |3661.164207|4207.552059|3848.7401875      |204.0340473300641 |[0m
[0m[[0minfo[0m] [0m|DF: range                |3462.199326|3840.861593|3601.7371628333335|132.96783367030497|[0m
[0m[[0minfo[0m] [0m|DS: average              |null       |null       |null              |null              |[0m
[0m[[0minfo[0m] [0m|DS: back-to-back filters |4118.532818|4610.477977|4293.5414513333335|171.93736588737133|[0m
[0m[[0minfo[0m] [0m|DS: back-to-back maps    |3951.7472  |4288.611441|4157.7243785      |129.49796140868588|[0m
[0m[[0minfo[0m] [0m|DS: range                |3444.564971|5411.379155|3966.4434545      |725.0061958189086 |[0m
[0m[[0minfo[0m] [0m|RDD: average             |35.095274  |164.646803 |65.8173895        |49.557959796196904|[0m
[0m[[0minfo[0m] [0m|RDD: back-to-back filters|3794.96735 |4149.787571|3902.9298839999997|131.27752920885553|[0m
[0m[[0minfo[0m] [0m|RDD: back-to-back maps   |4649.90917 |5153.412994|4836.949048833333 |192.30693569767257|[0m
[0m[[0minfo[0m] [0m|RDD: range               |1213.421127|1563.296715|1451.7049856666665|124.40340898480682|[0m
[0m[[0minfo[0m] [0m+-------------------------+-----------+-----------+------------------+------------------+[0m
[0m[[0minfo[0m] [0m[0m
[0m[[0minfo[0m] [0mResults: sqlContext.read.json("file:/home/charanjits/Documents/ideaProjects/finalProjectImaginea/spark-tpcds-perf-master/performance//timestamp=1465309156735")[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO SparkContext: Invoking stop() from shutdown hook[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO SparkUI: Stopped Spark web UI at http://172.16.54.31:4040[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped![0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO MemoryStore: MemoryStore cleared[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO BlockManager: BlockManager stopped[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO BlockManagerMaster: BlockManagerMaster stopped[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped![0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO SparkContext: Successfully stopped SparkContext[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO ShutdownHookManager: Shutdown hook called[0m
[0m[[31merror[0m] [0m16/06/07 19:52:49 INFO ShutdownHookManager: Deleting directory /tmp/spark-e17e774a-83df-4590-aabb-72f2d222700d[0m
