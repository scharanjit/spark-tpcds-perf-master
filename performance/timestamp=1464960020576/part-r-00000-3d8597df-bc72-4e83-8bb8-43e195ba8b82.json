{"timestamp":1464960020576,"iteration":1,"tags":{"StandardRun":"true","runtype":"local","host":"PRINHYLTPHP0415"},"configuration":{"sparkVersion":"2.0.0-SNAPSHOT","sqlConf":{"spark.tpcds.perf.results":"file:/home/charanjits/Documents/ideaProjects/finalProjectImaginea/spark-tpcds-perf-master/performance/","spark.driver.host":"172.16.54.31","spark.driver.port":"43697","spark.app.name":"com.imaginea.spark.tpcds.perf.RunBenchmark$","spark.executor.id":"driver","spark.master":"local[*]","spark.app.id":"local-1464960016473"},"sparkConf":{"spark.driver.host":"172.16.54.31","spark.driver.port":"43697","spark.app.name":"com.imaginea.spark.tpcds.perf.RunBenchmark$","spark.executor.id":"driver","spark.master":"local[*]","spark.app.id":"local-1464960016473"},"defaultParallelism":4,"buildInfo":{}},"results":[{"name":"DS: range","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.011565,"analysisTime":0.004854,"optimizationTime":0.36739,"planningTime":0.225367,"executionTime":4396.353357,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nRange (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Range (1, 100000000, splits=4)"},{"name":"DF: range","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001743,"analysisTime":0.001158,"optimizationTime":0.001709,"planningTime":0.001494,"executionTime":3423.867758,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nRange (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Range (1, 100000000, splits=4)"},{"name":"RDD: range","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":923.056766,"breakDown":[]},{"name":"DS: back-to-back filters","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.00185,"analysisTime":0.001106,"optimizationTime":15.30588,"planningTime":0.775986,"executionTime":4380.384069,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#524L]\n+- 'Filter <function1>.apply\n   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#523: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#521L]\n         +- Filter <function1>.apply\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#520: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#518L]\n                  +- Filter <function1>.apply\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#517: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#515L]\n                           +- Filter <function1>.apply\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#514: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#524L]\n+- Filter <function1>.apply\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#523: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#521L]\n         +- Filter <function1>.apply\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#520: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#518L]\n                  +- Filter <function1>.apply\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#517: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#515L]\n                           +- Filter <function1>.apply\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#514: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#524L]\n+- Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#514: com.imaginea.spark.tpcds.perf.Data\n      +- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#524L]\n+- *Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)\n   +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#514: com.imaginea.spark.tpcds.perf.Data\n      +- *Range (1, 100000000, splits=4)"},{"name":"DF: back-to-back filters","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001214,"analysisTime":0.001689,"optimizationTime":5.451584,"planningTime":0.812641,"executionTime":3601.146407,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Filter NOT (('id % 103) = 0)\n+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))\n   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))\n      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))\n         +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nFilter NOT ((id#0L % cast(103 as bigint)) = cast(0 as bigint))\n+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))\n   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))\n      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))\n         +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nFilter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))\n+- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Filter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))\n+- *Range (1, 100000000, splits=4)"},{"name":"RDD: back-to-back filters","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":3254.478384,"breakDown":[]},{"name":"DS: back-to-back maps","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001559,"analysisTime":0.001163,"optimizationTime":5.448352,"planningTime":1.039992,"executionTime":4413.445702,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#608L]\n+- 'MapElements <function1>, obj#607: com.imaginea.spark.tpcds.perf.Data\n   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#606: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#603L]\n         +- MapElements <function1>, obj#602: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#601: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#598L]\n                  +- MapElements <function1>, obj#597: com.imaginea.spark.tpcds.perf.Data\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#596: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#593L]\n                           +- MapElements <function1>, obj#592: com.imaginea.spark.tpcds.perf.Data\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#591: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#608L]\n+- MapElements <function1>, obj#607: com.imaginea.spark.tpcds.perf.Data\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#606: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#603L]\n         +- MapElements <function1>, obj#602: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#601: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#598L]\n                  +- MapElements <function1>, obj#597: com.imaginea.spark.tpcds.perf.Data\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#596: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#593L]\n                           +- MapElements <function1>, obj#592: com.imaginea.spark.tpcds.perf.Data\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#591: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#608L]\n+- MapElements <function1>, obj#607: com.imaginea.spark.tpcds.perf.Data\n   +- MapElements <function1>, obj#602: com.imaginea.spark.tpcds.perf.Data\n      +- MapElements <function1>, obj#597: com.imaginea.spark.tpcds.perf.Data\n         +- MapElements <function1>, obj#592: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#591: com.imaginea.spark.tpcds.perf.Data\n               +- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#608L]\n+- *MapElements <function1>, obj#607: com.imaginea.spark.tpcds.perf.Data\n   +- *MapElements <function1>, obj#602: com.imaginea.spark.tpcds.perf.Data\n      +- *MapElements <function1>, obj#597: com.imaginea.spark.tpcds.perf.Data\n         +- *MapElements <function1>, obj#592: com.imaginea.spark.tpcds.perf.Data\n            +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#591: com.imaginea.spark.tpcds.perf.Data\n               +- *Range (1, 100000000, splits=4)"},{"name":"DF: back-to-back maps","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001504,"analysisTime":0.0012,"optimizationTime":2.436127,"planningTime":0.726682,"executionTime":3560.049632,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Project [('id + 1) AS id#662]\n+- Project [(id#656L + cast(1 as bigint)) AS id#659L]\n   +- Project [(id#653L + cast(1 as bigint)) AS id#656L]\n      +- Project [(id#0L + cast(1 as bigint)) AS id#653L]\n         +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nProject [(id#659L + cast(1 as bigint)) AS id#662L]\n+- Project [(id#656L + cast(1 as bigint)) AS id#659L]\n   +- Project [(id#653L + cast(1 as bigint)) AS id#656L]\n      +- Project [(id#0L + cast(1 as bigint)) AS id#653L]\n         +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nProject [((((id#0L + 1) + 1) + 1) + 1) AS id#662L]\n+- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Project [((((id#0L + 1) + 1) + 1) + 1) AS id#662L]\n+- *Range (1, 100000000, splits=4)"},{"name":"RDD: back-to-back maps","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":3846.888512,"breakDown":[]},{"name":"DS: average","mode":"collect","parameters":{},"joinTypes":[],"tables":[],"breakDown":[],"failure":{"className":"org.apache.spark.sql.AnalysisException","message":"cannot resolve '`sum`' given input columns: [id];"}},{"name":"DF: average","mode":"collect","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001217,"analysisTime":0.001203,"optimizationTime":0.557889,"planningTime":0.976407,"executionTime":309.08862,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Project [unresolvedalias('avg('id), Some(<function1>))]\n+- Range (1, 1000000, splits=4)\n\n== Analyzed Logical Plan ==\navg(id): double\nAggregate [avg(id#3L) AS avg(id)#704]\n+- Range (1, 1000000, splits=4)\n\n== Optimized Logical Plan ==\nAggregate [avg(id#3L) AS avg(id)#704]\n+- Range (1, 1000000, splits=4)\n\n== Physical Plan ==\n*TungstenAggregate(key=[], functions=[avg(id#3L)], output=[avg(id)#704])\n+- Exchange SinglePartition, None\n   +- *TungstenAggregate(key=[], functions=[partial_avg(id#3L)], output=[sum#708,count#709L])\n      +- *Range (1, 1000000, splits=4)"},{"name":"RDD: average","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":114.966927,"breakDown":[]},{"name":"DS: range","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001195,"analysisTime":9.23E-4,"optimizationTime":0.335721,"planningTime":0.227183,"executionTime":3286.61813,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nRange (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Range (1, 100000000, splits=4)"},{"name":"DF: range","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001263,"analysisTime":9.82E-4,"optimizationTime":0.001204,"planningTime":7.56E-4,"executionTime":3314.95523,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nRange (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Range (1, 100000000, splits=4)"},{"name":"RDD: range","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":1029.082722,"breakDown":[]},{"name":"DS: back-to-back filters","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001959,"analysisTime":0.001189,"optimizationTime":12.716823,"planningTime":0.575736,"executionTime":4251.970297,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#761L]\n+- 'Filter <function1>.apply\n   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#760: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#758L]\n         +- Filter <function1>.apply\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#757: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#755L]\n                  +- Filter <function1>.apply\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#754: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#752L]\n                           +- Filter <function1>.apply\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#751: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#761L]\n+- Filter <function1>.apply\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#760: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#758L]\n         +- Filter <function1>.apply\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#757: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#755L]\n                  +- Filter <function1>.apply\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#754: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#752L]\n                           +- Filter <function1>.apply\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#751: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#761L]\n+- Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#751: com.imaginea.spark.tpcds.perf.Data\n      +- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#761L]\n+- *Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)\n   +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#751: com.imaginea.spark.tpcds.perf.Data\n      +- *Range (1, 100000000, splits=4)"},{"name":"DF: back-to-back filters","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.005504,"analysisTime":0.003878,"optimizationTime":6.232151,"planningTime":0.612603,"executionTime":3695.174326,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Filter NOT (('id % 103) = 0)\n+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))\n   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))\n      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))\n         +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nFilter NOT ((id#0L % cast(103 as bigint)) = cast(0 as bigint))\n+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))\n   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))\n      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))\n         +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nFilter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))\n+- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Filter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))\n+- *Range (1, 100000000, splits=4)"},{"name":"RDD: back-to-back filters","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":3053.13546,"breakDown":[]},{"name":"DS: back-to-back maps","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.0014,"analysisTime":8.97E-4,"optimizationTime":5.102978,"planningTime":0.78015,"executionTime":4044.213469,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#823L]\n+- 'MapElements <function1>, obj#822: com.imaginea.spark.tpcds.perf.Data\n   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#821: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#818L]\n         +- MapElements <function1>, obj#817: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#816: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#813L]\n                  +- MapElements <function1>, obj#812: com.imaginea.spark.tpcds.perf.Data\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#811: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#808L]\n                           +- MapElements <function1>, obj#807: com.imaginea.spark.tpcds.perf.Data\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#806: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#823L]\n+- MapElements <function1>, obj#822: com.imaginea.spark.tpcds.perf.Data\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#821: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#818L]\n         +- MapElements <function1>, obj#817: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#816: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#813L]\n                  +- MapElements <function1>, obj#812: com.imaginea.spark.tpcds.perf.Data\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#811: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#808L]\n                           +- MapElements <function1>, obj#807: com.imaginea.spark.tpcds.perf.Data\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#806: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#823L]\n+- MapElements <function1>, obj#822: com.imaginea.spark.tpcds.perf.Data\n   +- MapElements <function1>, obj#817: com.imaginea.spark.tpcds.perf.Data\n      +- MapElements <function1>, obj#812: com.imaginea.spark.tpcds.perf.Data\n         +- MapElements <function1>, obj#807: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#806: com.imaginea.spark.tpcds.perf.Data\n               +- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#823L]\n+- *MapElements <function1>, obj#822: com.imaginea.spark.tpcds.perf.Data\n   +- *MapElements <function1>, obj#817: com.imaginea.spark.tpcds.perf.Data\n      +- *MapElements <function1>, obj#812: com.imaginea.spark.tpcds.perf.Data\n         +- *MapElements <function1>, obj#807: com.imaginea.spark.tpcds.perf.Data\n            +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#806: com.imaginea.spark.tpcds.perf.Data\n               +- *Range (1, 100000000, splits=4)"},{"name":"DF: back-to-back maps","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001318,"analysisTime":0.001216,"optimizationTime":1.488628,"planningTime":0.402531,"executionTime":3496.327759,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Project [('id + 1) AS id#853]\n+- Project [(id#847L + cast(1 as bigint)) AS id#850L]\n   +- Project [(id#844L + cast(1 as bigint)) AS id#847L]\n      +- Project [(id#0L + cast(1 as bigint)) AS id#844L]\n         +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nProject [(id#850L + cast(1 as bigint)) AS id#853L]\n+- Project [(id#847L + cast(1 as bigint)) AS id#850L]\n   +- Project [(id#844L + cast(1 as bigint)) AS id#847L]\n      +- Project [(id#0L + cast(1 as bigint)) AS id#844L]\n         +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nProject [((((id#0L + 1) + 1) + 1) + 1) AS id#853L]\n+- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Project [((((id#0L + 1) + 1) + 1) + 1) AS id#853L]\n+- *Range (1, 100000000, splits=4)"},{"name":"RDD: back-to-back maps","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":3783.698286,"breakDown":[]},{"name":"DS: average","mode":"collect","parameters":{},"joinTypes":[],"tables":[],"breakDown":[],"failure":{"className":"org.apache.spark.sql.AnalysisException","message":"cannot resolve '`sum`' given input columns: [id];"}},{"name":"DF: average","mode":"collect","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001406,"analysisTime":9.92E-4,"optimizationTime":0.631434,"planningTime":0.826339,"executionTime":64.282108,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Project [unresolvedalias('avg('id), Some(<function1>))]\n+- Range (1, 1000000, splits=4)\n\n== Analyzed Logical Plan ==\navg(id): double\nAggregate [avg(id#3L) AS avg(id)#881]\n+- Range (1, 1000000, splits=4)\n\n== Optimized Logical Plan ==\nAggregate [avg(id#3L) AS avg(id)#881]\n+- Range (1, 1000000, splits=4)\n\n== Physical Plan ==\n*TungstenAggregate(key=[], functions=[avg(id#3L)], output=[avg(id)#881])\n+- Exchange SinglePartition, None\n   +- *TungstenAggregate(key=[], functions=[partial_avg(id#3L)], output=[sum#885,count#886L])\n      +- *Range (1, 1000000, splits=4)"},{"name":"RDD: average","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":54.065864,"breakDown":[]}]}
{"timestamp":1464960020576,"iteration":2,"tags":{"StandardRun":"true","runtype":"local","host":"PRINHYLTPHP0415"},"configuration":{"sparkVersion":"2.0.0-SNAPSHOT","sqlConf":{"spark.tpcds.perf.results":"file:/home/charanjits/Documents/ideaProjects/finalProjectImaginea/spark-tpcds-perf-master/performance/","spark.driver.host":"172.16.54.31","spark.driver.port":"43697","spark.app.name":"com.imaginea.spark.tpcds.perf.RunBenchmark$","spark.executor.id":"driver","spark.master":"local[*]","spark.app.id":"local-1464960016473"},"sparkConf":{"spark.driver.host":"172.16.54.31","spark.driver.port":"43697","spark.app.name":"com.imaginea.spark.tpcds.perf.RunBenchmark$","spark.executor.id":"driver","spark.master":"local[*]","spark.app.id":"local-1464960016473"},"defaultParallelism":4,"buildInfo":{}},"results":[{"name":"DS: range","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001378,"analysisTime":9.79E-4,"optimizationTime":0.322177,"planningTime":0.195181,"executionTime":3595.830674,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nRange (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Range (1, 100000000, splits=4)"},{"name":"DF: range","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001503,"analysisTime":0.001392,"optimizationTime":0.001444,"planningTime":9.43E-4,"executionTime":3205.52712,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nRange (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Range (1, 100000000, splits=4)"},{"name":"RDD: range","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":1001.493975,"breakDown":[]},{"name":"DS: back-to-back filters","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.00128,"analysisTime":0.001324,"optimizationTime":10.509623,"planningTime":0.766716,"executionTime":4131.328377,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#930L]\n+- 'Filter <function1>.apply\n   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#929: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#927L]\n         +- Filter <function1>.apply\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#926: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#924L]\n                  +- Filter <function1>.apply\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#923: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#921L]\n                           +- Filter <function1>.apply\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#920: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#930L]\n+- Filter <function1>.apply\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#929: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#927L]\n         +- Filter <function1>.apply\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#926: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#924L]\n                  +- Filter <function1>.apply\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#923: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#921L]\n                           +- Filter <function1>.apply\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#920: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#930L]\n+- Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#920: com.imaginea.spark.tpcds.perf.Data\n      +- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#930L]\n+- *Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)\n   +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#920: com.imaginea.spark.tpcds.perf.Data\n      +- *Range (1, 100000000, splits=4)"},{"name":"DF: back-to-back filters","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":9.95E-4,"analysisTime":0.001102,"optimizationTime":3.502782,"planningTime":0.396344,"executionTime":3626.642092,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Filter NOT (('id % 103) = 0)\n+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))\n   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))\n      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))\n         +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nFilter NOT ((id#0L % cast(103 as bigint)) = cast(0 as bigint))\n+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))\n   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))\n      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))\n         +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nFilter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))\n+- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Filter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))\n+- *Range (1, 100000000, splits=4)"},{"name":"RDD: back-to-back filters","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":3032.578126,"breakDown":[]},{"name":"DS: back-to-back maps","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001358,"analysisTime":0.001578,"optimizationTime":3.03349,"planningTime":0.621108,"executionTime":3875.231482,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#992L]\n+- 'MapElements <function1>, obj#991: com.imaginea.spark.tpcds.perf.Data\n   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#990: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#987L]\n         +- MapElements <function1>, obj#986: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#985: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#982L]\n                  +- MapElements <function1>, obj#981: com.imaginea.spark.tpcds.perf.Data\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#980: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#977L]\n                           +- MapElements <function1>, obj#976: com.imaginea.spark.tpcds.perf.Data\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#975: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#992L]\n+- MapElements <function1>, obj#991: com.imaginea.spark.tpcds.perf.Data\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#990: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#987L]\n         +- MapElements <function1>, obj#986: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#985: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#982L]\n                  +- MapElements <function1>, obj#981: com.imaginea.spark.tpcds.perf.Data\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#980: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#977L]\n                           +- MapElements <function1>, obj#976: com.imaginea.spark.tpcds.perf.Data\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#975: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#992L]\n+- MapElements <function1>, obj#991: com.imaginea.spark.tpcds.perf.Data\n   +- MapElements <function1>, obj#986: com.imaginea.spark.tpcds.perf.Data\n      +- MapElements <function1>, obj#981: com.imaginea.spark.tpcds.perf.Data\n         +- MapElements <function1>, obj#976: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#975: com.imaginea.spark.tpcds.perf.Data\n               +- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#992L]\n+- *MapElements <function1>, obj#991: com.imaginea.spark.tpcds.perf.Data\n   +- *MapElements <function1>, obj#986: com.imaginea.spark.tpcds.perf.Data\n      +- *MapElements <function1>, obj#981: com.imaginea.spark.tpcds.perf.Data\n         +- *MapElements <function1>, obj#976: com.imaginea.spark.tpcds.perf.Data\n            +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#975: com.imaginea.spark.tpcds.perf.Data\n               +- *Range (1, 100000000, splits=4)"},{"name":"DF: back-to-back maps","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.002135,"analysisTime":0.00122,"optimizationTime":2.144019,"planningTime":0.515219,"executionTime":3473.625588,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Project [('id + 1) AS id#1022]\n+- Project [(id#1016L + cast(1 as bigint)) AS id#1019L]\n   +- Project [(id#1013L + cast(1 as bigint)) AS id#1016L]\n      +- Project [(id#0L + cast(1 as bigint)) AS id#1013L]\n         +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nProject [(id#1019L + cast(1 as bigint)) AS id#1022L]\n+- Project [(id#1016L + cast(1 as bigint)) AS id#1019L]\n   +- Project [(id#1013L + cast(1 as bigint)) AS id#1016L]\n      +- Project [(id#0L + cast(1 as bigint)) AS id#1013L]\n         +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nProject [((((id#0L + 1) + 1) + 1) + 1) AS id#1022L]\n+- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Project [((((id#0L + 1) + 1) + 1) + 1) AS id#1022L]\n+- *Range (1, 100000000, splits=4)"},{"name":"RDD: back-to-back maps","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":3821.018402,"breakDown":[]},{"name":"DS: average","mode":"collect","parameters":{},"joinTypes":[],"tables":[],"breakDown":[],"failure":{"className":"org.apache.spark.sql.AnalysisException","message":"cannot resolve '`sum`' given input columns: [id];"}},{"name":"DF: average","mode":"collect","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001268,"analysisTime":7.72E-4,"optimizationTime":0.781383,"planningTime":1.623641,"executionTime":63.290691,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Project [unresolvedalias('avg('id), Some(<function1>))]\n+- Range (1, 1000000, splits=4)\n\n== Analyzed Logical Plan ==\navg(id): double\nAggregate [avg(id#3L) AS avg(id)#1050]\n+- Range (1, 1000000, splits=4)\n\n== Optimized Logical Plan ==\nAggregate [avg(id#3L) AS avg(id)#1050]\n+- Range (1, 1000000, splits=4)\n\n== Physical Plan ==\n*TungstenAggregate(key=[], functions=[avg(id#3L)], output=[avg(id)#1050])\n+- Exchange SinglePartition, None\n   +- *TungstenAggregate(key=[], functions=[partial_avg(id#3L)], output=[sum#1054,count#1055L])\n      +- *Range (1, 1000000, splits=4)"},{"name":"RDD: average","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":48.545329,"breakDown":[]},{"name":"DS: range","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.006118,"analysisTime":0.003191,"optimizationTime":0.509833,"planningTime":0.18249,"executionTime":3602.242148,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nRange (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Range (1, 100000000, splits=4)"},{"name":"DF: range","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001108,"analysisTime":0.0012,"optimizationTime":0.00163,"planningTime":8.09E-4,"executionTime":3746.807941,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nRange (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Range (1, 100000000, splits=4)"},{"name":"RDD: range","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":1004.314227,"breakDown":[]},{"name":"DS: back-to-back filters","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001077,"analysisTime":0.001327,"optimizationTime":10.26081,"planningTime":0.437431,"executionTime":4198.646898,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1099L]\n+- 'Filter <function1>.apply\n   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#1098: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1096L]\n         +- Filter <function1>.apply\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1095: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1093L]\n                  +- Filter <function1>.apply\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1092: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1090L]\n                           +- Filter <function1>.apply\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1089: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1099L]\n+- Filter <function1>.apply\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1098: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1096L]\n         +- Filter <function1>.apply\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1095: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1093L]\n                  +- Filter <function1>.apply\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1092: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1090L]\n                           +- Filter <function1>.apply\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1089: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1099L]\n+- Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1089: com.imaginea.spark.tpcds.perf.Data\n      +- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1099L]\n+- *Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)\n   +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1089: com.imaginea.spark.tpcds.perf.Data\n      +- *Range (1, 100000000, splits=4)"},{"name":"DF: back-to-back filters","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001328,"analysisTime":9.42E-4,"optimizationTime":3.3565,"planningTime":0.651317,"executionTime":3561.736742,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Filter NOT (('id % 103) = 0)\n+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))\n   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))\n      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))\n         +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nFilter NOT ((id#0L % cast(103 as bigint)) = cast(0 as bigint))\n+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))\n   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))\n      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))\n         +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nFilter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))\n+- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Filter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))\n+- *Range (1, 100000000, splits=4)"},{"name":"RDD: back-to-back filters","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":3171.421167,"breakDown":[]},{"name":"DS: back-to-back maps","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001113,"analysisTime":8.7E-4,"optimizationTime":3.322236,"planningTime":0.789585,"executionTime":4395.871941,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1161L]\n+- 'MapElements <function1>, obj#1160: com.imaginea.spark.tpcds.perf.Data\n   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#1159: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1156L]\n         +- MapElements <function1>, obj#1155: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1154: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1151L]\n                  +- MapElements <function1>, obj#1150: com.imaginea.spark.tpcds.perf.Data\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1149: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1146L]\n                           +- MapElements <function1>, obj#1145: com.imaginea.spark.tpcds.perf.Data\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1144: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1161L]\n+- MapElements <function1>, obj#1160: com.imaginea.spark.tpcds.perf.Data\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1159: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1156L]\n         +- MapElements <function1>, obj#1155: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1154: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1151L]\n                  +- MapElements <function1>, obj#1150: com.imaginea.spark.tpcds.perf.Data\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1149: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1146L]\n                           +- MapElements <function1>, obj#1145: com.imaginea.spark.tpcds.perf.Data\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1144: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1161L]\n+- MapElements <function1>, obj#1160: com.imaginea.spark.tpcds.perf.Data\n   +- MapElements <function1>, obj#1155: com.imaginea.spark.tpcds.perf.Data\n      +- MapElements <function1>, obj#1150: com.imaginea.spark.tpcds.perf.Data\n         +- MapElements <function1>, obj#1145: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1144: com.imaginea.spark.tpcds.perf.Data\n               +- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1161L]\n+- *MapElements <function1>, obj#1160: com.imaginea.spark.tpcds.perf.Data\n   +- *MapElements <function1>, obj#1155: com.imaginea.spark.tpcds.perf.Data\n      +- *MapElements <function1>, obj#1150: com.imaginea.spark.tpcds.perf.Data\n         +- *MapElements <function1>, obj#1145: com.imaginea.spark.tpcds.perf.Data\n            +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1144: com.imaginea.spark.tpcds.perf.Data\n               +- *Range (1, 100000000, splits=4)"},{"name":"DF: back-to-back maps","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.00133,"analysisTime":0.001339,"optimizationTime":1.578896,"planningTime":0.437664,"executionTime":3744.362705,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Project [('id + 1) AS id#1191]\n+- Project [(id#1185L + cast(1 as bigint)) AS id#1188L]\n   +- Project [(id#1182L + cast(1 as bigint)) AS id#1185L]\n      +- Project [(id#0L + cast(1 as bigint)) AS id#1182L]\n         +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nProject [(id#1188L + cast(1 as bigint)) AS id#1191L]\n+- Project [(id#1185L + cast(1 as bigint)) AS id#1188L]\n   +- Project [(id#1182L + cast(1 as bigint)) AS id#1185L]\n      +- Project [(id#0L + cast(1 as bigint)) AS id#1182L]\n         +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nProject [((((id#0L + 1) + 1) + 1) + 1) AS id#1191L]\n+- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Project [((((id#0L + 1) + 1) + 1) + 1) AS id#1191L]\n+- *Range (1, 100000000, splits=4)"},{"name":"RDD: back-to-back maps","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":3799.598399,"breakDown":[]},{"name":"DS: average","mode":"collect","parameters":{},"joinTypes":[],"tables":[],"breakDown":[],"failure":{"className":"org.apache.spark.sql.AnalysisException","message":"cannot resolve '`sum`' given input columns: [id];"}},{"name":"DF: average","mode":"collect","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001034,"analysisTime":0.001095,"optimizationTime":0.489382,"planningTime":0.904619,"executionTime":52.507005,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Project [unresolvedalias('avg('id), Some(<function1>))]\n+- Range (1, 1000000, splits=4)\n\n== Analyzed Logical Plan ==\navg(id): double\nAggregate [avg(id#3L) AS avg(id)#1219]\n+- Range (1, 1000000, splits=4)\n\n== Optimized Logical Plan ==\nAggregate [avg(id#3L) AS avg(id)#1219]\n+- Range (1, 1000000, splits=4)\n\n== Physical Plan ==\n*TungstenAggregate(key=[], functions=[avg(id#3L)], output=[avg(id)#1219])\n+- Exchange SinglePartition, None\n   +- *TungstenAggregate(key=[], functions=[partial_avg(id#3L)], output=[sum#1223,count#1224L])\n      +- *Range (1, 1000000, splits=4)"},{"name":"RDD: average","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":35.747342,"breakDown":[]}]}
{"timestamp":1464960020576,"iteration":3,"tags":{"StandardRun":"true","runtype":"local","host":"PRINHYLTPHP0415"},"configuration":{"sparkVersion":"2.0.0-SNAPSHOT","sqlConf":{"spark.tpcds.perf.results":"file:/home/charanjits/Documents/ideaProjects/finalProjectImaginea/spark-tpcds-perf-master/performance/","spark.driver.host":"172.16.54.31","spark.driver.port":"43697","spark.app.name":"com.imaginea.spark.tpcds.perf.RunBenchmark$","spark.executor.id":"driver","spark.master":"local[*]","spark.app.id":"local-1464960016473"},"sparkConf":{"spark.driver.host":"172.16.54.31","spark.driver.port":"43697","spark.app.name":"com.imaginea.spark.tpcds.perf.RunBenchmark$","spark.executor.id":"driver","spark.master":"local[*]","spark.app.id":"local-1464960016473"},"defaultParallelism":4,"buildInfo":{}},"results":[{"name":"DS: range","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001062,"analysisTime":7.6E-4,"optimizationTime":0.285367,"planningTime":0.224114,"executionTime":3385.610878,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nRange (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Range (1, 100000000, splits=4)"},{"name":"DF: range","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001755,"analysisTime":0.001792,"optimizationTime":0.002231,"planningTime":0.001256,"executionTime":3391.823837,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nRange (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Range (1, 100000000, splits=4)"},{"name":"RDD: range","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":1350.833593,"breakDown":[]},{"name":"DS: back-to-back filters","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.002309,"analysisTime":0.001311,"optimizationTime":11.264293,"planningTime":0.620194,"executionTime":5134.676609,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1268L]\n+- 'Filter <function1>.apply\n   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#1267: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1265L]\n         +- Filter <function1>.apply\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1264: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1262L]\n                  +- Filter <function1>.apply\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1261: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1259L]\n                           +- Filter <function1>.apply\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1258: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1268L]\n+- Filter <function1>.apply\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1267: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1265L]\n         +- Filter <function1>.apply\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1264: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1262L]\n                  +- Filter <function1>.apply\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1261: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1259L]\n                           +- Filter <function1>.apply\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1258: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1268L]\n+- Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1258: com.imaginea.spark.tpcds.perf.Data\n      +- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1268L]\n+- *Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)\n   +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1258: com.imaginea.spark.tpcds.perf.Data\n      +- *Range (1, 100000000, splits=4)"},{"name":"DF: back-to-back filters","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001797,"analysisTime":0.001352,"optimizationTime":4.710983,"planningTime":1.201363,"executionTime":3597.827486,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Filter NOT (('id % 103) = 0)\n+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))\n   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))\n      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))\n         +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nFilter NOT ((id#0L % cast(103 as bigint)) = cast(0 as bigint))\n+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))\n   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))\n      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))\n         +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nFilter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))\n+- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Filter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))\n+- *Range (1, 100000000, splits=4)"},{"name":"RDD: back-to-back filters","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":3297.268541,"breakDown":[]},{"name":"DS: back-to-back maps","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001985,"analysisTime":0.001055,"optimizationTime":4.147765,"planningTime":0.595886,"executionTime":4256.599005,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1330L]\n+- 'MapElements <function1>, obj#1329: com.imaginea.spark.tpcds.perf.Data\n   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#1328: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1325L]\n         +- MapElements <function1>, obj#1324: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1323: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1320L]\n                  +- MapElements <function1>, obj#1319: com.imaginea.spark.tpcds.perf.Data\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1318: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1315L]\n                           +- MapElements <function1>, obj#1314: com.imaginea.spark.tpcds.perf.Data\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1313: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1330L]\n+- MapElements <function1>, obj#1329: com.imaginea.spark.tpcds.perf.Data\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1328: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1325L]\n         +- MapElements <function1>, obj#1324: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1323: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1320L]\n                  +- MapElements <function1>, obj#1319: com.imaginea.spark.tpcds.perf.Data\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1318: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1315L]\n                           +- MapElements <function1>, obj#1314: com.imaginea.spark.tpcds.perf.Data\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1313: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1330L]\n+- MapElements <function1>, obj#1329: com.imaginea.spark.tpcds.perf.Data\n   +- MapElements <function1>, obj#1324: com.imaginea.spark.tpcds.perf.Data\n      +- MapElements <function1>, obj#1319: com.imaginea.spark.tpcds.perf.Data\n         +- MapElements <function1>, obj#1314: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1313: com.imaginea.spark.tpcds.perf.Data\n               +- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1330L]\n+- *MapElements <function1>, obj#1329: com.imaginea.spark.tpcds.perf.Data\n   +- *MapElements <function1>, obj#1324: com.imaginea.spark.tpcds.perf.Data\n      +- *MapElements <function1>, obj#1319: com.imaginea.spark.tpcds.perf.Data\n         +- *MapElements <function1>, obj#1314: com.imaginea.spark.tpcds.perf.Data\n            +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1313: com.imaginea.spark.tpcds.perf.Data\n               +- *Range (1, 100000000, splits=4)"},{"name":"DF: back-to-back maps","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001725,"analysisTime":0.001108,"optimizationTime":1.692894,"planningTime":0.356548,"executionTime":3425.730546,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Project [('id + 1) AS id#1360]\n+- Project [(id#1354L + cast(1 as bigint)) AS id#1357L]\n   +- Project [(id#1351L + cast(1 as bigint)) AS id#1354L]\n      +- Project [(id#0L + cast(1 as bigint)) AS id#1351L]\n         +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nProject [(id#1357L + cast(1 as bigint)) AS id#1360L]\n+- Project [(id#1354L + cast(1 as bigint)) AS id#1357L]\n   +- Project [(id#1351L + cast(1 as bigint)) AS id#1354L]\n      +- Project [(id#0L + cast(1 as bigint)) AS id#1351L]\n         +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nProject [((((id#0L + 1) + 1) + 1) + 1) AS id#1360L]\n+- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Project [((((id#0L + 1) + 1) + 1) + 1) AS id#1360L]\n+- *Range (1, 100000000, splits=4)"},{"name":"RDD: back-to-back maps","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":3883.296406,"breakDown":[]},{"name":"DS: average","mode":"collect","parameters":{},"joinTypes":[],"tables":[],"breakDown":[],"failure":{"className":"org.apache.spark.sql.AnalysisException","message":"cannot resolve '`sum`' given input columns: [id];"}},{"name":"DF: average","mode":"collect","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.002385,"analysisTime":0.00148,"optimizationTime":0.812014,"planningTime":1.225157,"executionTime":49.375489,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Project [unresolvedalias('avg('id), Some(<function1>))]\n+- Range (1, 1000000, splits=4)\n\n== Analyzed Logical Plan ==\navg(id): double\nAggregate [avg(id#3L) AS avg(id)#1388]\n+- Range (1, 1000000, splits=4)\n\n== Optimized Logical Plan ==\nAggregate [avg(id#3L) AS avg(id)#1388]\n+- Range (1, 1000000, splits=4)\n\n== Physical Plan ==\n*TungstenAggregate(key=[], functions=[avg(id#3L)], output=[avg(id)#1388])\n+- Exchange SinglePartition, None\n   +- *TungstenAggregate(key=[], functions=[partial_avg(id#3L)], output=[sum#1392,count#1393L])\n      +- *Range (1, 1000000, splits=4)"},{"name":"RDD: average","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":38.281001,"breakDown":[]},{"name":"DS: range","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001699,"analysisTime":0.001088,"optimizationTime":0.471239,"planningTime":0.524844,"executionTime":3910.098014,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nRange (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Range (1, 100000000, splits=4)"},{"name":"DF: range","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001162,"analysisTime":0.001085,"optimizationTime":0.001316,"planningTime":9.98E-4,"executionTime":3582.988561,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nRange (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Range (1, 100000000, splits=4)"},{"name":"RDD: range","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":1105.36915,"breakDown":[]},{"name":"DS: back-to-back filters","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001362,"analysisTime":9.16E-4,"optimizationTime":7.073027,"planningTime":0.511775,"executionTime":4289.415079,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1437L]\n+- 'Filter <function1>.apply\n   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#1436: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1434L]\n         +- Filter <function1>.apply\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1433: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1431L]\n                  +- Filter <function1>.apply\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1430: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1428L]\n                           +- Filter <function1>.apply\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1427: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1437L]\n+- Filter <function1>.apply\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1436: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1434L]\n         +- Filter <function1>.apply\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1433: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1431L]\n                  +- Filter <function1>.apply\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1430: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1428L]\n                           +- Filter <function1>.apply\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1427: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1437L]\n+- Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1427: com.imaginea.spark.tpcds.perf.Data\n      +- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1437L]\n+- *Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)\n   +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1427: com.imaginea.spark.tpcds.perf.Data\n      +- *Range (1, 100000000, splits=4)"},{"name":"DF: back-to-back filters","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.002197,"analysisTime":9.72E-4,"optimizationTime":4.589766,"planningTime":0.645358,"executionTime":3698.804571,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Filter NOT (('id % 103) = 0)\n+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))\n   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))\n      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))\n         +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nFilter NOT ((id#0L % cast(103 as bigint)) = cast(0 as bigint))\n+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))\n   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))\n      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))\n         +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nFilter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))\n+- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Filter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))\n+- *Range (1, 100000000, splits=4)"},{"name":"RDD: back-to-back filters","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":3281.837056,"breakDown":[]},{"name":"DS: back-to-back maps","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.00156,"analysisTime":0.001135,"optimizationTime":2.490262,"planningTime":0.444077,"executionTime":4027.564094,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1499L]\n+- 'MapElements <function1>, obj#1498: com.imaginea.spark.tpcds.perf.Data\n   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#1497: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1494L]\n         +- MapElements <function1>, obj#1493: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1492: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1489L]\n                  +- MapElements <function1>, obj#1488: com.imaginea.spark.tpcds.perf.Data\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1487: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1484L]\n                           +- MapElements <function1>, obj#1483: com.imaginea.spark.tpcds.perf.Data\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1482: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1499L]\n+- MapElements <function1>, obj#1498: com.imaginea.spark.tpcds.perf.Data\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1497: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1494L]\n         +- MapElements <function1>, obj#1493: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1492: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1489L]\n                  +- MapElements <function1>, obj#1488: com.imaginea.spark.tpcds.perf.Data\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1487: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1484L]\n                           +- MapElements <function1>, obj#1483: com.imaginea.spark.tpcds.perf.Data\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1482: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1499L]\n+- MapElements <function1>, obj#1498: com.imaginea.spark.tpcds.perf.Data\n   +- MapElements <function1>, obj#1493: com.imaginea.spark.tpcds.perf.Data\n      +- MapElements <function1>, obj#1488: com.imaginea.spark.tpcds.perf.Data\n         +- MapElements <function1>, obj#1483: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1482: com.imaginea.spark.tpcds.perf.Data\n               +- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1499L]\n+- *MapElements <function1>, obj#1498: com.imaginea.spark.tpcds.perf.Data\n   +- *MapElements <function1>, obj#1493: com.imaginea.spark.tpcds.perf.Data\n      +- *MapElements <function1>, obj#1488: com.imaginea.spark.tpcds.perf.Data\n         +- *MapElements <function1>, obj#1483: com.imaginea.spark.tpcds.perf.Data\n            +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1482: com.imaginea.spark.tpcds.perf.Data\n               +- *Range (1, 100000000, splits=4)"},{"name":"DF: back-to-back maps","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001809,"analysisTime":0.001355,"optimizationTime":1.826661,"planningTime":0.512465,"executionTime":3711.701863,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Project [('id + 1) AS id#1529]\n+- Project [(id#1523L + cast(1 as bigint)) AS id#1526L]\n   +- Project [(id#1520L + cast(1 as bigint)) AS id#1523L]\n      +- Project [(id#0L + cast(1 as bigint)) AS id#1520L]\n         +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nProject [(id#1526L + cast(1 as bigint)) AS id#1529L]\n+- Project [(id#1523L + cast(1 as bigint)) AS id#1526L]\n   +- Project [(id#1520L + cast(1 as bigint)) AS id#1523L]\n      +- Project [(id#0L + cast(1 as bigint)) AS id#1520L]\n         +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nProject [((((id#0L + 1) + 1) + 1) + 1) AS id#1529L]\n+- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Project [((((id#0L + 1) + 1) + 1) + 1) AS id#1529L]\n+- *Range (1, 100000000, splits=4)"},{"name":"RDD: back-to-back maps","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":4886.168735,"breakDown":[]},{"name":"DS: average","mode":"collect","parameters":{},"joinTypes":[],"tables":[],"breakDown":[],"failure":{"className":"org.apache.spark.sql.AnalysisException","message":"cannot resolve '`sum`' given input columns: [id];"}},{"name":"DF: average","mode":"collect","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.002074,"analysisTime":0.001032,"optimizationTime":0.676657,"planningTime":0.619213,"executionTime":65.109529,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Project [unresolvedalias('avg('id), Some(<function1>))]\n+- Range (1, 1000000, splits=4)\n\n== Analyzed Logical Plan ==\navg(id): double\nAggregate [avg(id#3L) AS avg(id)#1557]\n+- Range (1, 1000000, splits=4)\n\n== Optimized Logical Plan ==\nAggregate [avg(id#3L) AS avg(id)#1557]\n+- Range (1, 1000000, splits=4)\n\n== Physical Plan ==\n*TungstenAggregate(key=[], functions=[avg(id#3L)], output=[avg(id)#1557])\n+- Exchange SinglePartition, None\n   +- *TungstenAggregate(key=[], functions=[partial_avg(id#3L)], output=[sum#1561,count#1562L])\n      +- *Range (1, 1000000, splits=4)"},{"name":"RDD: average","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":68.180047,"breakDown":[]}]}
