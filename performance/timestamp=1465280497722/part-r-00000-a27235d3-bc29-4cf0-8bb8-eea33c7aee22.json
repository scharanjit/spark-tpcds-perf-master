{"timestamp":1465280497722,"iteration":1,"tags":{"StandardRun":"true","runtype":"local","host":"PRINHYLTPHP0415"},"configuration":{"sparkVersion":"2.0.0-SNAPSHOT","sqlConf":{"spark.tpcds.perf.results":"file:/home/charanjits/Documents/ideaProjects/finalProjectImaginea/spark-tpcds-perf-master/performance/","spark.driver.host":"172.16.54.31","spark.driver.port":"53310","spark.app.name":"com.imaginea.spark.tpcds.perf.RunBenchmark$","spark.executor.id":"driver","spark.master":"local[*]","spark.app.id":"local-1465280493637"},"sparkConf":{"spark.driver.host":"172.16.54.31","spark.driver.port":"53310","spark.app.name":"com.imaginea.spark.tpcds.perf.RunBenchmark$","spark.executor.id":"driver","spark.master":"local[*]","spark.app.id":"local-1465280493637"},"defaultParallelism":4,"buildInfo":{}},"results":[{"name":"DS: range","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.011171,"analysisTime":0.007454,"optimizationTime":0.462766,"planningTime":0.292927,"executionTime":5031.914757,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nRange (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Range (1, 100000000, splits=4)"},{"name":"DF: range","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001198,"analysisTime":8.03E-4,"optimizationTime":0.001307,"planningTime":0.001319,"executionTime":3862.590524,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nRange (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Range (1, 100000000, splits=4)"},{"name":"RDD: range","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":962.602987,"breakDown":[]},{"name":"DS: back-to-back filters","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001115,"analysisTime":7.73E-4,"optimizationTime":17.988622,"planningTime":1.179383,"executionTime":4388.212977,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#524L]\n+- 'Filter <function1>.apply\n   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#523: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#521L]\n         +- Filter <function1>.apply\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#520: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#518L]\n                  +- Filter <function1>.apply\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#517: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#515L]\n                           +- Filter <function1>.apply\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#514: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#524L]\n+- Filter <function1>.apply\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#523: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#521L]\n         +- Filter <function1>.apply\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#520: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#518L]\n                  +- Filter <function1>.apply\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#517: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#515L]\n                           +- Filter <function1>.apply\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#514: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#524L]\n+- Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#514: com.imaginea.spark.tpcds.perf.Data\n      +- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#524L]\n+- *Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)\n   +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#514: com.imaginea.spark.tpcds.perf.Data\n      +- *Range (1, 100000000, splits=4)"},{"name":"DF: back-to-back filters","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001176,"analysisTime":8.22E-4,"optimizationTime":5.055255,"planningTime":0.752038,"executionTime":7775.322056,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Filter NOT (('id % 103) = 0)\n+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))\n   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))\n      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))\n         +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nFilter NOT ((id#0L % cast(103 as bigint)) = cast(0 as bigint))\n+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))\n   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))\n      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))\n         +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nFilter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))\n+- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Filter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))\n+- *Range (1, 100000000, splits=4)"},{"name":"RDD: back-to-back filters","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":10379.653159,"breakDown":[]},{"name":"DS: back-to-back maps","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001594,"analysisTime":9.98E-4,"optimizationTime":5.140095,"planningTime":0.930049,"executionTime":4380.773999,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#608L]\n+- 'MapElements <function1>, obj#607: com.imaginea.spark.tpcds.perf.Data\n   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#606: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#603L]\n         +- MapElements <function1>, obj#602: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#601: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#598L]\n                  +- MapElements <function1>, obj#597: com.imaginea.spark.tpcds.perf.Data\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#596: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#593L]\n                           +- MapElements <function1>, obj#592: com.imaginea.spark.tpcds.perf.Data\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#591: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#608L]\n+- MapElements <function1>, obj#607: com.imaginea.spark.tpcds.perf.Data\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#606: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#603L]\n         +- MapElements <function1>, obj#602: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#601: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#598L]\n                  +- MapElements <function1>, obj#597: com.imaginea.spark.tpcds.perf.Data\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#596: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#593L]\n                           +- MapElements <function1>, obj#592: com.imaginea.spark.tpcds.perf.Data\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#591: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#608L]\n+- MapElements <function1>, obj#607: com.imaginea.spark.tpcds.perf.Data\n   +- MapElements <function1>, obj#602: com.imaginea.spark.tpcds.perf.Data\n      +- MapElements <function1>, obj#597: com.imaginea.spark.tpcds.perf.Data\n         +- MapElements <function1>, obj#592: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#591: com.imaginea.spark.tpcds.perf.Data\n               +- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#608L]\n+- *MapElements <function1>, obj#607: com.imaginea.spark.tpcds.perf.Data\n   +- *MapElements <function1>, obj#602: com.imaginea.spark.tpcds.perf.Data\n      +- *MapElements <function1>, obj#597: com.imaginea.spark.tpcds.perf.Data\n         +- *MapElements <function1>, obj#592: com.imaginea.spark.tpcds.perf.Data\n            +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#591: com.imaginea.spark.tpcds.perf.Data\n               +- *Range (1, 100000000, splits=4)"},{"name":"DF: back-to-back maps","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001718,"analysisTime":0.001395,"optimizationTime":2.074334,"planningTime":0.652429,"executionTime":4284.167077,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Project [('id + 1) AS id#662]\n+- Project [(id#656L + cast(1 as bigint)) AS id#659L]\n   +- Project [(id#653L + cast(1 as bigint)) AS id#656L]\n      +- Project [(id#0L + cast(1 as bigint)) AS id#653L]\n         +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nProject [(id#659L + cast(1 as bigint)) AS id#662L]\n+- Project [(id#656L + cast(1 as bigint)) AS id#659L]\n   +- Project [(id#653L + cast(1 as bigint)) AS id#656L]\n      +- Project [(id#0L + cast(1 as bigint)) AS id#653L]\n         +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nProject [((((id#0L + 1) + 1) + 1) + 1) AS id#662L]\n+- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Project [((((id#0L + 1) + 1) + 1) + 1) AS id#662L]\n+- *Range (1, 100000000, splits=4)"},{"name":"RDD: back-to-back maps","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":4702.677245,"breakDown":[]},{"name":"DS: average","mode":"collect","parameters":{},"joinTypes":[],"tables":[],"breakDown":[],"failure":{"className":"org.apache.spark.sql.AnalysisException","message":"cannot resolve '`sum`' given input columns: [id];"}},{"name":"DF: average","mode":"collect","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001654,"analysisTime":0.001023,"optimizationTime":0.876243,"planningTime":0.881604,"executionTime":398.435425,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Project [unresolvedalias('avg('id), Some(<function1>))]\n+- Range (1, 1000000, splits=4)\n\n== Analyzed Logical Plan ==\navg(id): double\nAggregate [avg(id#3L) AS avg(id)#704]\n+- Range (1, 1000000, splits=4)\n\n== Optimized Logical Plan ==\nAggregate [avg(id#3L) AS avg(id)#704]\n+- Range (1, 1000000, splits=4)\n\n== Physical Plan ==\n*TungstenAggregate(key=[], functions=[avg(id#3L)], output=[avg(id)#704])\n+- Exchange SinglePartition, None\n   +- *TungstenAggregate(key=[], functions=[partial_avg(id#3L)], output=[sum#708,count#709L])\n      +- *Range (1, 1000000, splits=4)"},{"name":"RDD: average","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":128.345315,"breakDown":[]},{"name":"DS: range","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001378,"analysisTime":9.16E-4,"optimizationTime":0.345549,"planningTime":0.590832,"executionTime":3849.493687,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nRange (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Range (1, 100000000, splits=4)"},{"name":"DF: range","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001504,"analysisTime":0.001262,"optimizationTime":0.001961,"planningTime":0.001441,"executionTime":3623.651428,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nRange (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Range (1, 100000000, splits=4)"},{"name":"RDD: range","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":1013.769786,"breakDown":[]},{"name":"DS: back-to-back filters","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001186,"analysisTime":0.001012,"optimizationTime":12.100416,"planningTime":0.780947,"executionTime":4147.099671,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#761L]\n+- 'Filter <function1>.apply\n   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#760: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#758L]\n         +- Filter <function1>.apply\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#757: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#755L]\n                  +- Filter <function1>.apply\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#754: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#752L]\n                           +- Filter <function1>.apply\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#751: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#761L]\n+- Filter <function1>.apply\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#760: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#758L]\n         +- Filter <function1>.apply\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#757: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#755L]\n                  +- Filter <function1>.apply\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#754: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#752L]\n                           +- Filter <function1>.apply\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#751: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#761L]\n+- Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#751: com.imaginea.spark.tpcds.perf.Data\n      +- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#761L]\n+- *Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)\n   +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#751: com.imaginea.spark.tpcds.perf.Data\n      +- *Range (1, 100000000, splits=4)"},{"name":"DF: back-to-back filters","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001283,"analysisTime":9.44E-4,"optimizationTime":2.697898,"planningTime":0.551705,"executionTime":5499.584769,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Filter NOT (('id % 103) = 0)\n+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))\n   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))\n      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))\n         +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nFilter NOT ((id#0L % cast(103 as bigint)) = cast(0 as bigint))\n+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))\n   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))\n      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))\n         +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nFilter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))\n+- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Filter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))\n+- *Range (1, 100000000, splits=4)"},{"name":"RDD: back-to-back filters","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":3483.358758,"breakDown":[]},{"name":"DS: back-to-back maps","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001483,"analysisTime":9.55E-4,"optimizationTime":4.979879,"planningTime":0.81823,"executionTime":4280.148683,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#823L]\n+- 'MapElements <function1>, obj#822: com.imaginea.spark.tpcds.perf.Data\n   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#821: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#818L]\n         +- MapElements <function1>, obj#817: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#816: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#813L]\n                  +- MapElements <function1>, obj#812: com.imaginea.spark.tpcds.perf.Data\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#811: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#808L]\n                           +- MapElements <function1>, obj#807: com.imaginea.spark.tpcds.perf.Data\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#806: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#823L]\n+- MapElements <function1>, obj#822: com.imaginea.spark.tpcds.perf.Data\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#821: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#818L]\n         +- MapElements <function1>, obj#817: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#816: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#813L]\n                  +- MapElements <function1>, obj#812: com.imaginea.spark.tpcds.perf.Data\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#811: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#808L]\n                           +- MapElements <function1>, obj#807: com.imaginea.spark.tpcds.perf.Data\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#806: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#823L]\n+- MapElements <function1>, obj#822: com.imaginea.spark.tpcds.perf.Data\n   +- MapElements <function1>, obj#817: com.imaginea.spark.tpcds.perf.Data\n      +- MapElements <function1>, obj#812: com.imaginea.spark.tpcds.perf.Data\n         +- MapElements <function1>, obj#807: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#806: com.imaginea.spark.tpcds.perf.Data\n               +- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#823L]\n+- *MapElements <function1>, obj#822: com.imaginea.spark.tpcds.perf.Data\n   +- *MapElements <function1>, obj#817: com.imaginea.spark.tpcds.perf.Data\n      +- *MapElements <function1>, obj#812: com.imaginea.spark.tpcds.perf.Data\n         +- *MapElements <function1>, obj#807: com.imaginea.spark.tpcds.perf.Data\n            +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#806: com.imaginea.spark.tpcds.perf.Data\n               +- *Range (1, 100000000, splits=4)"},{"name":"DF: back-to-back maps","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001269,"analysisTime":9.33E-4,"optimizationTime":1.908654,"planningTime":0.489326,"executionTime":3555.946392,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Project [('id + 1) AS id#853]\n+- Project [(id#847L + cast(1 as bigint)) AS id#850L]\n   +- Project [(id#844L + cast(1 as bigint)) AS id#847L]\n      +- Project [(id#0L + cast(1 as bigint)) AS id#844L]\n         +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nProject [(id#850L + cast(1 as bigint)) AS id#853L]\n+- Project [(id#847L + cast(1 as bigint)) AS id#850L]\n   +- Project [(id#844L + cast(1 as bigint)) AS id#847L]\n      +- Project [(id#0L + cast(1 as bigint)) AS id#844L]\n         +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nProject [((((id#0L + 1) + 1) + 1) + 1) AS id#853L]\n+- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Project [((((id#0L + 1) + 1) + 1) + 1) AS id#853L]\n+- *Range (1, 100000000, splits=4)"},{"name":"RDD: back-to-back maps","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":4635.771662,"breakDown":[]},{"name":"DS: average","mode":"collect","parameters":{},"joinTypes":[],"tables":[],"breakDown":[],"failure":{"className":"org.apache.spark.sql.AnalysisException","message":"cannot resolve '`sum`' given input columns: [id];"}},{"name":"DF: average","mode":"collect","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001696,"analysisTime":0.001301,"optimizationTime":0.717836,"planningTime":1.101156,"executionTime":76.435802,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Project [unresolvedalias('avg('id), Some(<function1>))]\n+- Range (1, 1000000, splits=4)\n\n== Analyzed Logical Plan ==\navg(id): double\nAggregate [avg(id#3L) AS avg(id)#881]\n+- Range (1, 1000000, splits=4)\n\n== Optimized Logical Plan ==\nAggregate [avg(id#3L) AS avg(id)#881]\n+- Range (1, 1000000, splits=4)\n\n== Physical Plan ==\n*TungstenAggregate(key=[], functions=[avg(id#3L)], output=[avg(id)#881])\n+- Exchange SinglePartition, None\n   +- *TungstenAggregate(key=[], functions=[partial_avg(id#3L)], output=[sum#885,count#886L])\n      +- *Range (1, 1000000, splits=4)"},{"name":"RDD: average","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":57.902199,"breakDown":[]}]}
{"timestamp":1465280497722,"iteration":2,"tags":{"StandardRun":"true","runtype":"local","host":"PRINHYLTPHP0415"},"configuration":{"sparkVersion":"2.0.0-SNAPSHOT","sqlConf":{"spark.tpcds.perf.results":"file:/home/charanjits/Documents/ideaProjects/finalProjectImaginea/spark-tpcds-perf-master/performance/","spark.driver.host":"172.16.54.31","spark.driver.port":"53310","spark.app.name":"com.imaginea.spark.tpcds.perf.RunBenchmark$","spark.executor.id":"driver","spark.master":"local[*]","spark.app.id":"local-1465280493637"},"sparkConf":{"spark.driver.host":"172.16.54.31","spark.driver.port":"53310","spark.app.name":"com.imaginea.spark.tpcds.perf.RunBenchmark$","spark.executor.id":"driver","spark.master":"local[*]","spark.app.id":"local-1465280493637"},"defaultParallelism":4,"buildInfo":{}},"results":[{"name":"DS: range","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001897,"analysisTime":0.001263,"optimizationTime":0.422198,"planningTime":0.260022,"executionTime":3473.272446,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nRange (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Range (1, 100000000, splits=4)"},{"name":"DF: range","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001324,"analysisTime":7.51E-4,"optimizationTime":0.001324,"planningTime":0.001555,"executionTime":4279.547686,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nRange (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Range (1, 100000000, splits=4)"},{"name":"RDD: range","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":1230.819778,"breakDown":[]},{"name":"DS: back-to-back filters","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001118,"analysisTime":6.81E-4,"optimizationTime":9.643682,"planningTime":1.25812,"executionTime":4060.790789,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#930L]\n+- 'Filter <function1>.apply\n   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#929: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#927L]\n         +- Filter <function1>.apply\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#926: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#924L]\n                  +- Filter <function1>.apply\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#923: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#921L]\n                           +- Filter <function1>.apply\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#920: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#930L]\n+- Filter <function1>.apply\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#929: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#927L]\n         +- Filter <function1>.apply\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#926: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#924L]\n                  +- Filter <function1>.apply\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#923: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#921L]\n                           +- Filter <function1>.apply\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#920: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#930L]\n+- Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#920: com.imaginea.spark.tpcds.perf.Data\n      +- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#930L]\n+- *Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)\n   +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#920: com.imaginea.spark.tpcds.perf.Data\n      +- *Range (1, 100000000, splits=4)"},{"name":"DF: back-to-back filters","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001171,"analysisTime":7.71E-4,"optimizationTime":2.670389,"planningTime":0.373593,"executionTime":3544.023803,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Filter NOT (('id % 103) = 0)\n+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))\n   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))\n      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))\n         +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nFilter NOT ((id#0L % cast(103 as bigint)) = cast(0 as bigint))\n+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))\n   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))\n      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))\n         +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nFilter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))\n+- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Filter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))\n+- *Range (1, 100000000, splits=4)"},{"name":"RDD: back-to-back filters","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":3095.976413,"breakDown":[]},{"name":"DS: back-to-back maps","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.00101,"analysisTime":7.04E-4,"optimizationTime":2.463583,"planningTime":0.587455,"executionTime":3909.180545,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#992L]\n+- 'MapElements <function1>, obj#991: com.imaginea.spark.tpcds.perf.Data\n   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#990: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#987L]\n         +- MapElements <function1>, obj#986: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#985: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#982L]\n                  +- MapElements <function1>, obj#981: com.imaginea.spark.tpcds.perf.Data\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#980: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#977L]\n                           +- MapElements <function1>, obj#976: com.imaginea.spark.tpcds.perf.Data\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#975: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#992L]\n+- MapElements <function1>, obj#991: com.imaginea.spark.tpcds.perf.Data\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#990: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#987L]\n         +- MapElements <function1>, obj#986: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#985: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#982L]\n                  +- MapElements <function1>, obj#981: com.imaginea.spark.tpcds.perf.Data\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#980: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#977L]\n                           +- MapElements <function1>, obj#976: com.imaginea.spark.tpcds.perf.Data\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#975: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#992L]\n+- MapElements <function1>, obj#991: com.imaginea.spark.tpcds.perf.Data\n   +- MapElements <function1>, obj#986: com.imaginea.spark.tpcds.perf.Data\n      +- MapElements <function1>, obj#981: com.imaginea.spark.tpcds.perf.Data\n         +- MapElements <function1>, obj#976: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#975: com.imaginea.spark.tpcds.perf.Data\n               +- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#992L]\n+- *MapElements <function1>, obj#991: com.imaginea.spark.tpcds.perf.Data\n   +- *MapElements <function1>, obj#986: com.imaginea.spark.tpcds.perf.Data\n      +- *MapElements <function1>, obj#981: com.imaginea.spark.tpcds.perf.Data\n         +- *MapElements <function1>, obj#976: com.imaginea.spark.tpcds.perf.Data\n            +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#975: com.imaginea.spark.tpcds.perf.Data\n               +- *Range (1, 100000000, splits=4)"},{"name":"DF: back-to-back maps","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001149,"analysisTime":8.65E-4,"optimizationTime":1.161755,"planningTime":0.340726,"executionTime":3728.022661,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Project [('id + 1) AS id#1022]\n+- Project [(id#1016L + cast(1 as bigint)) AS id#1019L]\n   +- Project [(id#1013L + cast(1 as bigint)) AS id#1016L]\n      +- Project [(id#0L + cast(1 as bigint)) AS id#1013L]\n         +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nProject [(id#1019L + cast(1 as bigint)) AS id#1022L]\n+- Project [(id#1016L + cast(1 as bigint)) AS id#1019L]\n   +- Project [(id#1013L + cast(1 as bigint)) AS id#1016L]\n      +- Project [(id#0L + cast(1 as bigint)) AS id#1013L]\n         +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nProject [((((id#0L + 1) + 1) + 1) + 1) AS id#1022L]\n+- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Project [((((id#0L + 1) + 1) + 1) + 1) AS id#1022L]\n+- *Range (1, 100000000, splits=4)"},{"name":"RDD: back-to-back maps","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":4175.373711,"breakDown":[]},{"name":"DS: average","mode":"collect","parameters":{},"joinTypes":[],"tables":[],"breakDown":[],"failure":{"className":"org.apache.spark.sql.AnalysisException","message":"cannot resolve '`sum`' given input columns: [id];"}},{"name":"DF: average","mode":"collect","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001341,"analysisTime":0.001164,"optimizationTime":0.600861,"planningTime":0.963309,"executionTime":56.547491,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Project [unresolvedalias('avg('id), Some(<function1>))]\n+- Range (1, 1000000, splits=4)\n\n== Analyzed Logical Plan ==\navg(id): double\nAggregate [avg(id#3L) AS avg(id)#1050]\n+- Range (1, 1000000, splits=4)\n\n== Optimized Logical Plan ==\nAggregate [avg(id#3L) AS avg(id)#1050]\n+- Range (1, 1000000, splits=4)\n\n== Physical Plan ==\n*TungstenAggregate(key=[], functions=[avg(id#3L)], output=[avg(id)#1050])\n+- Exchange SinglePartition, None\n   +- *TungstenAggregate(key=[], functions=[partial_avg(id#3L)], output=[sum#1054,count#1055L])\n      +- *Range (1, 1000000, splits=4)"},{"name":"RDD: average","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":40.92896,"breakDown":[]},{"name":"DS: range","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.002202,"analysisTime":9.48E-4,"optimizationTime":0.425136,"planningTime":0.216712,"executionTime":3584.787715,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nRange (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Range (1, 100000000, splits=4)"},{"name":"DF: range","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001312,"analysisTime":7.67E-4,"optimizationTime":0.001367,"planningTime":7.23E-4,"executionTime":3636.791061,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nRange (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Range (1, 100000000, splits=4)"},{"name":"RDD: range","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":1016.18704,"breakDown":[]},{"name":"DS: back-to-back filters","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001232,"analysisTime":7.69E-4,"optimizationTime":9.771905,"planningTime":0.410879,"executionTime":4300.18003,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1099L]\n+- 'Filter <function1>.apply\n   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#1098: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1096L]\n         +- Filter <function1>.apply\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1095: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1093L]\n                  +- Filter <function1>.apply\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1092: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1090L]\n                           +- Filter <function1>.apply\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1089: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1099L]\n+- Filter <function1>.apply\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1098: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1096L]\n         +- Filter <function1>.apply\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1095: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1093L]\n                  +- Filter <function1>.apply\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1092: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1090L]\n                           +- Filter <function1>.apply\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1089: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1099L]\n+- Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1089: com.imaginea.spark.tpcds.perf.Data\n      +- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1099L]\n+- *Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)\n   +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1089: com.imaginea.spark.tpcds.perf.Data\n      +- *Range (1, 100000000, splits=4)"},{"name":"DF: back-to-back filters","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.00138,"analysisTime":8.23E-4,"optimizationTime":2.614664,"planningTime":0.446321,"executionTime":3788.824612,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Filter NOT (('id % 103) = 0)\n+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))\n   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))\n      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))\n         +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nFilter NOT ((id#0L % cast(103 as bigint)) = cast(0 as bigint))\n+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))\n   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))\n      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))\n         +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nFilter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))\n+- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Filter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))\n+- *Range (1, 100000000, splits=4)"},{"name":"RDD: back-to-back filters","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":3629.529877,"breakDown":[]},{"name":"DS: back-to-back maps","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001344,"analysisTime":0.001308,"optimizationTime":2.855393,"planningTime":0.528788,"executionTime":4332.915638,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1161L]\n+- 'MapElements <function1>, obj#1160: com.imaginea.spark.tpcds.perf.Data\n   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#1159: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1156L]\n         +- MapElements <function1>, obj#1155: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1154: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1151L]\n                  +- MapElements <function1>, obj#1150: com.imaginea.spark.tpcds.perf.Data\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1149: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1146L]\n                           +- MapElements <function1>, obj#1145: com.imaginea.spark.tpcds.perf.Data\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1144: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1161L]\n+- MapElements <function1>, obj#1160: com.imaginea.spark.tpcds.perf.Data\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1159: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1156L]\n         +- MapElements <function1>, obj#1155: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1154: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1151L]\n                  +- MapElements <function1>, obj#1150: com.imaginea.spark.tpcds.perf.Data\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1149: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1146L]\n                           +- MapElements <function1>, obj#1145: com.imaginea.spark.tpcds.perf.Data\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1144: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1161L]\n+- MapElements <function1>, obj#1160: com.imaginea.spark.tpcds.perf.Data\n   +- MapElements <function1>, obj#1155: com.imaginea.spark.tpcds.perf.Data\n      +- MapElements <function1>, obj#1150: com.imaginea.spark.tpcds.perf.Data\n         +- MapElements <function1>, obj#1145: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1144: com.imaginea.spark.tpcds.perf.Data\n               +- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1161L]\n+- *MapElements <function1>, obj#1160: com.imaginea.spark.tpcds.perf.Data\n   +- *MapElements <function1>, obj#1155: com.imaginea.spark.tpcds.perf.Data\n      +- *MapElements <function1>, obj#1150: com.imaginea.spark.tpcds.perf.Data\n         +- *MapElements <function1>, obj#1145: com.imaginea.spark.tpcds.perf.Data\n            +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1144: com.imaginea.spark.tpcds.perf.Data\n               +- *Range (1, 100000000, splits=4)"},{"name":"DF: back-to-back maps","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001027,"analysisTime":0.001082,"optimizationTime":1.101424,"planningTime":0.297363,"executionTime":3623.383635,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Project [('id + 1) AS id#1191]\n+- Project [(id#1185L + cast(1 as bigint)) AS id#1188L]\n   +- Project [(id#1182L + cast(1 as bigint)) AS id#1185L]\n      +- Project [(id#0L + cast(1 as bigint)) AS id#1182L]\n         +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nProject [(id#1188L + cast(1 as bigint)) AS id#1191L]\n+- Project [(id#1185L + cast(1 as bigint)) AS id#1188L]\n   +- Project [(id#1182L + cast(1 as bigint)) AS id#1185L]\n      +- Project [(id#0L + cast(1 as bigint)) AS id#1182L]\n         +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nProject [((((id#0L + 1) + 1) + 1) + 1) AS id#1191L]\n+- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Project [((((id#0L + 1) + 1) + 1) + 1) AS id#1191L]\n+- *Range (1, 100000000, splits=4)"},{"name":"RDD: back-to-back maps","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":4208.681081,"breakDown":[]},{"name":"DS: average","mode":"collect","parameters":{},"joinTypes":[],"tables":[],"breakDown":[],"failure":{"className":"org.apache.spark.sql.AnalysisException","message":"cannot resolve '`sum`' given input columns: [id];"}},{"name":"DF: average","mode":"collect","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001546,"analysisTime":7.84E-4,"optimizationTime":0.511805,"planningTime":0.721147,"executionTime":94.207781,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Project [unresolvedalias('avg('id), Some(<function1>))]\n+- Range (1, 1000000, splits=4)\n\n== Analyzed Logical Plan ==\navg(id): double\nAggregate [avg(id#3L) AS avg(id)#1219]\n+- Range (1, 1000000, splits=4)\n\n== Optimized Logical Plan ==\nAggregate [avg(id#3L) AS avg(id)#1219]\n+- Range (1, 1000000, splits=4)\n\n== Physical Plan ==\n*TungstenAggregate(key=[], functions=[avg(id#3L)], output=[avg(id)#1219])\n+- Exchange SinglePartition, None\n   +- *TungstenAggregate(key=[], functions=[partial_avg(id#3L)], output=[sum#1223,count#1224L])\n      +- *Range (1, 1000000, splits=4)"},{"name":"RDD: average","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":48.635934,"breakDown":[]}]}
{"timestamp":1465280497722,"iteration":3,"tags":{"StandardRun":"true","runtype":"local","host":"PRINHYLTPHP0415"},"configuration":{"sparkVersion":"2.0.0-SNAPSHOT","sqlConf":{"spark.tpcds.perf.results":"file:/home/charanjits/Documents/ideaProjects/finalProjectImaginea/spark-tpcds-perf-master/performance/","spark.driver.host":"172.16.54.31","spark.driver.port":"53310","spark.app.name":"com.imaginea.spark.tpcds.perf.RunBenchmark$","spark.executor.id":"driver","spark.master":"local[*]","spark.app.id":"local-1465280493637"},"sparkConf":{"spark.driver.host":"172.16.54.31","spark.driver.port":"53310","spark.app.name":"com.imaginea.spark.tpcds.perf.RunBenchmark$","spark.executor.id":"driver","spark.master":"local[*]","spark.app.id":"local-1465280493637"},"defaultParallelism":4,"buildInfo":{}},"results":[{"name":"DS: range","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001624,"analysisTime":9.02E-4,"optimizationTime":0.386531,"planningTime":0.26085,"executionTime":3794.079963,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nRange (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Range (1, 100000000, splits=4)"},{"name":"DF: range","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.002056,"analysisTime":0.001266,"optimizationTime":0.001278,"planningTime":0.001206,"executionTime":3262.690097,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nRange (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Range (1, 100000000, splits=4)"},{"name":"RDD: range","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":1027.285023,"breakDown":[]},{"name":"DS: back-to-back filters","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001225,"analysisTime":0.001105,"optimizationTime":7.290869,"planningTime":0.378567,"executionTime":4276.785052,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1268L]\n+- 'Filter <function1>.apply\n   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#1267: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1265L]\n         +- Filter <function1>.apply\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1264: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1262L]\n                  +- Filter <function1>.apply\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1261: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1259L]\n                           +- Filter <function1>.apply\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1258: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1268L]\n+- Filter <function1>.apply\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1267: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1265L]\n         +- Filter <function1>.apply\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1264: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1262L]\n                  +- Filter <function1>.apply\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1261: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1259L]\n                           +- Filter <function1>.apply\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1258: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1268L]\n+- Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1258: com.imaginea.spark.tpcds.perf.Data\n      +- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1268L]\n+- *Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)\n   +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1258: com.imaginea.spark.tpcds.perf.Data\n      +- *Range (1, 100000000, splits=4)"},{"name":"DF: back-to-back filters","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001629,"analysisTime":0.001176,"optimizationTime":2.34206,"planningTime":0.340865,"executionTime":3563.31689,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Filter NOT (('id % 103) = 0)\n+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))\n   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))\n      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))\n         +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nFilter NOT ((id#0L % cast(103 as bigint)) = cast(0 as bigint))\n+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))\n   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))\n      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))\n         +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nFilter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))\n+- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Filter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))\n+- *Range (1, 100000000, splits=4)"},{"name":"RDD: back-to-back filters","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":3125.433794,"breakDown":[]},{"name":"DS: back-to-back maps","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001759,"analysisTime":0.001229,"optimizationTime":3.896061,"planningTime":0.563956,"executionTime":3815.455465,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1330L]\n+- 'MapElements <function1>, obj#1329: com.imaginea.spark.tpcds.perf.Data\n   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#1328: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1325L]\n         +- MapElements <function1>, obj#1324: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1323: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1320L]\n                  +- MapElements <function1>, obj#1319: com.imaginea.spark.tpcds.perf.Data\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1318: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1315L]\n                           +- MapElements <function1>, obj#1314: com.imaginea.spark.tpcds.perf.Data\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1313: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1330L]\n+- MapElements <function1>, obj#1329: com.imaginea.spark.tpcds.perf.Data\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1328: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1325L]\n         +- MapElements <function1>, obj#1324: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1323: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1320L]\n                  +- MapElements <function1>, obj#1319: com.imaginea.spark.tpcds.perf.Data\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1318: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1315L]\n                           +- MapElements <function1>, obj#1314: com.imaginea.spark.tpcds.perf.Data\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1313: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1330L]\n+- MapElements <function1>, obj#1329: com.imaginea.spark.tpcds.perf.Data\n   +- MapElements <function1>, obj#1324: com.imaginea.spark.tpcds.perf.Data\n      +- MapElements <function1>, obj#1319: com.imaginea.spark.tpcds.perf.Data\n         +- MapElements <function1>, obj#1314: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1313: com.imaginea.spark.tpcds.perf.Data\n               +- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1330L]\n+- *MapElements <function1>, obj#1329: com.imaginea.spark.tpcds.perf.Data\n   +- *MapElements <function1>, obj#1324: com.imaginea.spark.tpcds.perf.Data\n      +- *MapElements <function1>, obj#1319: com.imaginea.spark.tpcds.perf.Data\n         +- *MapElements <function1>, obj#1314: com.imaginea.spark.tpcds.perf.Data\n            +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1313: com.imaginea.spark.tpcds.perf.Data\n               +- *Range (1, 100000000, splits=4)"},{"name":"DF: back-to-back maps","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001802,"analysisTime":0.001027,"optimizationTime":1.128704,"planningTime":0.265869,"executionTime":3534.700451,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Project [('id + 1) AS id#1360]\n+- Project [(id#1354L + cast(1 as bigint)) AS id#1357L]\n   +- Project [(id#1351L + cast(1 as bigint)) AS id#1354L]\n      +- Project [(id#0L + cast(1 as bigint)) AS id#1351L]\n         +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nProject [(id#1357L + cast(1 as bigint)) AS id#1360L]\n+- Project [(id#1354L + cast(1 as bigint)) AS id#1357L]\n   +- Project [(id#1351L + cast(1 as bigint)) AS id#1354L]\n      +- Project [(id#0L + cast(1 as bigint)) AS id#1351L]\n         +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nProject [((((id#0L + 1) + 1) + 1) + 1) AS id#1360L]\n+- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Project [((((id#0L + 1) + 1) + 1) + 1) AS id#1360L]\n+- *Range (1, 100000000, splits=4)"},{"name":"RDD: back-to-back maps","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":4200.776856,"breakDown":[]},{"name":"DS: average","mode":"collect","parameters":{},"joinTypes":[],"tables":[],"breakDown":[],"failure":{"className":"org.apache.spark.sql.AnalysisException","message":"cannot resolve '`sum`' given input columns: [id];"}},{"name":"DF: average","mode":"collect","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001057,"analysisTime":7.76E-4,"optimizationTime":0.45058,"planningTime":0.925324,"executionTime":48.876151,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Project [unresolvedalias('avg('id), Some(<function1>))]\n+- Range (1, 1000000, splits=4)\n\n== Analyzed Logical Plan ==\navg(id): double\nAggregate [avg(id#3L) AS avg(id)#1388]\n+- Range (1, 1000000, splits=4)\n\n== Optimized Logical Plan ==\nAggregate [avg(id#3L) AS avg(id)#1388]\n+- Range (1, 1000000, splits=4)\n\n== Physical Plan ==\n*TungstenAggregate(key=[], functions=[avg(id#3L)], output=[avg(id)#1388])\n+- Exchange SinglePartition, None\n   +- *TungstenAggregate(key=[], functions=[partial_avg(id#3L)], output=[sum#1392,count#1393L])\n      +- *Range (1, 1000000, splits=4)"},{"name":"RDD: average","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":36.871703,"breakDown":[]},{"name":"DS: range","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.00112,"analysisTime":0.001196,"optimizationTime":0.285482,"planningTime":0.139903,"executionTime":3207.240406,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nRange (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Range (1, 100000000, splits=4)"},{"name":"DF: range","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001497,"analysisTime":0.001059,"optimizationTime":0.001801,"planningTime":0.00107,"executionTime":3374.334209,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nRange (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Range (1, 100000000, splits=4)"},{"name":"RDD: range","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":966.08197,"breakDown":[]},{"name":"DS: back-to-back filters","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001095,"analysisTime":8.51E-4,"optimizationTime":5.86166,"planningTime":0.540266,"executionTime":4023.464582,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1437L]\n+- 'Filter <function1>.apply\n   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#1436: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1434L]\n         +- Filter <function1>.apply\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1433: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1431L]\n                  +- Filter <function1>.apply\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1430: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1428L]\n                           +- Filter <function1>.apply\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1427: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1437L]\n+- Filter <function1>.apply\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1436: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1434L]\n         +- Filter <function1>.apply\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1433: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1431L]\n                  +- Filter <function1>.apply\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1430: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1428L]\n                           +- Filter <function1>.apply\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1427: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1437L]\n+- Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1427: com.imaginea.spark.tpcds.perf.Data\n      +- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1437L]\n+- *Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)\n   +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1427: com.imaginea.spark.tpcds.perf.Data\n      +- *Range (1, 100000000, splits=4)"},{"name":"DF: back-to-back filters","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001403,"analysisTime":9.58E-4,"optimizationTime":2.159238,"planningTime":0.582943,"executionTime":3503.545466,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Filter NOT (('id % 103) = 0)\n+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))\n   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))\n      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))\n         +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nFilter NOT ((id#0L % cast(103 as bigint)) = cast(0 as bigint))\n+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))\n   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))\n      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))\n         +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nFilter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))\n+- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Filter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))\n+- *Range (1, 100000000, splits=4)"},{"name":"RDD: back-to-back filters","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":3291.788791,"breakDown":[]},{"name":"DS: back-to-back maps","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001848,"analysisTime":9.07E-4,"optimizationTime":3.956525,"planningTime":0.659649,"executionTime":3956.941245,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1499L]\n+- 'MapElements <function1>, obj#1498: com.imaginea.spark.tpcds.perf.Data\n   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#1497: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1494L]\n         +- MapElements <function1>, obj#1493: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1492: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1489L]\n                  +- MapElements <function1>, obj#1488: com.imaginea.spark.tpcds.perf.Data\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1487: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1484L]\n                           +- MapElements <function1>, obj#1483: com.imaginea.spark.tpcds.perf.Data\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1482: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1499L]\n+- MapElements <function1>, obj#1498: com.imaginea.spark.tpcds.perf.Data\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1497: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1494L]\n         +- MapElements <function1>, obj#1493: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1492: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1489L]\n                  +- MapElements <function1>, obj#1488: com.imaginea.spark.tpcds.perf.Data\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1487: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1484L]\n                           +- MapElements <function1>, obj#1483: com.imaginea.spark.tpcds.perf.Data\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1482: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1499L]\n+- MapElements <function1>, obj#1498: com.imaginea.spark.tpcds.perf.Data\n   +- MapElements <function1>, obj#1493: com.imaginea.spark.tpcds.perf.Data\n      +- MapElements <function1>, obj#1488: com.imaginea.spark.tpcds.perf.Data\n         +- MapElements <function1>, obj#1483: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1482: com.imaginea.spark.tpcds.perf.Data\n               +- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1499L]\n+- *MapElements <function1>, obj#1498: com.imaginea.spark.tpcds.perf.Data\n   +- *MapElements <function1>, obj#1493: com.imaginea.spark.tpcds.perf.Data\n      +- *MapElements <function1>, obj#1488: com.imaginea.spark.tpcds.perf.Data\n         +- *MapElements <function1>, obj#1483: com.imaginea.spark.tpcds.perf.Data\n            +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1482: com.imaginea.spark.tpcds.perf.Data\n               +- *Range (1, 100000000, splits=4)"},{"name":"DF: back-to-back maps","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001523,"analysisTime":7.22E-4,"optimizationTime":1.1014,"planningTime":0.389949,"executionTime":3625.917749,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Project [('id + 1) AS id#1529]\n+- Project [(id#1523L + cast(1 as bigint)) AS id#1526L]\n   +- Project [(id#1520L + cast(1 as bigint)) AS id#1523L]\n      +- Project [(id#0L + cast(1 as bigint)) AS id#1520L]\n         +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nProject [(id#1526L + cast(1 as bigint)) AS id#1529L]\n+- Project [(id#1523L + cast(1 as bigint)) AS id#1526L]\n   +- Project [(id#1520L + cast(1 as bigint)) AS id#1523L]\n      +- Project [(id#0L + cast(1 as bigint)) AS id#1520L]\n         +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nProject [((((id#0L + 1) + 1) + 1) + 1) AS id#1529L]\n+- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Project [((((id#0L + 1) + 1) + 1) + 1) AS id#1529L]\n+- *Range (1, 100000000, splits=4)"},{"name":"RDD: back-to-back maps","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":4210.221393,"breakDown":[]},{"name":"DS: average","mode":"collect","parameters":{},"joinTypes":[],"tables":[],"breakDown":[],"failure":{"className":"org.apache.spark.sql.AnalysisException","message":"cannot resolve '`sum`' given input columns: [id];"}},{"name":"DF: average","mode":"collect","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001264,"analysisTime":7.17E-4,"optimizationTime":0.433953,"planningTime":0.543179,"executionTime":50.109791,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Project [unresolvedalias('avg('id), Some(<function1>))]\n+- Range (1, 1000000, splits=4)\n\n== Analyzed Logical Plan ==\navg(id): double\nAggregate [avg(id#3L) AS avg(id)#1557]\n+- Range (1, 1000000, splits=4)\n\n== Optimized Logical Plan ==\nAggregate [avg(id#3L) AS avg(id)#1557]\n+- Range (1, 1000000, splits=4)\n\n== Physical Plan ==\n*TungstenAggregate(key=[], functions=[avg(id#3L)], output=[avg(id)#1557])\n+- Exchange SinglePartition, None\n   +- *TungstenAggregate(key=[], functions=[partial_avg(id#3L)], output=[sum#1561,count#1562L])\n      +- *Range (1, 1000000, splits=4)"},{"name":"RDD: average","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":35.238127,"breakDown":[]}]}
