{"timestamp":1464960505478,"iteration":1,"tags":{"StandardRun":"true","runtype":"local","host":"PRINHYLTPHP0415"},"configuration":{"sparkVersion":"2.0.0-SNAPSHOT","sqlConf":{"spark.tpcds.perf.results":"file:/home/charanjits/Documents/ideaProjects/finalProjectImaginea/spark-tpcds-perf-master/performance/","spark.driver.host":"172.16.54.31","spark.driver.port":"34635","spark.app.name":"com.imaginea.spark.tpcds.perf.RunBenchmark$","spark.executor.id":"driver","spark.master":"local[*]","spark.app.id":"local-1464960501432"},"sparkConf":{"spark.driver.host":"172.16.54.31","spark.driver.port":"34635","spark.app.name":"com.imaginea.spark.tpcds.perf.RunBenchmark$","spark.executor.id":"driver","spark.master":"local[*]","spark.app.id":"local-1464960501432"},"defaultParallelism":4,"buildInfo":{}},"results":[{"name":"DS: range","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.014869,"analysisTime":0.008876,"optimizationTime":1.351276,"planningTime":0.345931,"executionTime":4398.951552,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nRange (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Range (1, 100000000, splits=4)"},{"name":"DF: range","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.002013,"analysisTime":0.001238,"optimizationTime":0.001707,"planningTime":0.001366,"executionTime":3869.758456,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nRange (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Range (1, 100000000, splits=4)"},{"name":"RDD: range","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":1497.568355,"breakDown":[]},{"name":"DS: back-to-back filters","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":8.59E-4,"analysisTime":6.96E-4,"optimizationTime":13.860057,"planningTime":2.522157,"executionTime":4306.556268,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#524L]\n+- 'Filter <function1>.apply\n   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#523: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#521L]\n         +- Filter <function1>.apply\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#520: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#518L]\n                  +- Filter <function1>.apply\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#517: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#515L]\n                           +- Filter <function1>.apply\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#514: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#524L]\n+- Filter <function1>.apply\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#523: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#521L]\n         +- Filter <function1>.apply\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#520: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#518L]\n                  +- Filter <function1>.apply\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#517: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#515L]\n                           +- Filter <function1>.apply\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#514: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#524L]\n+- Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#514: com.imaginea.spark.tpcds.perf.Data\n      +- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#524L]\n+- *Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)\n   +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#514: com.imaginea.spark.tpcds.perf.Data\n      +- *Range (1, 100000000, splits=4)"},{"name":"DF: back-to-back filters","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001783,"analysisTime":9.6E-4,"optimizationTime":5.031709,"planningTime":0.773808,"executionTime":3750.542027,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Filter NOT (('id % 103) = 0)\n+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))\n   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))\n      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))\n         +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nFilter NOT ((id#0L % cast(103 as bigint)) = cast(0 as bigint))\n+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))\n   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))\n      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))\n         +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nFilter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))\n+- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Filter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))\n+- *Range (1, 100000000, splits=4)"},{"name":"RDD: back-to-back filters","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":4177.993467,"breakDown":[]},{"name":"DS: back-to-back maps","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001781,"analysisTime":0.001526,"optimizationTime":5.274872,"planningTime":0.918184,"executionTime":4122.165263,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#608L]\n+- 'MapElements <function1>, obj#607: com.imaginea.spark.tpcds.perf.Data\n   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#606: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#603L]\n         +- MapElements <function1>, obj#602: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#601: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#598L]\n                  +- MapElements <function1>, obj#597: com.imaginea.spark.tpcds.perf.Data\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#596: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#593L]\n                           +- MapElements <function1>, obj#592: com.imaginea.spark.tpcds.perf.Data\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#591: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#608L]\n+- MapElements <function1>, obj#607: com.imaginea.spark.tpcds.perf.Data\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#606: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#603L]\n         +- MapElements <function1>, obj#602: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#601: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#598L]\n                  +- MapElements <function1>, obj#597: com.imaginea.spark.tpcds.perf.Data\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#596: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#593L]\n                           +- MapElements <function1>, obj#592: com.imaginea.spark.tpcds.perf.Data\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#591: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#608L]\n+- MapElements <function1>, obj#607: com.imaginea.spark.tpcds.perf.Data\n   +- MapElements <function1>, obj#602: com.imaginea.spark.tpcds.perf.Data\n      +- MapElements <function1>, obj#597: com.imaginea.spark.tpcds.perf.Data\n         +- MapElements <function1>, obj#592: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#591: com.imaginea.spark.tpcds.perf.Data\n               +- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#608L]\n+- *MapElements <function1>, obj#607: com.imaginea.spark.tpcds.perf.Data\n   +- *MapElements <function1>, obj#602: com.imaginea.spark.tpcds.perf.Data\n      +- *MapElements <function1>, obj#597: com.imaginea.spark.tpcds.perf.Data\n         +- *MapElements <function1>, obj#592: com.imaginea.spark.tpcds.perf.Data\n            +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#591: com.imaginea.spark.tpcds.perf.Data\n               +- *Range (1, 100000000, splits=4)"},{"name":"DF: back-to-back maps","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001461,"analysisTime":9.9E-4,"optimizationTime":2.203881,"planningTime":0.653296,"executionTime":3601.9408,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Project [('id + 1) AS id#662]\n+- Project [(id#656L + cast(1 as bigint)) AS id#659L]\n   +- Project [(id#653L + cast(1 as bigint)) AS id#656L]\n      +- Project [(id#0L + cast(1 as bigint)) AS id#653L]\n         +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nProject [(id#659L + cast(1 as bigint)) AS id#662L]\n+- Project [(id#656L + cast(1 as bigint)) AS id#659L]\n   +- Project [(id#653L + cast(1 as bigint)) AS id#656L]\n      +- Project [(id#0L + cast(1 as bigint)) AS id#653L]\n         +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nProject [((((id#0L + 1) + 1) + 1) + 1) AS id#662L]\n+- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Project [((((id#0L + 1) + 1) + 1) + 1) AS id#662L]\n+- *Range (1, 100000000, splits=4)"},{"name":"RDD: back-to-back maps","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":4875.989876,"breakDown":[]},{"name":"DS: average","mode":"collect","parameters":{},"joinTypes":[],"tables":[],"breakDown":[],"failure":{"className":"org.apache.spark.sql.AnalysisException","message":"cannot resolve '`sum`' given input columns: [id];"}},{"name":"DF: average","mode":"collect","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.013864,"analysisTime":0.001909,"optimizationTime":0.57483,"planningTime":0.868497,"executionTime":304.652216,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Project [unresolvedalias('avg('id), Some(<function1>))]\n+- Range (1, 1000000, splits=4)\n\n== Analyzed Logical Plan ==\navg(id): double\nAggregate [avg(id#3L) AS avg(id)#704]\n+- Range (1, 1000000, splits=4)\n\n== Optimized Logical Plan ==\nAggregate [avg(id#3L) AS avg(id)#704]\n+- Range (1, 1000000, splits=4)\n\n== Physical Plan ==\n*TungstenAggregate(key=[], functions=[avg(id#3L)], output=[avg(id)#704])\n+- Exchange SinglePartition, None\n   +- *TungstenAggregate(key=[], functions=[partial_avg(id#3L)], output=[sum#708,count#709L])\n      +- *Range (1, 1000000, splits=4)"},{"name":"RDD: average","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":65.945349,"breakDown":[]},{"name":"DS: range","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001166,"analysisTime":0.001012,"optimizationTime":0.337299,"planningTime":0.239459,"executionTime":3209.78656,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nRange (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Range (1, 100000000, splits=4)"},{"name":"DF: range","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001619,"analysisTime":0.001255,"optimizationTime":0.001995,"planningTime":0.001285,"executionTime":3880.349821,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nRange (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Range (1, 100000000, splits=4)"},{"name":"RDD: range","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":1670.343688,"breakDown":[]},{"name":"DS: back-to-back filters","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001414,"analysisTime":0.001342,"optimizationTime":12.612617,"planningTime":0.893198,"executionTime":4089.140306,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#761L]\n+- 'Filter <function1>.apply\n   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#760: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#758L]\n         +- Filter <function1>.apply\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#757: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#755L]\n                  +- Filter <function1>.apply\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#754: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#752L]\n                           +- Filter <function1>.apply\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#751: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#761L]\n+- Filter <function1>.apply\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#760: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#758L]\n         +- Filter <function1>.apply\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#757: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#755L]\n                  +- Filter <function1>.apply\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#754: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#752L]\n                           +- Filter <function1>.apply\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#751: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#761L]\n+- Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#751: com.imaginea.spark.tpcds.perf.Data\n      +- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#761L]\n+- *Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)\n   +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#751: com.imaginea.spark.tpcds.perf.Data\n      +- *Range (1, 100000000, splits=4)"},{"name":"DF: back-to-back filters","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.004448,"analysisTime":0.002941,"optimizationTime":5.251847,"planningTime":0.422898,"executionTime":3716.546276,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Filter NOT (('id % 103) = 0)\n+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))\n   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))\n      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))\n         +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nFilter NOT ((id#0L % cast(103 as bigint)) = cast(0 as bigint))\n+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))\n   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))\n      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))\n         +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nFilter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))\n+- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Filter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))\n+- *Range (1, 100000000, splits=4)"},{"name":"RDD: back-to-back filters","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":4160.747992,"breakDown":[]},{"name":"DS: back-to-back maps","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001881,"analysisTime":0.001388,"optimizationTime":5.871702,"planningTime":0.980631,"executionTime":3851.479931,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#823L]\n+- 'MapElements <function1>, obj#822: com.imaginea.spark.tpcds.perf.Data\n   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#821: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#818L]\n         +- MapElements <function1>, obj#817: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#816: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#813L]\n                  +- MapElements <function1>, obj#812: com.imaginea.spark.tpcds.perf.Data\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#811: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#808L]\n                           +- MapElements <function1>, obj#807: com.imaginea.spark.tpcds.perf.Data\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#806: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#823L]\n+- MapElements <function1>, obj#822: com.imaginea.spark.tpcds.perf.Data\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#821: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#818L]\n         +- MapElements <function1>, obj#817: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#816: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#813L]\n                  +- MapElements <function1>, obj#812: com.imaginea.spark.tpcds.perf.Data\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#811: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#808L]\n                           +- MapElements <function1>, obj#807: com.imaginea.spark.tpcds.perf.Data\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#806: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#823L]\n+- MapElements <function1>, obj#822: com.imaginea.spark.tpcds.perf.Data\n   +- MapElements <function1>, obj#817: com.imaginea.spark.tpcds.perf.Data\n      +- MapElements <function1>, obj#812: com.imaginea.spark.tpcds.perf.Data\n         +- MapElements <function1>, obj#807: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#806: com.imaginea.spark.tpcds.perf.Data\n               +- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#823L]\n+- *MapElements <function1>, obj#822: com.imaginea.spark.tpcds.perf.Data\n   +- *MapElements <function1>, obj#817: com.imaginea.spark.tpcds.perf.Data\n      +- *MapElements <function1>, obj#812: com.imaginea.spark.tpcds.perf.Data\n         +- *MapElements <function1>, obj#807: com.imaginea.spark.tpcds.perf.Data\n            +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#806: com.imaginea.spark.tpcds.perf.Data\n               +- *Range (1, 100000000, splits=4)"},{"name":"DF: back-to-back maps","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001986,"analysisTime":0.001358,"optimizationTime":2.135375,"planningTime":0.572463,"executionTime":3378.095911,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Project [('id + 1) AS id#853]\n+- Project [(id#847L + cast(1 as bigint)) AS id#850L]\n   +- Project [(id#844L + cast(1 as bigint)) AS id#847L]\n      +- Project [(id#0L + cast(1 as bigint)) AS id#844L]\n         +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nProject [(id#850L + cast(1 as bigint)) AS id#853L]\n+- Project [(id#847L + cast(1 as bigint)) AS id#850L]\n   +- Project [(id#844L + cast(1 as bigint)) AS id#847L]\n      +- Project [(id#0L + cast(1 as bigint)) AS id#844L]\n         +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nProject [((((id#0L + 1) + 1) + 1) + 1) AS id#853L]\n+- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Project [((((id#0L + 1) + 1) + 1) + 1) AS id#853L]\n+- *Range (1, 100000000, splits=4)"},{"name":"RDD: back-to-back maps","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":4088.368795,"breakDown":[]},{"name":"DS: average","mode":"collect","parameters":{},"joinTypes":[],"tables":[],"breakDown":[],"failure":{"className":"org.apache.spark.sql.AnalysisException","message":"cannot resolve '`sum`' given input columns: [id];"}},{"name":"DF: average","mode":"collect","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.002162,"analysisTime":9.96E-4,"optimizationTime":1.932417,"planningTime":0.902436,"executionTime":76.733227,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Project [unresolvedalias('avg('id), Some(<function1>))]\n+- Range (1, 1000000, splits=4)\n\n== Analyzed Logical Plan ==\navg(id): double\nAggregate [avg(id#3L) AS avg(id)#881]\n+- Range (1, 1000000, splits=4)\n\n== Optimized Logical Plan ==\nAggregate [avg(id#3L) AS avg(id)#881]\n+- Range (1, 1000000, splits=4)\n\n== Physical Plan ==\n*TungstenAggregate(key=[], functions=[avg(id#3L)], output=[avg(id)#881])\n+- Exchange SinglePartition, None\n   +- *TungstenAggregate(key=[], functions=[partial_avg(id#3L)], output=[sum#885,count#886L])\n      +- *Range (1, 1000000, splits=4)"},{"name":"RDD: average","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":56.673497,"breakDown":[]}]}
{"timestamp":1464960505478,"iteration":2,"tags":{"StandardRun":"true","runtype":"local","host":"PRINHYLTPHP0415"},"configuration":{"sparkVersion":"2.0.0-SNAPSHOT","sqlConf":{"spark.tpcds.perf.results":"file:/home/charanjits/Documents/ideaProjects/finalProjectImaginea/spark-tpcds-perf-master/performance/","spark.driver.host":"172.16.54.31","spark.driver.port":"34635","spark.app.name":"com.imaginea.spark.tpcds.perf.RunBenchmark$","spark.executor.id":"driver","spark.master":"local[*]","spark.app.id":"local-1464960501432"},"sparkConf":{"spark.driver.host":"172.16.54.31","spark.driver.port":"34635","spark.app.name":"com.imaginea.spark.tpcds.perf.RunBenchmark$","spark.executor.id":"driver","spark.master":"local[*]","spark.app.id":"local-1464960501432"},"defaultParallelism":4,"buildInfo":{}},"results":[{"name":"DS: range","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001921,"analysisTime":0.001439,"optimizationTime":0.466101,"planningTime":0.247087,"executionTime":3448.576249,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nRange (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Range (1, 100000000, splits=4)"},{"name":"DF: range","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001342,"analysisTime":9.09E-4,"optimizationTime":0.00152,"planningTime":7.92E-4,"executionTime":3175.922093,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nRange (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Range (1, 100000000, splits=4)"},{"name":"RDD: range","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":1479.161667,"breakDown":[]},{"name":"DS: back-to-back filters","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001037,"analysisTime":7.76E-4,"optimizationTime":8.88002,"planningTime":0.574273,"executionTime":3910.666043,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#930L]\n+- 'Filter <function1>.apply\n   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#929: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#927L]\n         +- Filter <function1>.apply\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#926: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#924L]\n                  +- Filter <function1>.apply\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#923: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#921L]\n                           +- Filter <function1>.apply\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#920: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#930L]\n+- Filter <function1>.apply\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#929: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#927L]\n         +- Filter <function1>.apply\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#926: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#924L]\n                  +- Filter <function1>.apply\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#923: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#921L]\n                           +- Filter <function1>.apply\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#920: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#930L]\n+- Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#920: com.imaginea.spark.tpcds.perf.Data\n      +- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#930L]\n+- *Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)\n   +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#920: com.imaginea.spark.tpcds.perf.Data\n      +- *Range (1, 100000000, splits=4)"},{"name":"DF: back-to-back filters","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.003899,"analysisTime":0.002644,"optimizationTime":3.725577,"planningTime":0.542486,"executionTime":3404.348796,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Filter NOT (('id % 103) = 0)\n+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))\n   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))\n      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))\n         +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nFilter NOT ((id#0L % cast(103 as bigint)) = cast(0 as bigint))\n+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))\n   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))\n      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))\n         +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nFilter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))\n+- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Filter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))\n+- *Range (1, 100000000, splits=4)"},{"name":"RDD: back-to-back filters","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":3834.799041,"breakDown":[]},{"name":"DS: back-to-back maps","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001529,"analysisTime":0.001104,"optimizationTime":3.907686,"planningTime":0.645676,"executionTime":4191.606314,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#992L]\n+- 'MapElements <function1>, obj#991: com.imaginea.spark.tpcds.perf.Data\n   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#990: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#987L]\n         +- MapElements <function1>, obj#986: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#985: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#982L]\n                  +- MapElements <function1>, obj#981: com.imaginea.spark.tpcds.perf.Data\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#980: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#977L]\n                           +- MapElements <function1>, obj#976: com.imaginea.spark.tpcds.perf.Data\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#975: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#992L]\n+- MapElements <function1>, obj#991: com.imaginea.spark.tpcds.perf.Data\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#990: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#987L]\n         +- MapElements <function1>, obj#986: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#985: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#982L]\n                  +- MapElements <function1>, obj#981: com.imaginea.spark.tpcds.perf.Data\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#980: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#977L]\n                           +- MapElements <function1>, obj#976: com.imaginea.spark.tpcds.perf.Data\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#975: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#992L]\n+- MapElements <function1>, obj#991: com.imaginea.spark.tpcds.perf.Data\n   +- MapElements <function1>, obj#986: com.imaginea.spark.tpcds.perf.Data\n      +- MapElements <function1>, obj#981: com.imaginea.spark.tpcds.perf.Data\n         +- MapElements <function1>, obj#976: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#975: com.imaginea.spark.tpcds.perf.Data\n               +- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#992L]\n+- *MapElements <function1>, obj#991: com.imaginea.spark.tpcds.perf.Data\n   +- *MapElements <function1>, obj#986: com.imaginea.spark.tpcds.perf.Data\n      +- *MapElements <function1>, obj#981: com.imaginea.spark.tpcds.perf.Data\n         +- *MapElements <function1>, obj#976: com.imaginea.spark.tpcds.perf.Data\n            +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#975: com.imaginea.spark.tpcds.perf.Data\n               +- *Range (1, 100000000, splits=4)"},{"name":"DF: back-to-back maps","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.0015,"analysisTime":0.001095,"optimizationTime":1.53215,"planningTime":0.891731,"executionTime":3374.732918,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Project [('id + 1) AS id#1022]\n+- Project [(id#1016L + cast(1 as bigint)) AS id#1019L]\n   +- Project [(id#1013L + cast(1 as bigint)) AS id#1016L]\n      +- Project [(id#0L + cast(1 as bigint)) AS id#1013L]\n         +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nProject [(id#1019L + cast(1 as bigint)) AS id#1022L]\n+- Project [(id#1016L + cast(1 as bigint)) AS id#1019L]\n   +- Project [(id#1013L + cast(1 as bigint)) AS id#1016L]\n      +- Project [(id#0L + cast(1 as bigint)) AS id#1013L]\n         +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nProject [((((id#0L + 1) + 1) + 1) + 1) AS id#1022L]\n+- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Project [((((id#0L + 1) + 1) + 1) + 1) AS id#1022L]\n+- *Range (1, 100000000, splits=4)"},{"name":"RDD: back-to-back maps","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":4094.805786,"breakDown":[]},{"name":"DS: average","mode":"collect","parameters":{},"joinTypes":[],"tables":[],"breakDown":[],"failure":{"className":"org.apache.spark.sql.AnalysisException","message":"cannot resolve '`sum`' given input columns: [id];"}},{"name":"DF: average","mode":"collect","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.00176,"analysisTime":9.06E-4,"optimizationTime":2.64211,"planningTime":1.010456,"executionTime":60.284314,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Project [unresolvedalias('avg('id), Some(<function1>))]\n+- Range (1, 1000000, splits=4)\n\n== Analyzed Logical Plan ==\navg(id): double\nAggregate [avg(id#3L) AS avg(id)#1050]\n+- Range (1, 1000000, splits=4)\n\n== Optimized Logical Plan ==\nAggregate [avg(id#3L) AS avg(id)#1050]\n+- Range (1, 1000000, splits=4)\n\n== Physical Plan ==\n*TungstenAggregate(key=[], functions=[avg(id#3L)], output=[avg(id)#1050])\n+- Exchange SinglePartition, None\n   +- *TungstenAggregate(key=[], functions=[partial_avg(id#3L)], output=[sum#1054,count#1055L])\n      +- *Range (1, 1000000, splits=4)"},{"name":"RDD: average","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":40.480123,"breakDown":[]},{"name":"DS: range","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.002178,"analysisTime":0.001048,"optimizationTime":0.440891,"planningTime":0.218208,"executionTime":3268.299148,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nRange (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Range (1, 100000000, splits=4)"},{"name":"DF: range","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001288,"analysisTime":0.001444,"optimizationTime":0.001802,"planningTime":9.55E-4,"executionTime":3287.805028,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nRange (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Range (1, 100000000, splits=4)"},{"name":"RDD: range","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":1363.120005,"breakDown":[]},{"name":"DS: back-to-back filters","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001661,"analysisTime":0.00103,"optimizationTime":8.618349,"planningTime":0.425212,"executionTime":4048.492406,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1099L]\n+- 'Filter <function1>.apply\n   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#1098: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1096L]\n         +- Filter <function1>.apply\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1095: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1093L]\n                  +- Filter <function1>.apply\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1092: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1090L]\n                           +- Filter <function1>.apply\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1089: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1099L]\n+- Filter <function1>.apply\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1098: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1096L]\n         +- Filter <function1>.apply\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1095: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1093L]\n                  +- Filter <function1>.apply\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1092: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1090L]\n                           +- Filter <function1>.apply\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1089: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1099L]\n+- Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1089: com.imaginea.spark.tpcds.perf.Data\n      +- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1099L]\n+- *Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)\n   +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1089: com.imaginea.spark.tpcds.perf.Data\n      +- *Range (1, 100000000, splits=4)"},{"name":"DF: back-to-back filters","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001959,"analysisTime":0.001094,"optimizationTime":3.296864,"planningTime":0.487651,"executionTime":3447.3026,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Filter NOT (('id % 103) = 0)\n+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))\n   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))\n      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))\n         +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nFilter NOT ((id#0L % cast(103 as bigint)) = cast(0 as bigint))\n+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))\n   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))\n      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))\n         +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nFilter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))\n+- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Filter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))\n+- *Range (1, 100000000, splits=4)"},{"name":"RDD: back-to-back filters","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":3858.542176,"breakDown":[]},{"name":"DS: back-to-back maps","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001932,"analysisTime":0.00124,"optimizationTime":2.825995,"planningTime":0.573197,"executionTime":4703.555971,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1161L]\n+- 'MapElements <function1>, obj#1160: com.imaginea.spark.tpcds.perf.Data\n   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#1159: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1156L]\n         +- MapElements <function1>, obj#1155: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1154: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1151L]\n                  +- MapElements <function1>, obj#1150: com.imaginea.spark.tpcds.perf.Data\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1149: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1146L]\n                           +- MapElements <function1>, obj#1145: com.imaginea.spark.tpcds.perf.Data\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1144: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1161L]\n+- MapElements <function1>, obj#1160: com.imaginea.spark.tpcds.perf.Data\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1159: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1156L]\n         +- MapElements <function1>, obj#1155: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1154: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1151L]\n                  +- MapElements <function1>, obj#1150: com.imaginea.spark.tpcds.perf.Data\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1149: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1146L]\n                           +- MapElements <function1>, obj#1145: com.imaginea.spark.tpcds.perf.Data\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1144: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1161L]\n+- MapElements <function1>, obj#1160: com.imaginea.spark.tpcds.perf.Data\n   +- MapElements <function1>, obj#1155: com.imaginea.spark.tpcds.perf.Data\n      +- MapElements <function1>, obj#1150: com.imaginea.spark.tpcds.perf.Data\n         +- MapElements <function1>, obj#1145: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1144: com.imaginea.spark.tpcds.perf.Data\n               +- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1161L]\n+- *MapElements <function1>, obj#1160: com.imaginea.spark.tpcds.perf.Data\n   +- *MapElements <function1>, obj#1155: com.imaginea.spark.tpcds.perf.Data\n      +- *MapElements <function1>, obj#1150: com.imaginea.spark.tpcds.perf.Data\n         +- *MapElements <function1>, obj#1145: com.imaginea.spark.tpcds.perf.Data\n            +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1144: com.imaginea.spark.tpcds.perf.Data\n               +- *Range (1, 100000000, splits=4)"},{"name":"DF: back-to-back maps","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001645,"analysisTime":8.5E-4,"optimizationTime":1.603102,"planningTime":0.356338,"executionTime":5522.868168,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Project [('id + 1) AS id#1191]\n+- Project [(id#1185L + cast(1 as bigint)) AS id#1188L]\n   +- Project [(id#1182L + cast(1 as bigint)) AS id#1185L]\n      +- Project [(id#0L + cast(1 as bigint)) AS id#1182L]\n         +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nProject [(id#1188L + cast(1 as bigint)) AS id#1191L]\n+- Project [(id#1185L + cast(1 as bigint)) AS id#1188L]\n   +- Project [(id#1182L + cast(1 as bigint)) AS id#1185L]\n      +- Project [(id#0L + cast(1 as bigint)) AS id#1182L]\n         +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nProject [((((id#0L + 1) + 1) + 1) + 1) AS id#1191L]\n+- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Project [((((id#0L + 1) + 1) + 1) + 1) AS id#1191L]\n+- *Range (1, 100000000, splits=4)"},{"name":"RDD: back-to-back maps","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":6723.30921,"breakDown":[]},{"name":"DS: average","mode":"collect","parameters":{},"joinTypes":[],"tables":[],"breakDown":[],"failure":{"className":"org.apache.spark.sql.AnalysisException","message":"cannot resolve '`sum`' given input columns: [id];"}},{"name":"DF: average","mode":"collect","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001504,"analysisTime":8.58E-4,"optimizationTime":0.577209,"planningTime":0.847894,"executionTime":58.285907,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Project [unresolvedalias('avg('id), Some(<function1>))]\n+- Range (1, 1000000, splits=4)\n\n== Analyzed Logical Plan ==\navg(id): double\nAggregate [avg(id#3L) AS avg(id)#1219]\n+- Range (1, 1000000, splits=4)\n\n== Optimized Logical Plan ==\nAggregate [avg(id#3L) AS avg(id)#1219]\n+- Range (1, 1000000, splits=4)\n\n== Physical Plan ==\n*TungstenAggregate(key=[], functions=[avg(id#3L)], output=[avg(id)#1219])\n+- Exchange SinglePartition, None\n   +- *TungstenAggregate(key=[], functions=[partial_avg(id#3L)], output=[sum#1223,count#1224L])\n      +- *Range (1, 1000000, splits=4)"},{"name":"RDD: average","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":63.306984,"breakDown":[]}]}
{"timestamp":1464960505478,"iteration":3,"tags":{"StandardRun":"true","runtype":"local","host":"PRINHYLTPHP0415"},"configuration":{"sparkVersion":"2.0.0-SNAPSHOT","sqlConf":{"spark.tpcds.perf.results":"file:/home/charanjits/Documents/ideaProjects/finalProjectImaginea/spark-tpcds-perf-master/performance/","spark.driver.host":"172.16.54.31","spark.driver.port":"34635","spark.app.name":"com.imaginea.spark.tpcds.perf.RunBenchmark$","spark.executor.id":"driver","spark.master":"local[*]","spark.app.id":"local-1464960501432"},"sparkConf":{"spark.driver.host":"172.16.54.31","spark.driver.port":"34635","spark.app.name":"com.imaginea.spark.tpcds.perf.RunBenchmark$","spark.executor.id":"driver","spark.master":"local[*]","spark.app.id":"local-1464960501432"},"defaultParallelism":4,"buildInfo":{}},"results":[{"name":"DS: range","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001542,"analysisTime":9.34E-4,"optimizationTime":0.410325,"planningTime":0.166802,"executionTime":5570.762009,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nRange (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Range (1, 100000000, splits=4)"},{"name":"DF: range","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001696,"analysisTime":0.001249,"optimizationTime":0.001968,"planningTime":0.001357,"executionTime":4281.949116,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nRange (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Range (1, 100000000, splits=4)"},{"name":"RDD: range","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":1553.968241,"breakDown":[]},{"name":"DS: back-to-back filters","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001335,"analysisTime":0.001037,"optimizationTime":6.601592,"planningTime":0.418214,"executionTime":3936.886767,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1268L]\n+- 'Filter <function1>.apply\n   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#1267: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1265L]\n         +- Filter <function1>.apply\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1264: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1262L]\n                  +- Filter <function1>.apply\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1261: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1259L]\n                           +- Filter <function1>.apply\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1258: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1268L]\n+- Filter <function1>.apply\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1267: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1265L]\n         +- Filter <function1>.apply\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1264: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1262L]\n                  +- Filter <function1>.apply\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1261: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1259L]\n                           +- Filter <function1>.apply\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1258: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1268L]\n+- Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1258: com.imaginea.spark.tpcds.perf.Data\n      +- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1268L]\n+- *Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)\n   +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1258: com.imaginea.spark.tpcds.perf.Data\n      +- *Range (1, 100000000, splits=4)"},{"name":"DF: back-to-back filters","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.006409,"analysisTime":0.003892,"optimizationTime":6.785943,"planningTime":0.64652,"executionTime":3563.76631,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Filter NOT (('id % 103) = 0)\n+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))\n   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))\n      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))\n         +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nFilter NOT ((id#0L % cast(103 as bigint)) = cast(0 as bigint))\n+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))\n   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))\n      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))\n         +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nFilter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))\n+- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Filter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))\n+- *Range (1, 100000000, splits=4)"},{"name":"RDD: back-to-back filters","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":3637.068488,"breakDown":[]},{"name":"DS: back-to-back maps","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001489,"analysisTime":0.001131,"optimizationTime":3.959691,"planningTime":0.562335,"executionTime":4105.444376,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1330L]\n+- 'MapElements <function1>, obj#1329: com.imaginea.spark.tpcds.perf.Data\n   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#1328: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1325L]\n         +- MapElements <function1>, obj#1324: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1323: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1320L]\n                  +- MapElements <function1>, obj#1319: com.imaginea.spark.tpcds.perf.Data\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1318: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1315L]\n                           +- MapElements <function1>, obj#1314: com.imaginea.spark.tpcds.perf.Data\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1313: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1330L]\n+- MapElements <function1>, obj#1329: com.imaginea.spark.tpcds.perf.Data\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1328: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1325L]\n         +- MapElements <function1>, obj#1324: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1323: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1320L]\n                  +- MapElements <function1>, obj#1319: com.imaginea.spark.tpcds.perf.Data\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1318: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1315L]\n                           +- MapElements <function1>, obj#1314: com.imaginea.spark.tpcds.perf.Data\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1313: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1330L]\n+- MapElements <function1>, obj#1329: com.imaginea.spark.tpcds.perf.Data\n   +- MapElements <function1>, obj#1324: com.imaginea.spark.tpcds.perf.Data\n      +- MapElements <function1>, obj#1319: com.imaginea.spark.tpcds.perf.Data\n         +- MapElements <function1>, obj#1314: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1313: com.imaginea.spark.tpcds.perf.Data\n               +- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1330L]\n+- *MapElements <function1>, obj#1329: com.imaginea.spark.tpcds.perf.Data\n   +- *MapElements <function1>, obj#1324: com.imaginea.spark.tpcds.perf.Data\n      +- *MapElements <function1>, obj#1319: com.imaginea.spark.tpcds.perf.Data\n         +- *MapElements <function1>, obj#1314: com.imaginea.spark.tpcds.perf.Data\n            +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1313: com.imaginea.spark.tpcds.perf.Data\n               +- *Range (1, 100000000, splits=4)"},{"name":"DF: back-to-back maps","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.00172,"analysisTime":9.53E-4,"optimizationTime":2.521934,"planningTime":0.878691,"executionTime":3561.327051,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Project [('id + 1) AS id#1360]\n+- Project [(id#1354L + cast(1 as bigint)) AS id#1357L]\n   +- Project [(id#1351L + cast(1 as bigint)) AS id#1354L]\n      +- Project [(id#0L + cast(1 as bigint)) AS id#1351L]\n         +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nProject [(id#1357L + cast(1 as bigint)) AS id#1360L]\n+- Project [(id#1354L + cast(1 as bigint)) AS id#1357L]\n   +- Project [(id#1351L + cast(1 as bigint)) AS id#1354L]\n      +- Project [(id#0L + cast(1 as bigint)) AS id#1351L]\n         +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nProject [((((id#0L + 1) + 1) + 1) + 1) AS id#1360L]\n+- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Project [((((id#0L + 1) + 1) + 1) + 1) AS id#1360L]\n+- *Range (1, 100000000, splits=4)"},{"name":"RDD: back-to-back maps","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":4565.548436,"breakDown":[]},{"name":"DS: average","mode":"collect","parameters":{},"joinTypes":[],"tables":[],"breakDown":[],"failure":{"className":"org.apache.spark.sql.AnalysisException","message":"cannot resolve '`sum`' given input columns: [id];"}},{"name":"DF: average","mode":"collect","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001405,"analysisTime":0.001305,"optimizationTime":0.53072,"planningTime":1.006374,"executionTime":74.259807,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Project [unresolvedalias('avg('id), Some(<function1>))]\n+- Range (1, 1000000, splits=4)\n\n== Analyzed Logical Plan ==\navg(id): double\nAggregate [avg(id#3L) AS avg(id)#1388]\n+- Range (1, 1000000, splits=4)\n\n== Optimized Logical Plan ==\nAggregate [avg(id#3L) AS avg(id)#1388]\n+- Range (1, 1000000, splits=4)\n\n== Physical Plan ==\n*TungstenAggregate(key=[], functions=[avg(id#3L)], output=[avg(id)#1388])\n+- Exchange SinglePartition, None\n   +- *TungstenAggregate(key=[], functions=[partial_avg(id#3L)], output=[sum#1392,count#1393L])\n      +- *Range (1, 1000000, splits=4)"},{"name":"RDD: average","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":46.286332,"breakDown":[]},{"name":"DS: range","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001254,"analysisTime":7.19E-4,"optimizationTime":0.283,"planningTime":0.153909,"executionTime":4016.450458,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nRange (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Range (1, 100000000, splits=4)"},{"name":"DF: range","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.00133,"analysisTime":7.86E-4,"optimizationTime":0.001497,"planningTime":0.001219,"executionTime":3877.728639,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nRange (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Range (1, 100000000, splits=4)"},{"name":"RDD: range","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":1571.154404,"breakDown":[]},{"name":"DS: back-to-back filters","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001979,"analysisTime":8.66E-4,"optimizationTime":8.293916,"planningTime":0.497959,"executionTime":4156.928848,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1437L]\n+- 'Filter <function1>.apply\n   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#1436: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1434L]\n         +- Filter <function1>.apply\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1433: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1431L]\n                  +- Filter <function1>.apply\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1430: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1428L]\n                           +- Filter <function1>.apply\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1427: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1437L]\n+- Filter <function1>.apply\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1436: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1434L]\n         +- Filter <function1>.apply\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1433: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1431L]\n                  +- Filter <function1>.apply\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1430: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1428L]\n                           +- Filter <function1>.apply\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1427: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1437L]\n+- Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1427: com.imaginea.spark.tpcds.perf.Data\n      +- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1437L]\n+- *Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)\n   +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1427: com.imaginea.spark.tpcds.perf.Data\n      +- *Range (1, 100000000, splits=4)"},{"name":"DF: back-to-back filters","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.002064,"analysisTime":0.001744,"optimizationTime":2.335341,"planningTime":0.579277,"executionTime":3799.595521,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Filter NOT (('id % 103) = 0)\n+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))\n   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))\n      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))\n         +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nFilter NOT ((id#0L % cast(103 as bigint)) = cast(0 as bigint))\n+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))\n   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))\n      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))\n         +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nFilter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))\n+- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Filter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))\n+- *Range (1, 100000000, splits=4)"},{"name":"RDD: back-to-back filters","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":3691.874064,"breakDown":[]},{"name":"DS: back-to-back maps","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001351,"analysisTime":9.95E-4,"optimizationTime":2.608322,"planningTime":0.433589,"executionTime":3991.086123,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1499L]\n+- 'MapElements <function1>, obj#1498: com.imaginea.spark.tpcds.perf.Data\n   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#1497: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1494L]\n         +- MapElements <function1>, obj#1493: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1492: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1489L]\n                  +- MapElements <function1>, obj#1488: com.imaginea.spark.tpcds.perf.Data\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1487: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1484L]\n                           +- MapElements <function1>, obj#1483: com.imaginea.spark.tpcds.perf.Data\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1482: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1499L]\n+- MapElements <function1>, obj#1498: com.imaginea.spark.tpcds.perf.Data\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1497: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1494L]\n         +- MapElements <function1>, obj#1493: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1492: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1489L]\n                  +- MapElements <function1>, obj#1488: com.imaginea.spark.tpcds.perf.Data\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1487: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1484L]\n                           +- MapElements <function1>, obj#1483: com.imaginea.spark.tpcds.perf.Data\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1482: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1499L]\n+- MapElements <function1>, obj#1498: com.imaginea.spark.tpcds.perf.Data\n   +- MapElements <function1>, obj#1493: com.imaginea.spark.tpcds.perf.Data\n      +- MapElements <function1>, obj#1488: com.imaginea.spark.tpcds.perf.Data\n         +- MapElements <function1>, obj#1483: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1482: com.imaginea.spark.tpcds.perf.Data\n               +- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1499L]\n+- *MapElements <function1>, obj#1498: com.imaginea.spark.tpcds.perf.Data\n   +- *MapElements <function1>, obj#1493: com.imaginea.spark.tpcds.perf.Data\n      +- *MapElements <function1>, obj#1488: com.imaginea.spark.tpcds.perf.Data\n         +- *MapElements <function1>, obj#1483: com.imaginea.spark.tpcds.perf.Data\n            +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1482: com.imaginea.spark.tpcds.perf.Data\n               +- *Range (1, 100000000, splits=4)"},{"name":"DF: back-to-back maps","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.00147,"analysisTime":0.001007,"optimizationTime":1.101748,"planningTime":0.267508,"executionTime":3322.554858,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Project [('id + 1) AS id#1529]\n+- Project [(id#1523L + cast(1 as bigint)) AS id#1526L]\n   +- Project [(id#1520L + cast(1 as bigint)) AS id#1523L]\n      +- Project [(id#0L + cast(1 as bigint)) AS id#1520L]\n         +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nProject [(id#1526L + cast(1 as bigint)) AS id#1529L]\n+- Project [(id#1523L + cast(1 as bigint)) AS id#1526L]\n   +- Project [(id#1520L + cast(1 as bigint)) AS id#1523L]\n      +- Project [(id#0L + cast(1 as bigint)) AS id#1520L]\n         +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nProject [((((id#0L + 1) + 1) + 1) + 1) AS id#1529L]\n+- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Project [((((id#0L + 1) + 1) + 1) + 1) AS id#1529L]\n+- *Range (1, 100000000, splits=4)"},{"name":"RDD: back-to-back maps","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":4304.405847,"breakDown":[]},{"name":"DS: average","mode":"collect","parameters":{},"joinTypes":[],"tables":[],"breakDown":[],"failure":{"className":"org.apache.spark.sql.AnalysisException","message":"cannot resolve '`sum`' given input columns: [id];"}},{"name":"DF: average","mode":"collect","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001492,"analysisTime":0.001044,"optimizationTime":0.45429,"planningTime":0.551971,"executionTime":55.973302,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Project [unresolvedalias('avg('id), Some(<function1>))]\n+- Range (1, 1000000, splits=4)\n\n== Analyzed Logical Plan ==\navg(id): double\nAggregate [avg(id#3L) AS avg(id)#1557]\n+- Range (1, 1000000, splits=4)\n\n== Optimized Logical Plan ==\nAggregate [avg(id#3L) AS avg(id)#1557]\n+- Range (1, 1000000, splits=4)\n\n== Physical Plan ==\n*TungstenAggregate(key=[], functions=[avg(id#3L)], output=[avg(id)#1557])\n+- Exchange SinglePartition, None\n   +- *TungstenAggregate(key=[], functions=[partial_avg(id#3L)], output=[sum#1561,count#1562L])\n      +- *Range (1, 1000000, splits=4)"},{"name":"RDD: average","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":43.147404,"breakDown":[]}]}
