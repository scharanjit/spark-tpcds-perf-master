{"timestamp":1464962071785,"iteration":1,"tags":{"StandardRun":"true","runtype":"local","host":"PRINHYLTPHP0415"},"configuration":{"sparkVersion":"2.0.0-SNAPSHOT","sqlConf":{"spark.tpcds.perf.results":"file:/home/charanjits/Documents/ideaProjects/finalProjectImaginea/spark-tpcds-perf-master/performance/","spark.driver.host":"172.16.54.31","spark.driver.port":"46632","spark.app.name":"com.imaginea.spark.tpcds.perf.RunBenchmark$","spark.executor.id":"driver","spark.master":"local[*]","spark.app.id":"local-1464962067724"},"sparkConf":{"spark.driver.host":"172.16.54.31","spark.driver.port":"46632","spark.app.name":"com.imaginea.spark.tpcds.perf.RunBenchmark$","spark.executor.id":"driver","spark.master":"local[*]","spark.app.id":"local-1464962067724"},"defaultParallelism":4,"buildInfo":{}},"results":[{"name":"DS: range","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.014129,"analysisTime":0.012245,"optimizationTime":0.546773,"planningTime":0.400946,"executionTime":5048.942712,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nRange (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Range (1, 100000000, splits=4)"},{"name":"DF: range","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001967,"analysisTime":0.001159,"optimizationTime":0.001723,"planningTime":0.001177,"executionTime":3695.183013,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nRange (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Range (1, 100000000, splits=4)"},{"name":"RDD: range","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":951.661768,"breakDown":[]},{"name":"DS: back-to-back filters","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001001,"analysisTime":7.5E-4,"optimizationTime":14.95811,"planningTime":1.048498,"executionTime":4538.108838,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#524L]\n+- 'Filter <function1>.apply\n   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#523: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#521L]\n         +- Filter <function1>.apply\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#520: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#518L]\n                  +- Filter <function1>.apply\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#517: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#515L]\n                           +- Filter <function1>.apply\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#514: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#524L]\n+- Filter <function1>.apply\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#523: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#521L]\n         +- Filter <function1>.apply\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#520: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#518L]\n                  +- Filter <function1>.apply\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#517: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#515L]\n                           +- Filter <function1>.apply\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#514: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#524L]\n+- Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#514: com.imaginea.spark.tpcds.perf.Data\n      +- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#524L]\n+- *Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)\n   +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#514: com.imaginea.spark.tpcds.perf.Data\n      +- *Range (1, 100000000, splits=4)"},{"name":"DF: back-to-back filters","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001293,"analysisTime":0.001083,"optimizationTime":5.190174,"planningTime":0.713802,"executionTime":3686.607045,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Filter NOT (('id % 103) = 0)\n+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))\n   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))\n      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))\n         +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nFilter NOT ((id#0L % cast(103 as bigint)) = cast(0 as bigint))\n+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))\n   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))\n      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))\n         +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nFilter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))\n+- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Filter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))\n+- *Range (1, 100000000, splits=4)"},{"name":"RDD: back-to-back filters","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":3498.05299,"breakDown":[]},{"name":"DS: back-to-back maps","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001556,"analysisTime":0.001096,"optimizationTime":5.893058,"planningTime":1.078331,"executionTime":4144.681705,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#608L]\n+- 'MapElements <function1>, obj#607: com.imaginea.spark.tpcds.perf.Data\n   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#606: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#603L]\n         +- MapElements <function1>, obj#602: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#601: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#598L]\n                  +- MapElements <function1>, obj#597: com.imaginea.spark.tpcds.perf.Data\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#596: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#593L]\n                           +- MapElements <function1>, obj#592: com.imaginea.spark.tpcds.perf.Data\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#591: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#608L]\n+- MapElements <function1>, obj#607: com.imaginea.spark.tpcds.perf.Data\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#606: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#603L]\n         +- MapElements <function1>, obj#602: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#601: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#598L]\n                  +- MapElements <function1>, obj#597: com.imaginea.spark.tpcds.perf.Data\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#596: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#593L]\n                           +- MapElements <function1>, obj#592: com.imaginea.spark.tpcds.perf.Data\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#591: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#608L]\n+- MapElements <function1>, obj#607: com.imaginea.spark.tpcds.perf.Data\n   +- MapElements <function1>, obj#602: com.imaginea.spark.tpcds.perf.Data\n      +- MapElements <function1>, obj#597: com.imaginea.spark.tpcds.perf.Data\n         +- MapElements <function1>, obj#592: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#591: com.imaginea.spark.tpcds.perf.Data\n               +- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#608L]\n+- *MapElements <function1>, obj#607: com.imaginea.spark.tpcds.perf.Data\n   +- *MapElements <function1>, obj#602: com.imaginea.spark.tpcds.perf.Data\n      +- *MapElements <function1>, obj#597: com.imaginea.spark.tpcds.perf.Data\n         +- *MapElements <function1>, obj#592: com.imaginea.spark.tpcds.perf.Data\n            +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#591: com.imaginea.spark.tpcds.perf.Data\n               +- *Range (1, 100000000, splits=4)"},{"name":"DF: back-to-back maps","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.00188,"analysisTime":0.001021,"optimizationTime":2.129328,"planningTime":0.590751,"executionTime":3748.871661,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Project [('id + 1) AS id#662]\n+- Project [(id#656L + cast(1 as bigint)) AS id#659L]\n   +- Project [(id#653L + cast(1 as bigint)) AS id#656L]\n      +- Project [(id#0L + cast(1 as bigint)) AS id#653L]\n         +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nProject [(id#659L + cast(1 as bigint)) AS id#662L]\n+- Project [(id#656L + cast(1 as bigint)) AS id#659L]\n   +- Project [(id#653L + cast(1 as bigint)) AS id#656L]\n      +- Project [(id#0L + cast(1 as bigint)) AS id#653L]\n         +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nProject [((((id#0L + 1) + 1) + 1) + 1) AS id#662L]\n+- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Project [((((id#0L + 1) + 1) + 1) + 1) AS id#662L]\n+- *Range (1, 100000000, splits=4)"},{"name":"RDD: back-to-back maps","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":4014.472308,"breakDown":[]},{"name":"DS: average","mode":"collect","parameters":{},"joinTypes":[],"tables":[],"breakDown":[],"failure":{"className":"org.apache.spark.sql.AnalysisException","message":"cannot resolve '`sum`' given input columns: [id];"}},{"name":"DF: average","mode":"collect","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001815,"analysisTime":0.00105,"optimizationTime":0.782189,"planningTime":1.273991,"executionTime":300.049452,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Project [unresolvedalias('avg('id), Some(<function1>))]\n+- Range (1, 1000000, splits=4)\n\n== Analyzed Logical Plan ==\navg(id): double\nAggregate [avg(id#3L) AS avg(id)#704]\n+- Range (1, 1000000, splits=4)\n\n== Optimized Logical Plan ==\nAggregate [avg(id#3L) AS avg(id)#704]\n+- Range (1, 1000000, splits=4)\n\n== Physical Plan ==\n*TungstenAggregate(key=[], functions=[avg(id#3L)], output=[avg(id)#704])\n+- Exchange SinglePartition, None\n   +- *TungstenAggregate(key=[], functions=[partial_avg(id#3L)], output=[sum#708,count#709L])\n      +- *Range (1, 1000000, splits=4)"},{"name":"RDD: average","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":132.999014,"breakDown":[]},{"name":"DS: range","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001622,"analysisTime":0.001224,"optimizationTime":0.495841,"planningTime":0.345755,"executionTime":3375.546962,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nRange (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Range (1, 100000000, splits=4)"},{"name":"DF: range","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001105,"analysisTime":7.48E-4,"optimizationTime":0.001645,"planningTime":9.58E-4,"executionTime":3246.28807,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nRange (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Range (1, 100000000, splits=4)"},{"name":"RDD: range","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":997.397253,"breakDown":[]},{"name":"DS: back-to-back filters","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001702,"analysisTime":0.001166,"optimizationTime":10.523646,"planningTime":0.558201,"executionTime":4116.691035,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#761L]\n+- 'Filter <function1>.apply\n   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#760: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#758L]\n         +- Filter <function1>.apply\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#757: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#755L]\n                  +- Filter <function1>.apply\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#754: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#752L]\n                           +- Filter <function1>.apply\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#751: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#761L]\n+- Filter <function1>.apply\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#760: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#758L]\n         +- Filter <function1>.apply\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#757: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#755L]\n                  +- Filter <function1>.apply\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#754: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#752L]\n                           +- Filter <function1>.apply\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#751: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#761L]\n+- Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#751: com.imaginea.spark.tpcds.perf.Data\n      +- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#761L]\n+- *Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)\n   +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#751: com.imaginea.spark.tpcds.perf.Data\n      +- *Range (1, 100000000, splits=4)"},{"name":"DF: back-to-back filters","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001474,"analysisTime":0.001203,"optimizationTime":5.173243,"planningTime":0.750289,"executionTime":3795.213506,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Filter NOT (('id % 103) = 0)\n+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))\n   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))\n      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))\n         +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nFilter NOT ((id#0L % cast(103 as bigint)) = cast(0 as bigint))\n+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))\n   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))\n      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))\n         +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nFilter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))\n+- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Filter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))\n+- *Range (1, 100000000, splits=4)"},{"name":"RDD: back-to-back filters","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":3014.820464,"breakDown":[]},{"name":"DS: back-to-back maps","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001578,"analysisTime":0.001225,"optimizationTime":3.485452,"planningTime":0.811568,"executionTime":4070.440995,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#823L]\n+- 'MapElements <function1>, obj#822: com.imaginea.spark.tpcds.perf.Data\n   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#821: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#818L]\n         +- MapElements <function1>, obj#817: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#816: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#813L]\n                  +- MapElements <function1>, obj#812: com.imaginea.spark.tpcds.perf.Data\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#811: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#808L]\n                           +- MapElements <function1>, obj#807: com.imaginea.spark.tpcds.perf.Data\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#806: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#823L]\n+- MapElements <function1>, obj#822: com.imaginea.spark.tpcds.perf.Data\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#821: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#818L]\n         +- MapElements <function1>, obj#817: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#816: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#813L]\n                  +- MapElements <function1>, obj#812: com.imaginea.spark.tpcds.perf.Data\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#811: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#808L]\n                           +- MapElements <function1>, obj#807: com.imaginea.spark.tpcds.perf.Data\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#806: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#823L]\n+- MapElements <function1>, obj#822: com.imaginea.spark.tpcds.perf.Data\n   +- MapElements <function1>, obj#817: com.imaginea.spark.tpcds.perf.Data\n      +- MapElements <function1>, obj#812: com.imaginea.spark.tpcds.perf.Data\n         +- MapElements <function1>, obj#807: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#806: com.imaginea.spark.tpcds.perf.Data\n               +- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#823L]\n+- *MapElements <function1>, obj#822: com.imaginea.spark.tpcds.perf.Data\n   +- *MapElements <function1>, obj#817: com.imaginea.spark.tpcds.perf.Data\n      +- *MapElements <function1>, obj#812: com.imaginea.spark.tpcds.perf.Data\n         +- *MapElements <function1>, obj#807: com.imaginea.spark.tpcds.perf.Data\n            +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#806: com.imaginea.spark.tpcds.perf.Data\n               +- *Range (1, 100000000, splits=4)"},{"name":"DF: back-to-back maps","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.00131,"analysisTime":7.49E-4,"optimizationTime":1.345366,"planningTime":0.498522,"executionTime":3723.791755,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Project [('id + 1) AS id#853]\n+- Project [(id#847L + cast(1 as bigint)) AS id#850L]\n   +- Project [(id#844L + cast(1 as bigint)) AS id#847L]\n      +- Project [(id#0L + cast(1 as bigint)) AS id#844L]\n         +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nProject [(id#850L + cast(1 as bigint)) AS id#853L]\n+- Project [(id#847L + cast(1 as bigint)) AS id#850L]\n   +- Project [(id#844L + cast(1 as bigint)) AS id#847L]\n      +- Project [(id#0L + cast(1 as bigint)) AS id#844L]\n         +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nProject [((((id#0L + 1) + 1) + 1) + 1) AS id#853L]\n+- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Project [((((id#0L + 1) + 1) + 1) + 1) AS id#853L]\n+- *Range (1, 100000000, splits=4)"},{"name":"RDD: back-to-back maps","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":3946.656257,"breakDown":[]},{"name":"DS: average","mode":"collect","parameters":{},"joinTypes":[],"tables":[],"breakDown":[],"failure":{"className":"org.apache.spark.sql.AnalysisException","message":"cannot resolve '`sum`' given input columns: [id];"}},{"name":"DF: average","mode":"collect","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001262,"analysisTime":0.001208,"optimizationTime":1.014034,"planningTime":1.023602,"executionTime":69.653116,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Project [unresolvedalias('avg('id), Some(<function1>))]\n+- Range (1, 1000000, splits=4)\n\n== Analyzed Logical Plan ==\navg(id): double\nAggregate [avg(id#3L) AS avg(id)#881]\n+- Range (1, 1000000, splits=4)\n\n== Optimized Logical Plan ==\nAggregate [avg(id#3L) AS avg(id)#881]\n+- Range (1, 1000000, splits=4)\n\n== Physical Plan ==\n*TungstenAggregate(key=[], functions=[avg(id#3L)], output=[avg(id)#881])\n+- Exchange SinglePartition, None\n   +- *TungstenAggregate(key=[], functions=[partial_avg(id#3L)], output=[sum#885,count#886L])\n      +- *Range (1, 1000000, splits=4)"},{"name":"RDD: average","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":55.875228,"breakDown":[]}]}
{"timestamp":1464962071785,"iteration":2,"tags":{"StandardRun":"true","runtype":"local","host":"PRINHYLTPHP0415"},"configuration":{"sparkVersion":"2.0.0-SNAPSHOT","sqlConf":{"spark.tpcds.perf.results":"file:/home/charanjits/Documents/ideaProjects/finalProjectImaginea/spark-tpcds-perf-master/performance/","spark.driver.host":"172.16.54.31","spark.driver.port":"46632","spark.app.name":"com.imaginea.spark.tpcds.perf.RunBenchmark$","spark.executor.id":"driver","spark.master":"local[*]","spark.app.id":"local-1464962067724"},"sparkConf":{"spark.driver.host":"172.16.54.31","spark.driver.port":"46632","spark.app.name":"com.imaginea.spark.tpcds.perf.RunBenchmark$","spark.executor.id":"driver","spark.master":"local[*]","spark.app.id":"local-1464962067724"},"defaultParallelism":4,"buildInfo":{}},"results":[{"name":"DS: range","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001745,"analysisTime":0.001101,"optimizationTime":0.490746,"planningTime":0.265168,"executionTime":3476.223182,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nRange (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Range (1, 100000000, splits=4)"},{"name":"DF: range","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001827,"analysisTime":0.001036,"optimizationTime":0.001759,"planningTime":0.001136,"executionTime":3311.700362,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nRange (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Range (1, 100000000, splits=4)"},{"name":"RDD: range","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":1000.859868,"breakDown":[]},{"name":"DS: back-to-back filters","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001741,"analysisTime":0.001076,"optimizationTime":10.885772,"planningTime":0.812619,"executionTime":4156.227072,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#930L]\n+- 'Filter <function1>.apply\n   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#929: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#927L]\n         +- Filter <function1>.apply\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#926: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#924L]\n                  +- Filter <function1>.apply\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#923: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#921L]\n                           +- Filter <function1>.apply\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#920: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#930L]\n+- Filter <function1>.apply\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#929: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#927L]\n         +- Filter <function1>.apply\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#926: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#924L]\n                  +- Filter <function1>.apply\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#923: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#921L]\n                           +- Filter <function1>.apply\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#920: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#930L]\n+- Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#920: com.imaginea.spark.tpcds.perf.Data\n      +- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#930L]\n+- *Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)\n   +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#920: com.imaginea.spark.tpcds.perf.Data\n      +- *Range (1, 100000000, splits=4)"},{"name":"DF: back-to-back filters","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001575,"analysisTime":0.00121,"optimizationTime":4.228066,"planningTime":0.607969,"executionTime":3781.553335,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Filter NOT (('id % 103) = 0)\n+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))\n   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))\n      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))\n         +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nFilter NOT ((id#0L % cast(103 as bigint)) = cast(0 as bigint))\n+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))\n   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))\n      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))\n         +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nFilter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))\n+- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Filter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))\n+- *Range (1, 100000000, splits=4)"},{"name":"RDD: back-to-back filters","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":3218.950572,"breakDown":[]},{"name":"DS: back-to-back maps","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001241,"analysisTime":0.001181,"optimizationTime":4.206165,"planningTime":0.703825,"executionTime":4124.618808,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#992L]\n+- 'MapElements <function1>, obj#991: com.imaginea.spark.tpcds.perf.Data\n   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#990: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#987L]\n         +- MapElements <function1>, obj#986: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#985: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#982L]\n                  +- MapElements <function1>, obj#981: com.imaginea.spark.tpcds.perf.Data\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#980: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#977L]\n                           +- MapElements <function1>, obj#976: com.imaginea.spark.tpcds.perf.Data\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#975: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#992L]\n+- MapElements <function1>, obj#991: com.imaginea.spark.tpcds.perf.Data\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#990: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#987L]\n         +- MapElements <function1>, obj#986: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#985: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#982L]\n                  +- MapElements <function1>, obj#981: com.imaginea.spark.tpcds.perf.Data\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#980: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#977L]\n                           +- MapElements <function1>, obj#976: com.imaginea.spark.tpcds.perf.Data\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#975: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#992L]\n+- MapElements <function1>, obj#991: com.imaginea.spark.tpcds.perf.Data\n   +- MapElements <function1>, obj#986: com.imaginea.spark.tpcds.perf.Data\n      +- MapElements <function1>, obj#981: com.imaginea.spark.tpcds.perf.Data\n         +- MapElements <function1>, obj#976: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#975: com.imaginea.spark.tpcds.perf.Data\n               +- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#992L]\n+- *MapElements <function1>, obj#991: com.imaginea.spark.tpcds.perf.Data\n   +- *MapElements <function1>, obj#986: com.imaginea.spark.tpcds.perf.Data\n      +- *MapElements <function1>, obj#981: com.imaginea.spark.tpcds.perf.Data\n         +- *MapElements <function1>, obj#976: com.imaginea.spark.tpcds.perf.Data\n            +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#975: com.imaginea.spark.tpcds.perf.Data\n               +- *Range (1, 100000000, splits=4)"},{"name":"DF: back-to-back maps","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001234,"analysisTime":0.001045,"optimizationTime":1.235261,"planningTime":0.373804,"executionTime":3527.160959,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Project [('id + 1) AS id#1022]\n+- Project [(id#1016L + cast(1 as bigint)) AS id#1019L]\n   +- Project [(id#1013L + cast(1 as bigint)) AS id#1016L]\n      +- Project [(id#0L + cast(1 as bigint)) AS id#1013L]\n         +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nProject [(id#1019L + cast(1 as bigint)) AS id#1022L]\n+- Project [(id#1016L + cast(1 as bigint)) AS id#1019L]\n   +- Project [(id#1013L + cast(1 as bigint)) AS id#1016L]\n      +- Project [(id#0L + cast(1 as bigint)) AS id#1013L]\n         +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nProject [((((id#0L + 1) + 1) + 1) + 1) AS id#1022L]\n+- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Project [((((id#0L + 1) + 1) + 1) + 1) AS id#1022L]\n+- *Range (1, 100000000, splits=4)"},{"name":"RDD: back-to-back maps","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":3918.956872,"breakDown":[]},{"name":"DS: average","mode":"collect","parameters":{},"joinTypes":[],"tables":[],"breakDown":[],"failure":{"className":"org.apache.spark.sql.AnalysisException","message":"cannot resolve '`sum`' given input columns: [id];"}},{"name":"DF: average","mode":"collect","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001964,"analysisTime":9.3E-4,"optimizationTime":0.521119,"planningTime":0.757422,"executionTime":67.516031,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Project [unresolvedalias('avg('id), Some(<function1>))]\n+- Range (1, 1000000, splits=4)\n\n== Analyzed Logical Plan ==\navg(id): double\nAggregate [avg(id#3L) AS avg(id)#1050]\n+- Range (1, 1000000, splits=4)\n\n== Optimized Logical Plan ==\nAggregate [avg(id#3L) AS avg(id)#1050]\n+- Range (1, 1000000, splits=4)\n\n== Physical Plan ==\n*TungstenAggregate(key=[], functions=[avg(id#3L)], output=[avg(id)#1050])\n+- Exchange SinglePartition, None\n   +- *TungstenAggregate(key=[], functions=[partial_avg(id#3L)], output=[sum#1054,count#1055L])\n      +- *Range (1, 1000000, splits=4)"},{"name":"RDD: average","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":56.892485,"breakDown":[]},{"name":"DS: range","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001948,"analysisTime":0.00127,"optimizationTime":1.21312,"planningTime":0.226926,"executionTime":3363.726977,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nRange (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Range (1, 100000000, splits=4)"},{"name":"DF: range","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001833,"analysisTime":0.001057,"optimizationTime":0.002237,"planningTime":0.001758,"executionTime":3275.388064,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nRange (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Range (1, 100000000, splits=4)"},{"name":"RDD: range","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":1012.293453,"breakDown":[]},{"name":"DS: back-to-back filters","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001528,"analysisTime":7.02E-4,"optimizationTime":10.214956,"planningTime":0.675822,"executionTime":4149.758294,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1099L]\n+- 'Filter <function1>.apply\n   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#1098: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1096L]\n         +- Filter <function1>.apply\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1095: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1093L]\n                  +- Filter <function1>.apply\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1092: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1090L]\n                           +- Filter <function1>.apply\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1089: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1099L]\n+- Filter <function1>.apply\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1098: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1096L]\n         +- Filter <function1>.apply\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1095: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1093L]\n                  +- Filter <function1>.apply\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1092: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1090L]\n                           +- Filter <function1>.apply\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1089: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1099L]\n+- Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1089: com.imaginea.spark.tpcds.perf.Data\n      +- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1099L]\n+- *Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)\n   +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1089: com.imaginea.spark.tpcds.perf.Data\n      +- *Range (1, 100000000, splits=4)"},{"name":"DF: back-to-back filters","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001018,"analysisTime":7.11E-4,"optimizationTime":3.755159,"planningTime":0.779536,"executionTime":3739.502987,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Filter NOT (('id % 103) = 0)\n+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))\n   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))\n      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))\n         +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nFilter NOT ((id#0L % cast(103 as bigint)) = cast(0 as bigint))\n+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))\n   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))\n      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))\n         +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nFilter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))\n+- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Filter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))\n+- *Range (1, 100000000, splits=4)"},{"name":"RDD: back-to-back filters","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":2936.707046,"breakDown":[]},{"name":"DS: back-to-back maps","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001216,"analysisTime":0.001083,"optimizationTime":2.594106,"planningTime":0.46063,"executionTime":3852.329515,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1161L]\n+- 'MapElements <function1>, obj#1160: com.imaginea.spark.tpcds.perf.Data\n   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#1159: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1156L]\n         +- MapElements <function1>, obj#1155: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1154: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1151L]\n                  +- MapElements <function1>, obj#1150: com.imaginea.spark.tpcds.perf.Data\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1149: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1146L]\n                           +- MapElements <function1>, obj#1145: com.imaginea.spark.tpcds.perf.Data\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1144: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1161L]\n+- MapElements <function1>, obj#1160: com.imaginea.spark.tpcds.perf.Data\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1159: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1156L]\n         +- MapElements <function1>, obj#1155: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1154: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1151L]\n                  +- MapElements <function1>, obj#1150: com.imaginea.spark.tpcds.perf.Data\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1149: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1146L]\n                           +- MapElements <function1>, obj#1145: com.imaginea.spark.tpcds.perf.Data\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1144: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1161L]\n+- MapElements <function1>, obj#1160: com.imaginea.spark.tpcds.perf.Data\n   +- MapElements <function1>, obj#1155: com.imaginea.spark.tpcds.perf.Data\n      +- MapElements <function1>, obj#1150: com.imaginea.spark.tpcds.perf.Data\n         +- MapElements <function1>, obj#1145: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1144: com.imaginea.spark.tpcds.perf.Data\n               +- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1161L]\n+- *MapElements <function1>, obj#1160: com.imaginea.spark.tpcds.perf.Data\n   +- *MapElements <function1>, obj#1155: com.imaginea.spark.tpcds.perf.Data\n      +- *MapElements <function1>, obj#1150: com.imaginea.spark.tpcds.perf.Data\n         +- *MapElements <function1>, obj#1145: com.imaginea.spark.tpcds.perf.Data\n            +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1144: com.imaginea.spark.tpcds.perf.Data\n               +- *Range (1, 100000000, splits=4)"},{"name":"DF: back-to-back maps","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.002632,"analysisTime":0.001938,"optimizationTime":1.754452,"planningTime":0.376747,"executionTime":3449.114172,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Project [('id + 1) AS id#1191]\n+- Project [(id#1185L + cast(1 as bigint)) AS id#1188L]\n   +- Project [(id#1182L + cast(1 as bigint)) AS id#1185L]\n      +- Project [(id#0L + cast(1 as bigint)) AS id#1182L]\n         +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nProject [(id#1188L + cast(1 as bigint)) AS id#1191L]\n+- Project [(id#1185L + cast(1 as bigint)) AS id#1188L]\n   +- Project [(id#1182L + cast(1 as bigint)) AS id#1185L]\n      +- Project [(id#0L + cast(1 as bigint)) AS id#1182L]\n         +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nProject [((((id#0L + 1) + 1) + 1) + 1) AS id#1191L]\n+- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Project [((((id#0L + 1) + 1) + 1) + 1) AS id#1191L]\n+- *Range (1, 100000000, splits=4)"},{"name":"RDD: back-to-back maps","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":3917.437294,"breakDown":[]},{"name":"DS: average","mode":"collect","parameters":{},"joinTypes":[],"tables":[],"breakDown":[],"failure":{"className":"org.apache.spark.sql.AnalysisException","message":"cannot resolve '`sum`' given input columns: [id];"}},{"name":"DF: average","mode":"collect","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001798,"analysisTime":0.001229,"optimizationTime":0.72095,"planningTime":1.152549,"executionTime":83.711101,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Project [unresolvedalias('avg('id), Some(<function1>))]\n+- Range (1, 1000000, splits=4)\n\n== Analyzed Logical Plan ==\navg(id): double\nAggregate [avg(id#3L) AS avg(id)#1219]\n+- Range (1, 1000000, splits=4)\n\n== Optimized Logical Plan ==\nAggregate [avg(id#3L) AS avg(id)#1219]\n+- Range (1, 1000000, splits=4)\n\n== Physical Plan ==\n*TungstenAggregate(key=[], functions=[avg(id#3L)], output=[avg(id)#1219])\n+- Exchange SinglePartition, None\n   +- *TungstenAggregate(key=[], functions=[partial_avg(id#3L)], output=[sum#1223,count#1224L])\n      +- *Range (1, 1000000, splits=4)"},{"name":"RDD: average","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":45.154169,"breakDown":[]}]}
{"timestamp":1464962071785,"iteration":3,"tags":{"StandardRun":"true","runtype":"local","host":"PRINHYLTPHP0415"},"configuration":{"sparkVersion":"2.0.0-SNAPSHOT","sqlConf":{"spark.tpcds.perf.results":"file:/home/charanjits/Documents/ideaProjects/finalProjectImaginea/spark-tpcds-perf-master/performance/","spark.driver.host":"172.16.54.31","spark.driver.port":"46632","spark.app.name":"com.imaginea.spark.tpcds.perf.RunBenchmark$","spark.executor.id":"driver","spark.master":"local[*]","spark.app.id":"local-1464962067724"},"sparkConf":{"spark.driver.host":"172.16.54.31","spark.driver.port":"46632","spark.app.name":"com.imaginea.spark.tpcds.perf.RunBenchmark$","spark.executor.id":"driver","spark.master":"local[*]","spark.app.id":"local-1464962067724"},"defaultParallelism":4,"buildInfo":{}},"results":[{"name":"DS: range","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.002798,"analysisTime":0.001071,"optimizationTime":0.411693,"planningTime":0.27751,"executionTime":3510.742881,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nRange (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Range (1, 100000000, splits=4)"},{"name":"DF: range","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001271,"analysisTime":7.02E-4,"optimizationTime":0.001789,"planningTime":0.001244,"executionTime":3540.196388,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nRange (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Range (1, 100000000, splits=4)"},{"name":"RDD: range","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":996.431382,"breakDown":[]},{"name":"DS: back-to-back filters","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001095,"analysisTime":7.2E-4,"optimizationTime":5.850874,"planningTime":0.40424,"executionTime":4089.43517,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1268L]\n+- 'Filter <function1>.apply\n   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#1267: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1265L]\n         +- Filter <function1>.apply\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1264: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1262L]\n                  +- Filter <function1>.apply\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1261: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1259L]\n                           +- Filter <function1>.apply\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1258: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1268L]\n+- Filter <function1>.apply\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1267: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1265L]\n         +- Filter <function1>.apply\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1264: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1262L]\n                  +- Filter <function1>.apply\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1261: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1259L]\n                           +- Filter <function1>.apply\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1258: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1268L]\n+- Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1258: com.imaginea.spark.tpcds.perf.Data\n      +- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1268L]\n+- *Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)\n   +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1258: com.imaginea.spark.tpcds.perf.Data\n      +- *Range (1, 100000000, splits=4)"},{"name":"DF: back-to-back filters","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.002195,"analysisTime":0.001453,"optimizationTime":6.149964,"planningTime":0.759972,"executionTime":3697.894074,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Filter NOT (('id % 103) = 0)\n+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))\n   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))\n      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))\n         +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nFilter NOT ((id#0L % cast(103 as bigint)) = cast(0 as bigint))\n+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))\n   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))\n      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))\n         +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nFilter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))\n+- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Filter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))\n+- *Range (1, 100000000, splits=4)"},{"name":"RDD: back-to-back filters","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":2949.203118,"breakDown":[]},{"name":"DS: back-to-back maps","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001325,"analysisTime":7.96E-4,"optimizationTime":2.438214,"planningTime":0.46057,"executionTime":3912.102596,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1330L]\n+- 'MapElements <function1>, obj#1329: com.imaginea.spark.tpcds.perf.Data\n   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#1328: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1325L]\n         +- MapElements <function1>, obj#1324: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1323: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1320L]\n                  +- MapElements <function1>, obj#1319: com.imaginea.spark.tpcds.perf.Data\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1318: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1315L]\n                           +- MapElements <function1>, obj#1314: com.imaginea.spark.tpcds.perf.Data\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1313: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1330L]\n+- MapElements <function1>, obj#1329: com.imaginea.spark.tpcds.perf.Data\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1328: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1325L]\n         +- MapElements <function1>, obj#1324: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1323: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1320L]\n                  +- MapElements <function1>, obj#1319: com.imaginea.spark.tpcds.perf.Data\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1318: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1315L]\n                           +- MapElements <function1>, obj#1314: com.imaginea.spark.tpcds.perf.Data\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1313: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1330L]\n+- MapElements <function1>, obj#1329: com.imaginea.spark.tpcds.perf.Data\n   +- MapElements <function1>, obj#1324: com.imaginea.spark.tpcds.perf.Data\n      +- MapElements <function1>, obj#1319: com.imaginea.spark.tpcds.perf.Data\n         +- MapElements <function1>, obj#1314: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1313: com.imaginea.spark.tpcds.perf.Data\n               +- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1330L]\n+- *MapElements <function1>, obj#1329: com.imaginea.spark.tpcds.perf.Data\n   +- *MapElements <function1>, obj#1324: com.imaginea.spark.tpcds.perf.Data\n      +- *MapElements <function1>, obj#1319: com.imaginea.spark.tpcds.perf.Data\n         +- *MapElements <function1>, obj#1314: com.imaginea.spark.tpcds.perf.Data\n            +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1313: com.imaginea.spark.tpcds.perf.Data\n               +- *Range (1, 100000000, splits=4)"},{"name":"DF: back-to-back maps","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001322,"analysisTime":0.001249,"optimizationTime":1.045766,"planningTime":0.308443,"executionTime":3488.318927,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Project [('id + 1) AS id#1360]\n+- Project [(id#1354L + cast(1 as bigint)) AS id#1357L]\n   +- Project [(id#1351L + cast(1 as bigint)) AS id#1354L]\n      +- Project [(id#0L + cast(1 as bigint)) AS id#1351L]\n         +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nProject [(id#1357L + cast(1 as bigint)) AS id#1360L]\n+- Project [(id#1354L + cast(1 as bigint)) AS id#1357L]\n   +- Project [(id#1351L + cast(1 as bigint)) AS id#1354L]\n      +- Project [(id#0L + cast(1 as bigint)) AS id#1351L]\n         +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nProject [((((id#0L + 1) + 1) + 1) + 1) AS id#1360L]\n+- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Project [((((id#0L + 1) + 1) + 1) + 1) AS id#1360L]\n+- *Range (1, 100000000, splits=4)"},{"name":"RDD: back-to-back maps","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":3905.176916,"breakDown":[]},{"name":"DS: average","mode":"collect","parameters":{},"joinTypes":[],"tables":[],"breakDown":[],"failure":{"className":"org.apache.spark.sql.AnalysisException","message":"cannot resolve '`sum`' given input columns: [id];"}},{"name":"DF: average","mode":"collect","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001432,"analysisTime":7.72E-4,"optimizationTime":0.706012,"planningTime":1.620692,"executionTime":64.448496,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Project [unresolvedalias('avg('id), Some(<function1>))]\n+- Range (1, 1000000, splits=4)\n\n== Analyzed Logical Plan ==\navg(id): double\nAggregate [avg(id#3L) AS avg(id)#1388]\n+- Range (1, 1000000, splits=4)\n\n== Optimized Logical Plan ==\nAggregate [avg(id#3L) AS avg(id)#1388]\n+- Range (1, 1000000, splits=4)\n\n== Physical Plan ==\n*TungstenAggregate(key=[], functions=[avg(id#3L)], output=[avg(id)#1388])\n+- Exchange SinglePartition, None\n   +- *TungstenAggregate(key=[], functions=[partial_avg(id#3L)], output=[sum#1392,count#1393L])\n      +- *Range (1, 1000000, splits=4)"},{"name":"RDD: average","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":55.255607,"breakDown":[]},{"name":"DS: range","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001621,"analysisTime":9.35E-4,"optimizationTime":0.41647,"planningTime":0.142867,"executionTime":3434.064762,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nRange (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Range (1, 100000000, splits=4)"},{"name":"DF: range","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001086,"analysisTime":0.001361,"optimizationTime":0.001208,"planningTime":9.89E-4,"executionTime":3258.881293,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nRange (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Range (1, 100000000, splits=4)"},{"name":"RDD: range","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":994.375937,"breakDown":[]},{"name":"DS: back-to-back filters","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001417,"analysisTime":9.95E-4,"optimizationTime":6.909832,"planningTime":0.472778,"executionTime":4217.723622,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1437L]\n+- 'Filter <function1>.apply\n   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#1436: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1434L]\n         +- Filter <function1>.apply\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1433: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1431L]\n                  +- Filter <function1>.apply\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1430: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1428L]\n                           +- Filter <function1>.apply\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1427: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1437L]\n+- Filter <function1>.apply\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1436: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1434L]\n         +- Filter <function1>.apply\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1433: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1431L]\n                  +- Filter <function1>.apply\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1430: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1428L]\n                           +- Filter <function1>.apply\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1427: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1437L]\n+- Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1427: com.imaginea.spark.tpcds.perf.Data\n      +- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1437L]\n+- *Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)\n   +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1427: com.imaginea.spark.tpcds.perf.Data\n      +- *Range (1, 100000000, splits=4)"},{"name":"DF: back-to-back filters","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001377,"analysisTime":8.27E-4,"optimizationTime":2.393858,"planningTime":0.578567,"executionTime":3922.694451,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Filter NOT (('id % 103) = 0)\n+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))\n   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))\n      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))\n         +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nFilter NOT ((id#0L % cast(103 as bigint)) = cast(0 as bigint))\n+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))\n   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))\n      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))\n         +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nFilter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))\n+- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Filter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))\n+- *Range (1, 100000000, splits=4)"},{"name":"RDD: back-to-back filters","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":2927.85328,"breakDown":[]},{"name":"DS: back-to-back maps","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001774,"analysisTime":7.9E-4,"optimizationTime":2.497402,"planningTime":0.620584,"executionTime":3902.70888,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1499L]\n+- 'MapElements <function1>, obj#1498: com.imaginea.spark.tpcds.perf.Data\n   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#1497: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1494L]\n         +- MapElements <function1>, obj#1493: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1492: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1489L]\n                  +- MapElements <function1>, obj#1488: com.imaginea.spark.tpcds.perf.Data\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1487: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1484L]\n                           +- MapElements <function1>, obj#1483: com.imaginea.spark.tpcds.perf.Data\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1482: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1499L]\n+- MapElements <function1>, obj#1498: com.imaginea.spark.tpcds.perf.Data\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1497: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1494L]\n         +- MapElements <function1>, obj#1493: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1492: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1489L]\n                  +- MapElements <function1>, obj#1488: com.imaginea.spark.tpcds.perf.Data\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1487: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1484L]\n                           +- MapElements <function1>, obj#1483: com.imaginea.spark.tpcds.perf.Data\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1482: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1499L]\n+- MapElements <function1>, obj#1498: com.imaginea.spark.tpcds.perf.Data\n   +- MapElements <function1>, obj#1493: com.imaginea.spark.tpcds.perf.Data\n      +- MapElements <function1>, obj#1488: com.imaginea.spark.tpcds.perf.Data\n         +- MapElements <function1>, obj#1483: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1482: com.imaginea.spark.tpcds.perf.Data\n               +- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1499L]\n+- *MapElements <function1>, obj#1498: com.imaginea.spark.tpcds.perf.Data\n   +- *MapElements <function1>, obj#1493: com.imaginea.spark.tpcds.perf.Data\n      +- *MapElements <function1>, obj#1488: com.imaginea.spark.tpcds.perf.Data\n         +- *MapElements <function1>, obj#1483: com.imaginea.spark.tpcds.perf.Data\n            +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1482: com.imaginea.spark.tpcds.perf.Data\n               +- *Range (1, 100000000, splits=4)"},{"name":"DF: back-to-back maps","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001232,"analysisTime":8.09E-4,"optimizationTime":1.009829,"planningTime":0.340407,"executionTime":3401.704074,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Project [('id + 1) AS id#1529]\n+- Project [(id#1523L + cast(1 as bigint)) AS id#1526L]\n   +- Project [(id#1520L + cast(1 as bigint)) AS id#1523L]\n      +- Project [(id#0L + cast(1 as bigint)) AS id#1520L]\n         +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nProject [(id#1526L + cast(1 as bigint)) AS id#1529L]\n+- Project [(id#1523L + cast(1 as bigint)) AS id#1526L]\n   +- Project [(id#1520L + cast(1 as bigint)) AS id#1523L]\n      +- Project [(id#0L + cast(1 as bigint)) AS id#1520L]\n         +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nProject [((((id#0L + 1) + 1) + 1) + 1) AS id#1529L]\n+- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Project [((((id#0L + 1) + 1) + 1) + 1) AS id#1529L]\n+- *Range (1, 100000000, splits=4)"},{"name":"RDD: back-to-back maps","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":3929.213143,"breakDown":[]},{"name":"DS: average","mode":"collect","parameters":{},"joinTypes":[],"tables":[],"breakDown":[],"failure":{"className":"org.apache.spark.sql.AnalysisException","message":"cannot resolve '`sum`' given input columns: [id];"}},{"name":"DF: average","mode":"collect","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001386,"analysisTime":6.89E-4,"optimizationTime":0.470607,"planningTime":0.615339,"executionTime":46.11831,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Project [unresolvedalias('avg('id), Some(<function1>))]\n+- Range (1, 1000000, splits=4)\n\n== Analyzed Logical Plan ==\navg(id): double\nAggregate [avg(id#3L) AS avg(id)#1557]\n+- Range (1, 1000000, splits=4)\n\n== Optimized Logical Plan ==\nAggregate [avg(id#3L) AS avg(id)#1557]\n+- Range (1, 1000000, splits=4)\n\n== Physical Plan ==\n*TungstenAggregate(key=[], functions=[avg(id#3L)], output=[avg(id)#1557])\n+- Exchange SinglePartition, None\n   +- *TungstenAggregate(key=[], functions=[partial_avg(id#3L)], output=[sum#1561,count#1562L])\n      +- *Range (1, 1000000, splits=4)"},{"name":"RDD: average","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":59.317596,"breakDown":[]}]}
