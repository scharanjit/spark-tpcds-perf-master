{"timestamp":1465280756151,"iteration":1,"tags":{"StandardRun":"true","runtype":"local","host":"PRINHYLTPHP0415"},"configuration":{"sparkVersion":"2.0.0-SNAPSHOT","sqlConf":{"spark.tpcds.perf.results":"file:/home/charanjits/Documents/ideaProjects/finalProjectImaginea/spark-tpcds-perf-master/performance/","spark.driver.host":"172.16.54.31","spark.driver.port":"34796","spark.app.name":"com.imaginea.spark.tpcds.perf.RunBenchmark$","spark.executor.id":"driver","spark.master":"local[*]","spark.app.id":"local-1465280752198"},"sparkConf":{"spark.driver.host":"172.16.54.31","spark.driver.port":"34796","spark.app.name":"com.imaginea.spark.tpcds.perf.RunBenchmark$","spark.executor.id":"driver","spark.master":"local[*]","spark.app.id":"local-1465280752198"},"defaultParallelism":4,"buildInfo":{}},"results":[{"name":"DS: range","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.010417,"analysisTime":0.00456,"optimizationTime":0.468415,"planningTime":0.289269,"executionTime":5229.879687,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nRange (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Range (1, 100000000, splits=4)"},{"name":"DF: range","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001181,"analysisTime":0.001214,"optimizationTime":0.001198,"planningTime":0.001168,"executionTime":3440.933836,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nRange (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Range (1, 100000000, splits=4)"},{"name":"RDD: range","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":1031.137126,"breakDown":[]},{"name":"DS: back-to-back filters","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001024,"analysisTime":0.001031,"optimizationTime":15.590783,"planningTime":1.042536,"executionTime":4327.492749,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#524L]\n+- 'Filter <function1>.apply\n   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#523: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#521L]\n         +- Filter <function1>.apply\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#520: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#518L]\n                  +- Filter <function1>.apply\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#517: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#515L]\n                           +- Filter <function1>.apply\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#514: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#524L]\n+- Filter <function1>.apply\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#523: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#521L]\n         +- Filter <function1>.apply\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#520: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#518L]\n                  +- Filter <function1>.apply\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#517: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#515L]\n                           +- Filter <function1>.apply\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#514: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#524L]\n+- Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#514: com.imaginea.spark.tpcds.perf.Data\n      +- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#524L]\n+- *Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)\n   +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#514: com.imaginea.spark.tpcds.perf.Data\n      +- *Range (1, 100000000, splits=4)"},{"name":"DF: back-to-back filters","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":9.87E-4,"analysisTime":0.001353,"optimizationTime":3.571029,"planningTime":0.785422,"executionTime":3797.574166,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Filter NOT (('id % 103) = 0)\n+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))\n   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))\n      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))\n         +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nFilter NOT ((id#0L % cast(103 as bigint)) = cast(0 as bigint))\n+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))\n   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))\n      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))\n         +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nFilter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))\n+- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Filter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))\n+- *Range (1, 100000000, splits=4)"},{"name":"RDD: back-to-back filters","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":3537.510037,"breakDown":[]},{"name":"DS: back-to-back maps","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001989,"analysisTime":9.33E-4,"optimizationTime":5.527613,"planningTime":0.994521,"executionTime":4249.050358,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#608L]\n+- 'MapElements <function1>, obj#607: com.imaginea.spark.tpcds.perf.Data\n   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#606: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#603L]\n         +- MapElements <function1>, obj#602: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#601: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#598L]\n                  +- MapElements <function1>, obj#597: com.imaginea.spark.tpcds.perf.Data\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#596: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#593L]\n                           +- MapElements <function1>, obj#592: com.imaginea.spark.tpcds.perf.Data\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#591: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#608L]\n+- MapElements <function1>, obj#607: com.imaginea.spark.tpcds.perf.Data\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#606: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#603L]\n         +- MapElements <function1>, obj#602: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#601: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#598L]\n                  +- MapElements <function1>, obj#597: com.imaginea.spark.tpcds.perf.Data\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#596: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#593L]\n                           +- MapElements <function1>, obj#592: com.imaginea.spark.tpcds.perf.Data\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#591: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#608L]\n+- MapElements <function1>, obj#607: com.imaginea.spark.tpcds.perf.Data\n   +- MapElements <function1>, obj#602: com.imaginea.spark.tpcds.perf.Data\n      +- MapElements <function1>, obj#597: com.imaginea.spark.tpcds.perf.Data\n         +- MapElements <function1>, obj#592: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#591: com.imaginea.spark.tpcds.perf.Data\n               +- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#608L]\n+- *MapElements <function1>, obj#607: com.imaginea.spark.tpcds.perf.Data\n   +- *MapElements <function1>, obj#602: com.imaginea.spark.tpcds.perf.Data\n      +- *MapElements <function1>, obj#597: com.imaginea.spark.tpcds.perf.Data\n         +- *MapElements <function1>, obj#592: com.imaginea.spark.tpcds.perf.Data\n            +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#591: com.imaginea.spark.tpcds.perf.Data\n               +- *Range (1, 100000000, splits=4)"},{"name":"DF: back-to-back maps","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001166,"analysisTime":0.001432,"optimizationTime":1.384516,"planningTime":0.601794,"executionTime":3558.042641,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Project [('id + 1) AS id#662]\n+- Project [(id#656L + cast(1 as bigint)) AS id#659L]\n   +- Project [(id#653L + cast(1 as bigint)) AS id#656L]\n      +- Project [(id#0L + cast(1 as bigint)) AS id#653L]\n         +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nProject [(id#659L + cast(1 as bigint)) AS id#662L]\n+- Project [(id#656L + cast(1 as bigint)) AS id#659L]\n   +- Project [(id#653L + cast(1 as bigint)) AS id#656L]\n      +- Project [(id#0L + cast(1 as bigint)) AS id#653L]\n         +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nProject [((((id#0L + 1) + 1) + 1) + 1) AS id#662L]\n+- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Project [((((id#0L + 1) + 1) + 1) + 1) AS id#662L]\n+- *Range (1, 100000000, splits=4)"},{"name":"RDD: back-to-back maps","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":4875.631527,"breakDown":[]},{"name":"DS: average","mode":"collect","parameters":{},"joinTypes":[],"tables":[],"breakDown":[],"failure":{"className":"org.apache.spark.sql.AnalysisException","message":"cannot resolve '`sum`' given input columns: [id];"}},{"name":"DF: average","mode":"collect","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001557,"analysisTime":0.001398,"optimizationTime":0.616422,"planningTime":0.969961,"executionTime":313.363721,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Project [unresolvedalias('avg('id), Some(<function1>))]\n+- Range (1, 1000000, splits=4)\n\n== Analyzed Logical Plan ==\navg(id): double\nAggregate [avg(id#3L) AS avg(id)#704]\n+- Range (1, 1000000, splits=4)\n\n== Optimized Logical Plan ==\nAggregate [avg(id#3L) AS avg(id)#704]\n+- Range (1, 1000000, splits=4)\n\n== Physical Plan ==\n*TungstenAggregate(key=[], functions=[avg(id#3L)], output=[avg(id)#704])\n+- Exchange SinglePartition, None\n   +- *TungstenAggregate(key=[], functions=[partial_avg(id#3L)], output=[sum#708,count#709L])\n      +- *Range (1, 1000000, splits=4)"},{"name":"RDD: average","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":71.174269,"breakDown":[]},{"name":"DS: range","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001709,"analysisTime":0.001088,"optimizationTime":0.475889,"planningTime":0.286806,"executionTime":3367.217288,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nRange (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Range (1, 100000000, splits=4)"},{"name":"DF: range","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.002063,"analysisTime":9.34E-4,"optimizationTime":0.001764,"planningTime":0.001408,"executionTime":3362.132277,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nRange (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Range (1, 100000000, splits=4)"},{"name":"RDD: range","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":1315.279882,"breakDown":[]},{"name":"DS: back-to-back filters","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001164,"analysisTime":9.2E-4,"optimizationTime":12.423552,"planningTime":0.772204,"executionTime":4096.122282,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#761L]\n+- 'Filter <function1>.apply\n   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#760: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#758L]\n         +- Filter <function1>.apply\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#757: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#755L]\n                  +- Filter <function1>.apply\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#754: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#752L]\n                           +- Filter <function1>.apply\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#751: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#761L]\n+- Filter <function1>.apply\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#760: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#758L]\n         +- Filter <function1>.apply\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#757: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#755L]\n                  +- Filter <function1>.apply\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#754: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#752L]\n                           +- Filter <function1>.apply\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#751: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#761L]\n+- Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#751: com.imaginea.spark.tpcds.perf.Data\n      +- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#761L]\n+- *Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)\n   +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#751: com.imaginea.spark.tpcds.perf.Data\n      +- *Range (1, 100000000, splits=4)"},{"name":"DF: back-to-back filters","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001116,"analysisTime":8.78E-4,"optimizationTime":2.95874,"planningTime":0.411631,"executionTime":3881.591013,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Filter NOT (('id % 103) = 0)\n+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))\n   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))\n      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))\n         +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nFilter NOT ((id#0L % cast(103 as bigint)) = cast(0 as bigint))\n+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))\n   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))\n      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))\n         +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nFilter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))\n+- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Filter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))\n+- *Range (1, 100000000, splits=4)"},{"name":"RDD: back-to-back filters","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":3465.073151,"breakDown":[]},{"name":"DS: back-to-back maps","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001588,"analysisTime":0.001008,"optimizationTime":4.962243,"planningTime":0.84974,"executionTime":4211.540286,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#823L]\n+- 'MapElements <function1>, obj#822: com.imaginea.spark.tpcds.perf.Data\n   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#821: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#818L]\n         +- MapElements <function1>, obj#817: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#816: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#813L]\n                  +- MapElements <function1>, obj#812: com.imaginea.spark.tpcds.perf.Data\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#811: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#808L]\n                           +- MapElements <function1>, obj#807: com.imaginea.spark.tpcds.perf.Data\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#806: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#823L]\n+- MapElements <function1>, obj#822: com.imaginea.spark.tpcds.perf.Data\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#821: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#818L]\n         +- MapElements <function1>, obj#817: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#816: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#813L]\n                  +- MapElements <function1>, obj#812: com.imaginea.spark.tpcds.perf.Data\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#811: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#808L]\n                           +- MapElements <function1>, obj#807: com.imaginea.spark.tpcds.perf.Data\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#806: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#823L]\n+- MapElements <function1>, obj#822: com.imaginea.spark.tpcds.perf.Data\n   +- MapElements <function1>, obj#817: com.imaginea.spark.tpcds.perf.Data\n      +- MapElements <function1>, obj#812: com.imaginea.spark.tpcds.perf.Data\n         +- MapElements <function1>, obj#807: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#806: com.imaginea.spark.tpcds.perf.Data\n               +- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#823L]\n+- *MapElements <function1>, obj#822: com.imaginea.spark.tpcds.perf.Data\n   +- *MapElements <function1>, obj#817: com.imaginea.spark.tpcds.perf.Data\n      +- *MapElements <function1>, obj#812: com.imaginea.spark.tpcds.perf.Data\n         +- *MapElements <function1>, obj#807: com.imaginea.spark.tpcds.perf.Data\n            +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#806: com.imaginea.spark.tpcds.perf.Data\n               +- *Range (1, 100000000, splits=4)"},{"name":"DF: back-to-back maps","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001202,"analysisTime":0.001046,"optimizationTime":1.617734,"planningTime":0.510017,"executionTime":3636.339533,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Project [('id + 1) AS id#853]\n+- Project [(id#847L + cast(1 as bigint)) AS id#850L]\n   +- Project [(id#844L + cast(1 as bigint)) AS id#847L]\n      +- Project [(id#0L + cast(1 as bigint)) AS id#844L]\n         +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nProject [(id#850L + cast(1 as bigint)) AS id#853L]\n+- Project [(id#847L + cast(1 as bigint)) AS id#850L]\n   +- Project [(id#844L + cast(1 as bigint)) AS id#847L]\n      +- Project [(id#0L + cast(1 as bigint)) AS id#844L]\n         +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nProject [((((id#0L + 1) + 1) + 1) + 1) AS id#853L]\n+- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Project [((((id#0L + 1) + 1) + 1) + 1) AS id#853L]\n+- *Range (1, 100000000, splits=4)"},{"name":"RDD: back-to-back maps","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":4453.367508,"breakDown":[]},{"name":"DS: average","mode":"collect","parameters":{},"joinTypes":[],"tables":[],"breakDown":[],"failure":{"className":"org.apache.spark.sql.AnalysisException","message":"cannot resolve '`sum`' given input columns: [id];"}},{"name":"DF: average","mode":"collect","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001383,"analysisTime":9.51E-4,"optimizationTime":0.574697,"planningTime":0.860675,"executionTime":60.670483,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Project [unresolvedalias('avg('id), Some(<function1>))]\n+- Range (1, 1000000, splits=4)\n\n== Analyzed Logical Plan ==\navg(id): double\nAggregate [avg(id#3L) AS avg(id)#881]\n+- Range (1, 1000000, splits=4)\n\n== Optimized Logical Plan ==\nAggregate [avg(id#3L) AS avg(id)#881]\n+- Range (1, 1000000, splits=4)\n\n== Physical Plan ==\n*TungstenAggregate(key=[], functions=[avg(id#3L)], output=[avg(id)#881])\n+- Exchange SinglePartition, None\n   +- *TungstenAggregate(key=[], functions=[partial_avg(id#3L)], output=[sum#885,count#886L])\n      +- *Range (1, 1000000, splits=4)"},{"name":"RDD: average","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":49.769628,"breakDown":[]}]}
{"timestamp":1465280756151,"iteration":2,"tags":{"StandardRun":"true","runtype":"local","host":"PRINHYLTPHP0415"},"configuration":{"sparkVersion":"2.0.0-SNAPSHOT","sqlConf":{"spark.tpcds.perf.results":"file:/home/charanjits/Documents/ideaProjects/finalProjectImaginea/spark-tpcds-perf-master/performance/","spark.driver.host":"172.16.54.31","spark.driver.port":"34796","spark.app.name":"com.imaginea.spark.tpcds.perf.RunBenchmark$","spark.executor.id":"driver","spark.master":"local[*]","spark.app.id":"local-1465280752198"},"sparkConf":{"spark.driver.host":"172.16.54.31","spark.driver.port":"34796","spark.app.name":"com.imaginea.spark.tpcds.perf.RunBenchmark$","spark.executor.id":"driver","spark.master":"local[*]","spark.app.id":"local-1465280752198"},"defaultParallelism":4,"buildInfo":{}},"results":[{"name":"DS: range","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001217,"analysisTime":8.21E-4,"optimizationTime":0.3314,"planningTime":0.197688,"executionTime":3581.832769,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nRange (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Range (1, 100000000, splits=4)"},{"name":"DF: range","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.00127,"analysisTime":0.001365,"optimizationTime":0.001285,"planningTime":0.00105,"executionTime":3437.487838,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nRange (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Range (1, 100000000, splits=4)"},{"name":"RDD: range","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":1421.512493,"breakDown":[]},{"name":"DS: back-to-back filters","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001368,"analysisTime":9.51E-4,"optimizationTime":10.534132,"planningTime":0.495916,"executionTime":3965.556483,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#930L]\n+- 'Filter <function1>.apply\n   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#929: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#927L]\n         +- Filter <function1>.apply\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#926: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#924L]\n                  +- Filter <function1>.apply\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#923: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#921L]\n                           +- Filter <function1>.apply\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#920: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#930L]\n+- Filter <function1>.apply\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#929: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#927L]\n         +- Filter <function1>.apply\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#926: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#924L]\n                  +- Filter <function1>.apply\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#923: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#921L]\n                           +- Filter <function1>.apply\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#920: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#930L]\n+- Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#920: com.imaginea.spark.tpcds.perf.Data\n      +- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#930L]\n+- *Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)\n   +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#920: com.imaginea.spark.tpcds.perf.Data\n      +- *Range (1, 100000000, splits=4)"},{"name":"DF: back-to-back filters","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001011,"analysisTime":9.43E-4,"optimizationTime":4.032375,"planningTime":0.535252,"executionTime":3890.313671,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Filter NOT (('id % 103) = 0)\n+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))\n   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))\n      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))\n         +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nFilter NOT ((id#0L % cast(103 as bigint)) = cast(0 as bigint))\n+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))\n   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))\n      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))\n         +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nFilter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))\n+- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Filter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))\n+- *Range (1, 100000000, splits=4)"},{"name":"RDD: back-to-back filters","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":3584.605211,"breakDown":[]},{"name":"DS: back-to-back maps","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.002055,"analysisTime":0.001067,"optimizationTime":2.72253,"planningTime":0.501106,"executionTime":4971.057001,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#992L]\n+- 'MapElements <function1>, obj#991: com.imaginea.spark.tpcds.perf.Data\n   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#990: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#987L]\n         +- MapElements <function1>, obj#986: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#985: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#982L]\n                  +- MapElements <function1>, obj#981: com.imaginea.spark.tpcds.perf.Data\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#980: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#977L]\n                           +- MapElements <function1>, obj#976: com.imaginea.spark.tpcds.perf.Data\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#975: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#992L]\n+- MapElements <function1>, obj#991: com.imaginea.spark.tpcds.perf.Data\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#990: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#987L]\n         +- MapElements <function1>, obj#986: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#985: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#982L]\n                  +- MapElements <function1>, obj#981: com.imaginea.spark.tpcds.perf.Data\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#980: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#977L]\n                           +- MapElements <function1>, obj#976: com.imaginea.spark.tpcds.perf.Data\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#975: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#992L]\n+- MapElements <function1>, obj#991: com.imaginea.spark.tpcds.perf.Data\n   +- MapElements <function1>, obj#986: com.imaginea.spark.tpcds.perf.Data\n      +- MapElements <function1>, obj#981: com.imaginea.spark.tpcds.perf.Data\n         +- MapElements <function1>, obj#976: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#975: com.imaginea.spark.tpcds.perf.Data\n               +- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#992L]\n+- *MapElements <function1>, obj#991: com.imaginea.spark.tpcds.perf.Data\n   +- *MapElements <function1>, obj#986: com.imaginea.spark.tpcds.perf.Data\n      +- *MapElements <function1>, obj#981: com.imaginea.spark.tpcds.perf.Data\n         +- *MapElements <function1>, obj#976: com.imaginea.spark.tpcds.perf.Data\n            +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#975: com.imaginea.spark.tpcds.perf.Data\n               +- *Range (1, 100000000, splits=4)"},{"name":"DF: back-to-back maps","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.002252,"analysisTime":9.44E-4,"optimizationTime":2.009569,"planningTime":0.518822,"executionTime":6007.096487,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Project [('id + 1) AS id#1022]\n+- Project [(id#1016L + cast(1 as bigint)) AS id#1019L]\n   +- Project [(id#1013L + cast(1 as bigint)) AS id#1016L]\n      +- Project [(id#0L + cast(1 as bigint)) AS id#1013L]\n         +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nProject [(id#1019L + cast(1 as bigint)) AS id#1022L]\n+- Project [(id#1016L + cast(1 as bigint)) AS id#1019L]\n   +- Project [(id#1013L + cast(1 as bigint)) AS id#1016L]\n      +- Project [(id#0L + cast(1 as bigint)) AS id#1013L]\n         +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nProject [((((id#0L + 1) + 1) + 1) + 1) AS id#1022L]\n+- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Project [((((id#0L + 1) + 1) + 1) + 1) AS id#1022L]\n+- *Range (1, 100000000, splits=4)"},{"name":"RDD: back-to-back maps","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":8217.015722,"breakDown":[]},{"name":"DS: average","mode":"collect","parameters":{},"joinTypes":[],"tables":[],"breakDown":[],"failure":{"className":"org.apache.spark.sql.AnalysisException","message":"cannot resolve '`sum`' given input columns: [id];"}},{"name":"DF: average","mode":"collect","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.00173,"analysisTime":0.001142,"optimizationTime":0.811954,"planningTime":0.980519,"executionTime":89.061496,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Project [unresolvedalias('avg('id), Some(<function1>))]\n+- Range (1, 1000000, splits=4)\n\n== Analyzed Logical Plan ==\navg(id): double\nAggregate [avg(id#3L) AS avg(id)#1050]\n+- Range (1, 1000000, splits=4)\n\n== Optimized Logical Plan ==\nAggregate [avg(id#3L) AS avg(id)#1050]\n+- Range (1, 1000000, splits=4)\n\n== Physical Plan ==\n*TungstenAggregate(key=[], functions=[avg(id#3L)], output=[avg(id)#1050])\n+- Exchange SinglePartition, None\n   +- *TungstenAggregate(key=[], functions=[partial_avg(id#3L)], output=[sum#1054,count#1055L])\n      +- *Range (1, 1000000, splits=4)"},{"name":"RDD: average","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":78.272362,"breakDown":[]},{"name":"DS: range","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.002068,"analysisTime":8.53E-4,"optimizationTime":0.4131,"planningTime":0.199882,"executionTime":3852.068822,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nRange (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Range (1, 100000000, splits=4)"},{"name":"DF: range","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001369,"analysisTime":8.52E-4,"optimizationTime":0.001707,"planningTime":0.00113,"executionTime":3448.614819,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nRange (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Range (1, 100000000, splits=4)"},{"name":"RDD: range","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":1322.003604,"breakDown":[]},{"name":"DS: back-to-back filters","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001246,"analysisTime":8.14E-4,"optimizationTime":7.460671,"planningTime":0.570207,"executionTime":4068.75997,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1099L]\n+- 'Filter <function1>.apply\n   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#1098: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1096L]\n         +- Filter <function1>.apply\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1095: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1093L]\n                  +- Filter <function1>.apply\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1092: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1090L]\n                           +- Filter <function1>.apply\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1089: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1099L]\n+- Filter <function1>.apply\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1098: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1096L]\n         +- Filter <function1>.apply\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1095: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1093L]\n                  +- Filter <function1>.apply\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1092: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1090L]\n                           +- Filter <function1>.apply\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1089: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1099L]\n+- Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1089: com.imaginea.spark.tpcds.perf.Data\n      +- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1099L]\n+- *Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)\n   +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1089: com.imaginea.spark.tpcds.perf.Data\n      +- *Range (1, 100000000, splits=4)"},{"name":"DF: back-to-back filters","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001776,"analysisTime":0.001374,"optimizationTime":3.732479,"planningTime":0.6066,"executionTime":3634.427352,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Filter NOT (('id % 103) = 0)\n+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))\n   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))\n      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))\n         +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nFilter NOT ((id#0L % cast(103 as bigint)) = cast(0 as bigint))\n+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))\n   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))\n      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))\n         +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nFilter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))\n+- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Filter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))\n+- *Range (1, 100000000, splits=4)"},{"name":"RDD: back-to-back filters","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":3366.564213,"breakDown":[]},{"name":"DS: back-to-back maps","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001169,"analysisTime":8.66E-4,"optimizationTime":2.580157,"planningTime":0.489985,"executionTime":3964.333224,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1161L]\n+- 'MapElements <function1>, obj#1160: com.imaginea.spark.tpcds.perf.Data\n   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#1159: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1156L]\n         +- MapElements <function1>, obj#1155: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1154: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1151L]\n                  +- MapElements <function1>, obj#1150: com.imaginea.spark.tpcds.perf.Data\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1149: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1146L]\n                           +- MapElements <function1>, obj#1145: com.imaginea.spark.tpcds.perf.Data\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1144: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1161L]\n+- MapElements <function1>, obj#1160: com.imaginea.spark.tpcds.perf.Data\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1159: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1156L]\n         +- MapElements <function1>, obj#1155: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1154: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1151L]\n                  +- MapElements <function1>, obj#1150: com.imaginea.spark.tpcds.perf.Data\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1149: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1146L]\n                           +- MapElements <function1>, obj#1145: com.imaginea.spark.tpcds.perf.Data\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1144: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1161L]\n+- MapElements <function1>, obj#1160: com.imaginea.spark.tpcds.perf.Data\n   +- MapElements <function1>, obj#1155: com.imaginea.spark.tpcds.perf.Data\n      +- MapElements <function1>, obj#1150: com.imaginea.spark.tpcds.perf.Data\n         +- MapElements <function1>, obj#1145: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1144: com.imaginea.spark.tpcds.perf.Data\n               +- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1161L]\n+- *MapElements <function1>, obj#1160: com.imaginea.spark.tpcds.perf.Data\n   +- *MapElements <function1>, obj#1155: com.imaginea.spark.tpcds.perf.Data\n      +- *MapElements <function1>, obj#1150: com.imaginea.spark.tpcds.perf.Data\n         +- *MapElements <function1>, obj#1145: com.imaginea.spark.tpcds.perf.Data\n            +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1144: com.imaginea.spark.tpcds.perf.Data\n               +- *Range (1, 100000000, splits=4)"},{"name":"DF: back-to-back maps","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":8.88E-4,"analysisTime":9.95E-4,"optimizationTime":1.025922,"planningTime":0.304791,"executionTime":3621.961211,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Project [('id + 1) AS id#1191]\n+- Project [(id#1185L + cast(1 as bigint)) AS id#1188L]\n   +- Project [(id#1182L + cast(1 as bigint)) AS id#1185L]\n      +- Project [(id#0L + cast(1 as bigint)) AS id#1182L]\n         +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nProject [(id#1188L + cast(1 as bigint)) AS id#1191L]\n+- Project [(id#1185L + cast(1 as bigint)) AS id#1188L]\n   +- Project [(id#1182L + cast(1 as bigint)) AS id#1185L]\n      +- Project [(id#0L + cast(1 as bigint)) AS id#1182L]\n         +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nProject [((((id#0L + 1) + 1) + 1) + 1) AS id#1191L]\n+- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Project [((((id#0L + 1) + 1) + 1) + 1) AS id#1191L]\n+- *Range (1, 100000000, splits=4)"},{"name":"RDD: back-to-back maps","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":4524.721168,"breakDown":[]},{"name":"DS: average","mode":"collect","parameters":{},"joinTypes":[],"tables":[],"breakDown":[],"failure":{"className":"org.apache.spark.sql.AnalysisException","message":"cannot resolve '`sum`' given input columns: [id];"}},{"name":"DF: average","mode":"collect","parameters":{},"joinTypes":[],"tables":[],"parsingTime":9.89E-4,"analysisTime":0.00113,"optimizationTime":0.492828,"planningTime":0.72726,"executionTime":49.533148,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Project [unresolvedalias('avg('id), Some(<function1>))]\n+- Range (1, 1000000, splits=4)\n\n== Analyzed Logical Plan ==\navg(id): double\nAggregate [avg(id#3L) AS avg(id)#1219]\n+- Range (1, 1000000, splits=4)\n\n== Optimized Logical Plan ==\nAggregate [avg(id#3L) AS avg(id)#1219]\n+- Range (1, 1000000, splits=4)\n\n== Physical Plan ==\n*TungstenAggregate(key=[], functions=[avg(id#3L)], output=[avg(id)#1219])\n+- Exchange SinglePartition, None\n   +- *TungstenAggregate(key=[], functions=[partial_avg(id#3L)], output=[sum#1223,count#1224L])\n      +- *Range (1, 1000000, splits=4)"},{"name":"RDD: average","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":31.455203,"breakDown":[]}]}
{"timestamp":1465280756151,"iteration":3,"tags":{"StandardRun":"true","runtype":"local","host":"PRINHYLTPHP0415"},"configuration":{"sparkVersion":"2.0.0-SNAPSHOT","sqlConf":{"spark.tpcds.perf.results":"file:/home/charanjits/Documents/ideaProjects/finalProjectImaginea/spark-tpcds-perf-master/performance/","spark.driver.host":"172.16.54.31","spark.driver.port":"34796","spark.app.name":"com.imaginea.spark.tpcds.perf.RunBenchmark$","spark.executor.id":"driver","spark.master":"local[*]","spark.app.id":"local-1465280752198"},"sparkConf":{"spark.driver.host":"172.16.54.31","spark.driver.port":"34796","spark.app.name":"com.imaginea.spark.tpcds.perf.RunBenchmark$","spark.executor.id":"driver","spark.master":"local[*]","spark.app.id":"local-1465280752198"},"defaultParallelism":4,"buildInfo":{}},"results":[{"name":"DS: range","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001483,"analysisTime":0.001012,"optimizationTime":0.399845,"planningTime":0.22488,"executionTime":4717.145236,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nRange (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Range (1, 100000000, splits=4)"},{"name":"DF: range","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001082,"analysisTime":0.001136,"optimizationTime":0.001071,"planningTime":0.001159,"executionTime":3616.299887,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nRange (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Range (1, 100000000, splits=4)"},{"name":"RDD: range","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":1319.100396,"breakDown":[]},{"name":"DS: back-to-back filters","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001389,"analysisTime":9.32E-4,"optimizationTime":7.155549,"planningTime":0.672664,"executionTime":4064.287048,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1268L]\n+- 'Filter <function1>.apply\n   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#1267: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1265L]\n         +- Filter <function1>.apply\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1264: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1262L]\n                  +- Filter <function1>.apply\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1261: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1259L]\n                           +- Filter <function1>.apply\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1258: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1268L]\n+- Filter <function1>.apply\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1267: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1265L]\n         +- Filter <function1>.apply\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1264: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1262L]\n                  +- Filter <function1>.apply\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1261: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1259L]\n                           +- Filter <function1>.apply\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1258: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1268L]\n+- Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1258: com.imaginea.spark.tpcds.perf.Data\n      +- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1268L]\n+- *Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)\n   +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1258: com.imaginea.spark.tpcds.perf.Data\n      +- *Range (1, 100000000, splits=4)"},{"name":"DF: back-to-back filters","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001579,"analysisTime":9.02E-4,"optimizationTime":3.291454,"planningTime":0.499064,"executionTime":3608.194401,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Filter NOT (('id % 103) = 0)\n+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))\n   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))\n      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))\n         +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nFilter NOT ((id#0L % cast(103 as bigint)) = cast(0 as bigint))\n+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))\n   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))\n      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))\n         +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nFilter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))\n+- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Filter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))\n+- *Range (1, 100000000, splits=4)"},{"name":"RDD: back-to-back filters","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":3790.927985,"breakDown":[]},{"name":"DS: back-to-back maps","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.002364,"analysisTime":0.001224,"optimizationTime":4.279263,"planningTime":0.58316,"executionTime":4484.936385,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1330L]\n+- 'MapElements <function1>, obj#1329: com.imaginea.spark.tpcds.perf.Data\n   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#1328: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1325L]\n         +- MapElements <function1>, obj#1324: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1323: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1320L]\n                  +- MapElements <function1>, obj#1319: com.imaginea.spark.tpcds.perf.Data\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1318: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1315L]\n                           +- MapElements <function1>, obj#1314: com.imaginea.spark.tpcds.perf.Data\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1313: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1330L]\n+- MapElements <function1>, obj#1329: com.imaginea.spark.tpcds.perf.Data\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1328: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1325L]\n         +- MapElements <function1>, obj#1324: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1323: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1320L]\n                  +- MapElements <function1>, obj#1319: com.imaginea.spark.tpcds.perf.Data\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1318: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1315L]\n                           +- MapElements <function1>, obj#1314: com.imaginea.spark.tpcds.perf.Data\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1313: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1330L]\n+- MapElements <function1>, obj#1329: com.imaginea.spark.tpcds.perf.Data\n   +- MapElements <function1>, obj#1324: com.imaginea.spark.tpcds.perf.Data\n      +- MapElements <function1>, obj#1319: com.imaginea.spark.tpcds.perf.Data\n         +- MapElements <function1>, obj#1314: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1313: com.imaginea.spark.tpcds.perf.Data\n               +- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1330L]\n+- *MapElements <function1>, obj#1329: com.imaginea.spark.tpcds.perf.Data\n   +- *MapElements <function1>, obj#1324: com.imaginea.spark.tpcds.perf.Data\n      +- *MapElements <function1>, obj#1319: com.imaginea.spark.tpcds.perf.Data\n         +- *MapElements <function1>, obj#1314: com.imaginea.spark.tpcds.perf.Data\n            +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1313: com.imaginea.spark.tpcds.perf.Data\n               +- *Range (1, 100000000, splits=4)"},{"name":"DF: back-to-back maps","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.002272,"analysisTime":0.001187,"optimizationTime":7.875709,"planningTime":0.443151,"executionTime":6094.951101,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Project [('id + 1) AS id#1360]\n+- Project [(id#1354L + cast(1 as bigint)) AS id#1357L]\n   +- Project [(id#1351L + cast(1 as bigint)) AS id#1354L]\n      +- Project [(id#0L + cast(1 as bigint)) AS id#1351L]\n         +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nProject [(id#1357L + cast(1 as bigint)) AS id#1360L]\n+- Project [(id#1354L + cast(1 as bigint)) AS id#1357L]\n   +- Project [(id#1351L + cast(1 as bigint)) AS id#1354L]\n      +- Project [(id#0L + cast(1 as bigint)) AS id#1351L]\n         +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nProject [((((id#0L + 1) + 1) + 1) + 1) AS id#1360L]\n+- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Project [((((id#0L + 1) + 1) + 1) + 1) AS id#1360L]\n+- *Range (1, 100000000, splits=4)"},{"name":"RDD: back-to-back maps","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":5515.642766,"breakDown":[]},{"name":"DS: average","mode":"collect","parameters":{},"joinTypes":[],"tables":[],"breakDown":[],"failure":{"className":"org.apache.spark.sql.AnalysisException","message":"cannot resolve '`sum`' given input columns: [id];"}},{"name":"DF: average","mode":"collect","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001948,"analysisTime":0.001102,"optimizationTime":0.901124,"planningTime":1.733817,"executionTime":110.539455,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Project [unresolvedalias('avg('id), Some(<function1>))]\n+- Range (1, 1000000, splits=4)\n\n== Analyzed Logical Plan ==\navg(id): double\nAggregate [avg(id#3L) AS avg(id)#1388]\n+- Range (1, 1000000, splits=4)\n\n== Optimized Logical Plan ==\nAggregate [avg(id#3L) AS avg(id)#1388]\n+- Range (1, 1000000, splits=4)\n\n== Physical Plan ==\n*TungstenAggregate(key=[], functions=[avg(id#3L)], output=[avg(id)#1388])\n+- Exchange SinglePartition, None\n   +- *TungstenAggregate(key=[], functions=[partial_avg(id#3L)], output=[sum#1392,count#1393L])\n      +- *Range (1, 1000000, splits=4)"},{"name":"RDD: average","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":36.168872,"breakDown":[]},{"name":"DS: range","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001578,"analysisTime":0.001149,"optimizationTime":0.304568,"planningTime":0.149113,"executionTime":3540.029715,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nRange (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Range (1, 100000000, splits=4)"},{"name":"DF: range","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.002066,"analysisTime":0.001575,"optimizationTime":0.002228,"planningTime":0.001145,"executionTime":3909.020092,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nRange (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nRange (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Range (1, 100000000, splits=4)"},{"name":"RDD: range","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":1355.355359,"breakDown":[]},{"name":"DS: back-to-back filters","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001357,"analysisTime":7.8E-4,"optimizationTime":6.35565,"planningTime":0.530175,"executionTime":3963.395014,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1437L]\n+- 'Filter <function1>.apply\n   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#1436: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1434L]\n         +- Filter <function1>.apply\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1433: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1431L]\n                  +- Filter <function1>.apply\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1430: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1428L]\n                           +- Filter <function1>.apply\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1427: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1437L]\n+- Filter <function1>.apply\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1436: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1434L]\n         +- Filter <function1>.apply\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1433: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1431L]\n                  +- Filter <function1>.apply\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1430: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1428L]\n                           +- Filter <function1>.apply\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1427: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1437L]\n+- Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1427: com.imaginea.spark.tpcds.perf.Data\n      +- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1437L]\n+- *Filter (((<function1>.apply && <function1>.apply) && <function1>.apply) && <function1>.apply)\n   +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1427: com.imaginea.spark.tpcds.perf.Data\n      +- *Range (1, 100000000, splits=4)"},{"name":"DF: back-to-back filters","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001878,"analysisTime":0.001201,"optimizationTime":3.31934,"planningTime":0.833799,"executionTime":3563.834341,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Filter NOT (('id % 103) = 0)\n+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))\n   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))\n      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))\n         +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nFilter NOT ((id#0L % cast(103 as bigint)) = cast(0 as bigint))\n+- Filter NOT ((id#0L % cast(102 as bigint)) = cast(0 as bigint))\n   +- Filter NOT ((id#0L % cast(101 as bigint)) = cast(0 as bigint))\n      +- Filter NOT ((id#0L % cast(100 as bigint)) = cast(0 as bigint))\n         +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nFilter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))\n+- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Filter (((NOT ((id#0L % 103) = 0) && NOT ((id#0L % 102) = 0)) && NOT ((id#0L % 101) = 0)) && NOT ((id#0L % 100) = 0))\n+- *Range (1, 100000000, splits=4)"},{"name":"RDD: back-to-back filters","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":3374.218231,"breakDown":[]},{"name":"DS: back-to-back maps","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.00149,"analysisTime":0.001225,"optimizationTime":3.863818,"planningTime":0.579019,"executionTime":3924.290342,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1499L]\n+- 'MapElements <function1>, obj#1498: com.imaginea.spark.tpcds.perf.Data\n   +- 'DeserializeToObject unresolveddeserializer(newInstance(class com.imaginea.spark.tpcds.perf.Data)), obj#1497: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1494L]\n         +- MapElements <function1>, obj#1493: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1492: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1489L]\n                  +- MapElements <function1>, obj#1488: com.imaginea.spark.tpcds.perf.Data\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1487: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1484L]\n                           +- MapElements <function1>, obj#1483: com.imaginea.spark.tpcds.perf.Data\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1482: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1499L]\n+- MapElements <function1>, obj#1498: com.imaginea.spark.tpcds.perf.Data\n   +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1497: com.imaginea.spark.tpcds.perf.Data\n      +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1494L]\n         +- MapElements <function1>, obj#1493: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1492: com.imaginea.spark.tpcds.perf.Data\n               +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1489L]\n                  +- MapElements <function1>, obj#1488: com.imaginea.spark.tpcds.perf.Data\n                     +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1487: com.imaginea.spark.tpcds.perf.Data\n                        +- SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1484L]\n                           +- MapElements <function1>, obj#1483: com.imaginea.spark.tpcds.perf.Data\n                              +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1482: com.imaginea.spark.tpcds.perf.Data\n                                 +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nSerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1499L]\n+- MapElements <function1>, obj#1498: com.imaginea.spark.tpcds.perf.Data\n   +- MapElements <function1>, obj#1493: com.imaginea.spark.tpcds.perf.Data\n      +- MapElements <function1>, obj#1488: com.imaginea.spark.tpcds.perf.Data\n         +- MapElements <function1>, obj#1483: com.imaginea.spark.tpcds.perf.Data\n            +- DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1482: com.imaginea.spark.tpcds.perf.Data\n               +- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*SerializeFromObject [input[0, com.imaginea.spark.tpcds.perf.Data, false].id AS id#1499L]\n+- *MapElements <function1>, obj#1498: com.imaginea.spark.tpcds.perf.Data\n   +- *MapElements <function1>, obj#1493: com.imaginea.spark.tpcds.perf.Data\n      +- *MapElements <function1>, obj#1488: com.imaginea.spark.tpcds.perf.Data\n         +- *MapElements <function1>, obj#1483: com.imaginea.spark.tpcds.perf.Data\n            +- *DeserializeToObject newInstance(class com.imaginea.spark.tpcds.perf.Data), obj#1482: com.imaginea.spark.tpcds.perf.Data\n               +- *Range (1, 100000000, splits=4)"},{"name":"DF: back-to-back maps","mode":"foreach","parameters":{},"joinTypes":[],"tables":[],"parsingTime":0.001661,"analysisTime":8.61E-4,"optimizationTime":1.203944,"planningTime":0.297527,"executionTime":4043.191968,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Project [('id + 1) AS id#1529]\n+- Project [(id#1523L + cast(1 as bigint)) AS id#1526L]\n   +- Project [(id#1520L + cast(1 as bigint)) AS id#1523L]\n      +- Project [(id#0L + cast(1 as bigint)) AS id#1520L]\n         +- Range (1, 100000000, splits=4)\n\n== Analyzed Logical Plan ==\nid: bigint\nProject [(id#1526L + cast(1 as bigint)) AS id#1529L]\n+- Project [(id#1523L + cast(1 as bigint)) AS id#1526L]\n   +- Project [(id#1520L + cast(1 as bigint)) AS id#1523L]\n      +- Project [(id#0L + cast(1 as bigint)) AS id#1520L]\n         +- Range (1, 100000000, splits=4)\n\n== Optimized Logical Plan ==\nProject [((((id#0L + 1) + 1) + 1) + 1) AS id#1529L]\n+- Range (1, 100000000, splits=4)\n\n== Physical Plan ==\n*Project [((((id#0L + 1) + 1) + 1) + 1) AS id#1529L]\n+- *Range (1, 100000000, splits=4)"},{"name":"RDD: back-to-back maps","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":4530.478316,"breakDown":[]},{"name":"DS: average","mode":"collect","parameters":{},"joinTypes":[],"tables":[],"breakDown":[],"failure":{"className":"org.apache.spark.sql.AnalysisException","message":"cannot resolve '`sum`' given input columns: [id];"}},{"name":"DF: average","mode":"collect","parameters":{},"joinTypes":[],"tables":[],"parsingTime":8.75E-4,"analysisTime":8.32E-4,"optimizationTime":0.453576,"planningTime":0.588844,"executionTime":47.960799,"breakDown":[],"queryExecution":"== Parsed Logical Plan ==\n'Project [unresolvedalias('avg('id), Some(<function1>))]\n+- Range (1, 1000000, splits=4)\n\n== Analyzed Logical Plan ==\navg(id): double\nAggregate [avg(id#3L) AS avg(id)#1557]\n+- Range (1, 1000000, splits=4)\n\n== Optimized Logical Plan ==\nAggregate [avg(id#3L) AS avg(id)#1557]\n+- Range (1, 1000000, splits=4)\n\n== Physical Plan ==\n*TungstenAggregate(key=[], functions=[avg(id#3L)], output=[avg(id)#1557])\n+- Exchange SinglePartition, None\n   +- *TungstenAggregate(key=[], functions=[partial_avg(id#3L)], output=[sum#1561,count#1562L])\n      +- *Range (1, 1000000, splits=4)"},{"name":"RDD: average","mode":"sparkPerf","parameters":{},"joinTypes":[],"tables":[],"executionTime":35.906597,"breakDown":[]}]}
